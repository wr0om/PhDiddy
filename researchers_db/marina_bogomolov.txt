Recent papers for Marina Bogomolov:

2022: Replicability Across Multiple Studies
Abstract: Meta-analysis is routinely performed in many scientific disciplines. This analysis is attractive since discoveries are possible even when all the individual studies are underpowered. However, the meta-analytic discoveries may be entirely driven by signal in a single study, and thus non-replicable. Although the great majority of meta-analyses carried out to date do not infer on the replicability of their findings, it is possible to do so. We provide a selective overview of analyses that can be carried out towards establishing replicability of the scientific findings. We describe methods for the setting where a single outcome is examined in multiple studies (as is common in systematic reviews of medical interventions), as well as for the setting where multiple studies each examine multiple features (as in genomics applications). We also discuss some of the current shortcomings and future directions.

2022: Protocol for an Observational Study on the Effects of Giving Births from Unintended Pregnancies on Later Life Physical and Mental Health
Abstract: There has been increasing interest in studying the effect of giving births to unintended pregnancies on later life physical and mental health. In this article, we provide the protocol for our planned observational study on the long-term mental and physical health consequences for mothers who bear children resulting from unintended pregnancies. We aim to use the data from the Wisconsin Longitudinal Study (WLS) and examine the effect of births from unintended pregnancies on a broad range of outcomes, including mental depression, psychological well-being, physical health, alcohol usage, and economic well-being. To strengthen our causal findings, we plan to address our research questions on two subgroups, Catholics and non-Catholics, and discover the"replicable"outcomes for which the effect of unintended pregnancy is negative (or, positive) in both subgroups. Following the idea of non-random cross-screening, the data will be split according to whether the woman is Catholic or not, and then one part of the data will be used to select the hypotheses and design the corresponding tests for the second part of the data. In past use of cross-screening (automatic cross-screening) there was only one team of investigators that dealt with both parts of the data so that the investigators would need to decide on an analysis plan before looking at the data. In this protocol, we describe plans to carry out a novel flexible cross-screening in which there will be two teams of investigators with access only to one part of data and each team will use their part of the data to decide how to plan the analysis for the second team's data. In addition to the above replicability analysis, we also discuss the plan to test the global null hypothesis that is intended to identify the outcomes which are affected by unintended pregnancy for at least one of the two subgroups of Catholics and non-Catholics.

2021: Testing partial conjunction hypotheses under dependency, with applications to meta-analysis
Abstract: In many statistical problems the hypotheses are naturally divided into groups, and the investigators are interested to perform grouplevel inference, possibly along with inference on individual hypotheses. We consider the goal of discovering groups containing u or more signals with group-level false discovery rate (FDR) control. This goal can be addressed by multiple testing of partial conjunction hypotheses with a parameter u, which reduce to global null hypotheses for u = 1. We consider the case where the partial conjunction p-values are combinations of within-group p-values, and obtain sufficient conditions on (1) the dependencies among the p-values within and across the groups, (2) the combining method for obtaining partial conjunction p-values, and (3) the multiple testing procedure, for obtaining FDR control on partial conjunction discoveries. We consider separately the dependencies encountered in the meta-analysis setting, where multiple features are tested in several independent studies, and the p-values within each study may be dependent. Based on the results for this setting, we generalize the procedure of Benjamini, Heller, and Yekutieli (2009) for assessing replicability of signals across studies, and extend their theoretical results regarding FDR control with respect to replicability claims.

2020: Hypotheses on a tree: new error rates and testing strategies.
Abstract: We introduce a multiple testing procedure that controls global error rates at multiple levels of resolution. Conceptually, we frame this problem as the selection of hypotheses that are organized hierarchically in a tree structure. We describe a fast algorithm and prove that it controls relevant error rates given certain assumptions on the dependence between the p-values. Through simulations, we demonstrate that the proposed procedure provides the desired guarantees under a range of dependency structures and that it has the potential to gain power over alternative methods. Finally, we apply the method to studies on the genetic regulation of gene expression across multiple tissues and on the relation between the gut microbiome and colorectal cancer.

2019: Order restricted univariate and multivariate inference with adjustment for covariates in partially linear models
Abstract: None

2018: Controlling FDR while highlighting selected discoveries
Abstract: Often modern scientific investigations start by testing a very large number of hypotheses in an effort to comprehensively mine the data for possible discoveries. Multiplicity adjustment strategies are employed to ensure replicability of the results of this broad search. Furthermore, in many cases, discoveries are subject to a second round of selection, where researchers identify the rejected hypotheses that better represent distinct and interpretable findings for reporting and follow-up. For example, in genetic studies, one DNA variant is often chosen to represent a group of neighboring polymorphisms, all apparently associated to a trait of interest. Unfortunately the guarantees of false discovery rate (FDR) control that might be true for the initial set of findings do not translate to this subset, possibly leading to an inflation of FDR in the reported discoveries. To guarantee valid inference, we introduce Focused BH, a multiple testing procedure that allows the researcher to curate rejections by subsetting or prioritizing them according to pre-specified but possibly data-dependent rules (filters). Focused BH assures FDR control on the selected discoveries under a range of assumptions on the filter and the p-value dependency structure; simulations illustrate that this is obtained without substantial power loss and that the procedure is robust to violations of our theoretical assumptions.

2018: Filtering the Rejection Set While Preserving False Discovery Rate Control
Abstract: Abstract Scientific hypotheses in a variety of applications have domain-specific structures, such as the tree structure of the international classification of diseases (ICD), the directed acyclic graph structure of the gene ontology (GO), or the spatial structure in genome-wide association studies. In the context of multiple testing, the resulting relationships among hypotheses can create redundancies among rejections that hinder interpretability. This leads to the practice of filtering rejection sets obtained from multiple testing procedures, which may in turn invalidate their inferential guarantees. We propose Focused BH, a simple, flexible, and principled methodology to adjust for the application of any prespecified filter. We prove that Focused BH controls the false discovery rate under various conditions, including when the filter satisfies an intuitive monotonicity property and the p-values are positively dependent. We demonstrate in simulations that Focused BH performs well across a variety of settings, and illustrate this method’s practical utility via analyses of real datasets based on ICD and GO.

2018: Controlling FDR while highlighting distinct discoveries
Abstract: Often modern scientific investigations start by testing a very large number of hypotheses in an effort to comprehensively mine the data for possible discoveries. Multiplicity adjustment strategies are employed to ensure replicability of the results of this broad search. Furthermore, in many cases, discoveries are subject to a second round of filtering, where researchers select the rejected hypotheses that better represent distinct and interpretable findings for reporting and follow-up. For example, in genetic studies, one DNA variant is often chosen to represent a group of neighboring polymorphisms, all apparently associated to a trait of interest. Unfortunately the guarantees of false discovery rate (FDR) control that might be true for the initial set of findings do not translate to this second filtered set. Indeed we observe that some filters used in practice have a tendency of keeping a larger fraction of nulls than non-nulls, thereby inflating the FDR. To overcome this, we introduce Focused BH, a multiple testing procedure that accounts for the filtering step, allowing the researcher to rely on the data and on the results of testing to filter the rejection set, while assuring FDR control under a range of assumptions on the filter and the p-value dependency structure. Simulations illustrate that FDR control on the filtered set of discoveries is obtained without substantial power loss and that the procedure is robust to violations of our theoretical assumptions. Notable applications of Focused BH include control of the outer node FDR when testing hypotheses on a tree.

2017: A powerful statistical framework for generalization testing in GWAS, with application to the HCHS/SOL
Abstract: In genome‐wide association studies (GWAS), “generalization” is the replication of genotype‐phenotype association in a population with different ancestry than the population in which it was first identified. Current practices for declaring generalizations rely on testing associations while controlling the family‐wise error rate (FWER) in the discovery study, then separately controlling error measures in the follow‐up study. This approach does not guarantee control over the FWER or false discovery rate (FDR) of the generalization null hypotheses. It also fails to leverage the two‐stage design to increase power for detecting generalized associations. We provide a formal statistical framework for quantifying the evidence of generalization that accounts for the (in)consistency between the directions of associations in the discovery and follow‐up studies. We develop the directional generalization FWER (FWERg) and FDR (FDRg) controlling r‐values, which are used to declare associations as generalized. This framework extends to generalization testing when applied to a published list of Single Nucleotide Polymorphism‐(SNP)‐trait associations. Our methods control FWERg or FDRg under various SNP selection rules based on P‐values in the discovery study. We find that it is often beneficial to use a more lenient P‐value threshold than the genome‐wide significance threshold. In a GWAS of total cholesterol in the Hispanic Community Health Study/Study of Latinos (HCHS/SOL), when testing all SNPs with P‐values <5×10−8 (15 genomic regions) for generalization in a large GWAS of whites, we generalized SNPs from 15 regions. But when testing all SNPs with P‐values <6.6×10−5 (89 regions), we generalized SNPs from 27 regions.

2017: Testing hypotheses on a tree: new error rates and controlling strategies
Abstract: We propose a new multiple testing procedure which addresses the challenge of controlling error rates at multiple levels of resolution. Conceptually, we frame this problem as the selection of hypotheses which are organized hierarchically in a tree structure. We provide a detailed algorithm for the proposed sequential procedure, and prove that it controls relevant error rates given certain assumptions on the dependence among the hypotheses. Through simulation, we demonstrate that the proposed strategy controls these error rates in both simple settings and in settings with dependence similar to that encountered in genome-wide association studies, while offering the potential to gain power over alternative methods. Finally, we conclude with two case studies where we apply the proposed method: firstly, to data collected as part of the Genotype-Tissue Expression (GTEx) project, which aims to characterize the genetic regulation of gene expression across multiple tissues in the human body, and secondly, to data examining the relationship between the gut microbiome and colorectal cancer.

2017: Replicability Analysis for Natural Language Processing: Testing Significance with Multiple Datasets
Abstract: With the ever growing amount of textual data from a large variety of languages, domains, and genres, it has become standard to evaluate NLP algorithms on multiple datasets in order to ensure a consistent performance across heterogeneous setups. However, such multiple comparisons pose significant challenges to traditional statistical analysis methods in NLP and can lead to erroneous conclusions. In this paper we propose a Replicability Analysis framework for a statistically sound analysis of multiple comparisons between algorithms for NLP tasks. We discuss the theoretical advantages of this framework over the current, statistically unjustified, practice in the NLP literature, and demonstrate its empirical value across four applications: multi-domain dependency parsing, multilingual POS tagging, cross-domain sentiment classification and word similarity prediction.

2016: Characterization of Expression Quantitative Trait Loci in Pedigrees from Colombia and Rica Ascertained for Bipolar Disorder.
Abstract: The observation that variants regulating gene expression (expression quantitative trait loci, eQTL) are at a high frequency among SNPs associated with complex traits has made the genome-wide characterization of gene expression an important tool in genetic mapping studies of such traits. As part of a study to identify genetic loci contributing to bipolar disorder and other quantitative traits in members of 26 pedigrees from Costa Rica and Colombia, we measured gene expression in lymphoblastoid cell lines derived from 786 pedigree members. The study design enabled us to comprehensively reconstruct the genetic regulatory network in these families, provide estimates of heritability, identify eQTL, evaluate missing heritability for the eQTL, and quantify the number of different alleles contributing to any given locus. In the eQTL analysis, we utilize a recently proposed hierarchical multiple testing strategy which controls error rates regarding the discovery of functional variants. Our results elucidate the heritability and regulation of gene expression in this unique Latin American study population and identify a set of regulatory SNPs which may be relevant in future investigations of complex disease in this population. Since our subjects belong to extended families, we are able to compare traditional kinship-based estimates with those from more recent methods that depend only on genotype information. We assess the heritability and genetic regulation of gene expression in a population of 786 individuals from Costa Rica and Colombia. The subjects, originally recruited in a study of bipolar disorder, are related within 26 extended families. This design allows us to compare estimates of the heritability of gene expression obtained using both traditional and geno-type-based methods. We address questions regarding the architecture of genetic regulation including the extent to which gene expression is influenced by variants located nearby vs. far away on the genome and how many variants affect the expression of a given gene. In addition, we identify genetic variants which regulate gene expression; these serve as candidates for future studies to establish the genetic basis of complex traits, including those related to bipolar disorder, and also provide insight into the architecture of genetic regulation in this unique Latin American study population. partial reconstruction of the specific regulatory network (i.e. the bipartite graph relating genetic variants to gene expression traits, the strength associated to each of these edges, and the overall impact of genetic variants on the variability of expression) for these families, allowing us to identify those components that might show differences from the general population. We study the genetic regulation of expression in these pedigrees at a multiscale level: we estimate heritability, evaluate the relative importance of local vs. distal genomic variation, identify variants with regulatory effects, and analyze the role of multiple associated SNPs in the same region. By capitalizing on known pedigree structure, as well as extensive genotyping, we can compare different methodologies for heritability estimation. The most interesting element of regulatory networks for our purpose is the localization of SNPs with regulatory effects (eSNPs): these variants are candidates for future studies investigating association to the BP1 endophenotypes measured in our sample, and also provide insight into functional genetic variation in this unique population. To control the rate of false discoveries of eSNPs, we adopt a novel hierarchical testing procedure that leads to the analysis of expression quantitative trait loci (eQTL) data in a stage-wise manner with increasing levels of detail.

2016: Characterization of Expression Quantitative Trait Loci in Pedigrees from Colombia and Costa Rica Ascertained for Bipolar Disorder
Abstract: The observation that variants regulating gene expression (expression quantitative trait loci, eQTL) are at a high frequency among SNPs associated with complex traits has made the genome-wide characterization of gene expression an important tool in genetic mapping studies of such traits. As part of a study to identify genetic loci contributing to bipolar disorder and other quantitative traits in members of 26 pedigrees from Costa Rica and Colombia, we measured gene expression in lymphoblastoid cell lines derived from 786 pedigree members. The study design enabled us to comprehensively reconstruct the genetic regulatory network in these families, provide estimates of heritability, identify eQTL, evaluate missing heritability for the eQTL, and quantify the number of different alleles contributing to any given locus. In the eQTL analysis, we utilize a recently proposed hierarchical multiple testing strategy which controls error rates regarding the discovery of functional variants. Our results elucidate the heritability and regulation of gene expression in this unique Latin American study population and identify a set of regulatory SNPs which may be relevant in future investigations of complex disease in this population. Since our subjects belong to extended families, we are able to compare traditional kinship-based estimates with those from more recent methods that depend only on genotype information.

2016: Genetic variation and gene expression across multiple tissues and developmental stages in a non-human primate
Abstract: By analyzing multitissue gene expression and genome-wide genetic variation data in samples from a vervet monkey pedigree, we generated a transcriptome resource and produced the first catalog of expression quantitative trait loci (eQTLs) in a nonhuman primate model. This catalog contains more genome-wide significant eQTLs per sample than comparable human resources and identifies sex- and age-related expression patterns. Findings include a master regulatory locus that likely has a role in immune function and a locus regulating hippocampal long noncoding RNAs (lncRNAs), whose expression correlates with hippocampal volume. This resource will facilitate genetic investigation of quantitative traits, including brain and behavioral phenotypes relevant to neuropsychiatric disorders.

2015: Many Phenotypes Without Many False Discoveries: Error Controlling Strategies for Multitrait Association Studies
Abstract: The genetic basis of multiple phenotypes such as gene expression, metabolite levels, or imaging features is often investigated by testing a large collection of hypotheses, probing the existence of association between each of the traits and hundreds of thousands of genotyped variants. Appropriate multiplicity adjustment is crucial to guarantee replicability of findings, and the false discovery rate (FDR) is frequently adopted as a measure of global error. In the interest of interpretability, results are often summarized so that reporting focuses on variants discovered to be associated to some phenotypes. We show that applying FDR‐controlling procedures on the entire collection of hypotheses fails to control the rate of false discovery of associated variants as well as the expected value of the average proportion of false discovery of phenotypes influenced by such variants. We propose a simple hierarchical testing procedure that allows control of both these error rates and provides a more reliable basis for the identification of variants with functional effects. We demonstrate the utility of this approach through simulation studies comparing various error rates and measures of power for genetic association studies of multiple traits. Finally, we apply the proposed method to identify genetic variants that impact flowering phenotypes in Arabidopsis thaliana, expanding the set of discoveries.

2015: Characterization of expression quantitative trait loci in extensively phenotyped pedigrees ascertained for bipolar disorder
Abstract: The observation that variants regulating gene expression (expression quantitative trait loci, eQTL) are at a high frequency among SNPs associated with complex traits has made the genome-wide characterization of gene expression an important tool in genetic mapping studies of such traits. As part of a study to identify genetic loci contributing to bipolar disorder and a wide range of BP-related quantitative traits in members of 26 pedigrees from Costa Rica and Colombia, we measured gene expression in lymphoblastoid cell lines derived from 786 pedigree members. The study design enabled us to comprehensively reconstruct the genetic regulatory network in these families, provide estimates of heritability, identify eQTL, evaluate missing heritability for the eQTL, and quantify the number of different alleles contributing to any given locus.

2015: Testing for replicability in a follow-up study when the primary study hypotheses are two-sided
Abstract: When testing for replication of results from a primary study with two-sided hypotheses in a follow-up study, we are usually interested in discovering the features with discoveries in the same direction in the two studies. The direction of testing in the follow-up study for each feature can therefore be decided by the primary study. We prove that in this case the methods suggested in Heller, Bogomolov, and Benjamini (2014) for control over false replicability claims are valid. Specifically, we prove that if we input into the procedures in Heller, Bogomolov, and Benjamini (2014) the one-sided p-values in the directions favoured by the primary study, then we achieve directional control over the desired error measure (family-wise error rate or false discovery rate).

2015: TreeQTL: hierarchical error control for eQTL findings
Abstract: Summary Commonly used multiplicity adjustments fail to control the error rate for reported findings in many expression quantitative trait loci (eQTL) studies. TreeQTL implements a stage-wise multiple testing procedure which allows control of appropriate error rates defined relative to a hierarchical grouping of the eQTL hypotheses. Availability and Implementation The R package TreeQTL is available for download at http://bioinformatics.org/treeqtl. Contact sabatti@stanford.edu

2015: Assessing replicability of findings across two studies of multiple features
Abstract: SummaryReplicability analysis aims to identify the overlapping signals across independent studies that examine the same features. For this purpose we develop hypothesis testing procedures that first select the promising features from each of two studies separately. Only those features selected in both studies are then tested. The proposed procedures have theoretical guarantees regarding their control of the familywise error rate or false discovery rate on the replicability claims. They can also be used for signal discovery in each study separately, with the desired error control. Their power for detecting truly replicable findings is compared to alternatives. We illustrate the procedures on behavioural genetics data.

2015: CONTROLLING FALSE DISCOVERIES IN MAPPING MULTIPLE PHENOTYPES
Abstract: The genetic basis of multiple phenotypes such as gene expression, metabolite levels, or imaging features is often investigated by testing a large collection of hypotheses, probing the existence of association between each of the traits and hundred of thousands of genotyped variants. Appropriate multiplicity adjustment is crucial to guarantee replicability of findings, and False Discovery Rate (FDR) is frequently adopted as a measure of global error. In the interest of interpretability, results are often summarized so that reporting focuses on variants discovered to be associated to some phenotypes. We show that applying FDR-controlling procedures on the entire collection of hypotheses fails to control the rate of false discovery of associated variants as well as the average rate of false discovery of phenotypes influenced by such variants. We propose a simple hierarchical testing procedure which allows control of both these error rates and provides a more reliable basis for the identification of variants with functional effects. We demonstrate the utility of this approach through simulation studies comparing various error rates and measures of power for multiple traits genetic association studies. Finally, we apply the proposed method to identify genetic variants which impact flowering phenotypes in Arabdopsis thaliana, expanding the set of discoveries.

