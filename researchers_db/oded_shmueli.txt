Recent papers for Oded Shmueli:

2025: Nondeterminism and the clique problem
Abstract: None

2024: Seventh International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (aiDM)
Abstract: Recent advances in AI techniques, as well as enabling hardware and infrastructure, have led to the integration of AI across wide-ranging domains and tasks. In particular, AI has been used to handle various types of data (including numerical, textual and image data) and has been adopted in large-scale distributed systems. From a data management perspective, this calls for the harnessing of state-of-the-art AI solutions for data management tasks and systems. aiDM is a full-day workshop that offers a stage for innovative interdisciplinary research that studies the interaction between AI and data management and develops new AI technologies for data-related tasks. This year, aiDM'24 particularly focuses on the transparent exploitation of AI techniques (e.g., using Generative AI frameworks) for data management for enterprise class workloads.

2023: Sixth International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (aiDM)
Abstract: Recent advances in AI techniques, as well as enabling hardware and infrastructure, has led to the integration of AI in wide-ranging domains and tasks. In particular, AI has been used to handle various types of data (including numerical, textual and image data) and has been adopted in large-scale distributed systems. From a data management perspective, this calls for the harnessing of state-of-the-art AI solutions for data management tasks and systems. aiDM is a full-day workshop that offers a stage for innovative interdisciplinary research that studies the interaction between AI and data management and develops new AI technologies for data-related tasks. This year, aiDM'23 particularly focuses on the transparent exploitation of AI techniques in existing enterprise-level data management workloads.

2022: aiDM'22: Fifth International Workshop on Exploiting Artificial Intelligence Techniques for Data Management
Abstract: Recent advances in AI techniques, as well as enabling hardware and infrastructure, has led to the integration of AI in wide-ranging domains and tasks. In particular, AI has been used to handle various types of data (including numerical, textual and graphical data) and has been adopted in large-scale distributed systems. From a data management perspective, this calls for the harnessing of state-of- the-art AI solutions for data management tasks and systems. aiDM is a full-day workshop that offers a stage for innovative interdisciplinary research that studies the interaction between AI and data management and develops new AI technologies for data-related tasks. This year, aiDM'22 particularly focuses on the transparent exploitation of AI techniques in existing enterprise-level data management workloads.

2022: Towards practical approximate lineage
Abstract: Traditionally, provenance and lineage mainly referred to query results. We take a more holistic approach. We consider a system in which tuples (records) that are produced by a query may affect other tuple insertions into the DB, as part of a normal workflow. Therefore, we consider both direct lineage (dependence of a query result on database tuples directly used in solving the query) and distant lineage (dependence on older tuples that caused the existence of the tuples directly used in solving the query). We aim to formulate practical methods for supporting direct and distant lineage. We use a novel genetics-inspired approach for approximating lineage tracking, which is based on word embedding to endow an explicitly inserted tuple with a small set of vectors that "encode" its content, and on an algebra on such sets of vectors that derives a set of vectors which encodes the lineage of a query-inserted tuple. During the execution of a query, we construct the lineage vectors of the final (and intermediate) result tuples in a similar fashion to that of semiring-based exact provenance calculations. We extend the + and operations to generate sets of lineage vectors, while retaining the ability to propagate information and preserve the compact representation. Therefore, our solution does not suffer from space complexity blow-up over time, and it "naturally ranks" explanations to the existence of a tuple. We introduce several fundamental improvements and extensions to the basic method of [19]. The aim is to make the basic scheme practical by taking advantage of additional knowledge regarding timing, query structure, and relative importance. The improvements include: tuple creation timestamps and a temporal sequence of search structures, column emphasis and query dependency DAG. We integrate our lineage computations with these improvements into the PostgreSQL system via an extension (ProvSQL) and perform extensive experiments. The experiments exhibit useful results in terms of accuracy against (the gold-standard) exact, semiring-based, tuple justifications, especially for the column-based (CV) method which exhibits high precision and high per-level recall. We focus on target tuples with multiple generations of tuples in their lineage, namely having a distant lineage, and analyze them in terms of generational lineage accuracy.

2022: Database States Exhibiting Tree Projection Necessity
Abstract: None

2022: Efficient approximate search for sets of lineage vectors
Abstract: One can approximate the lineage of a Database (DB) tuple using a small set of low dimensional vectors. To identify actual lineage tuples using these vector sets, given a set of vectors (of the target tuple), one needs to locate "close" sets of vectors associated with the lineage tuples. We first consider a similarity measure between two sets A and B of vectors, that balances the average and maximum cosine distance between pairs of vectors, one from set A and one from set B. The proposed similarity measure is intuitive and permutation invariant. To practically realize this measure, we need an approximate search algorithm that given a set of vectors A and sets of vectors B1, ..., Bn, the algorithm quickly locates the k-closest sets Bi1 ..., Bik that maximize the similarity measure. For the case where all sets are singleton sets, essentially each is a single vector, there are known efficient approximate search algorithms, e.g., approximated versions of tree search algorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and proximity graph algorithms. We utilize the mathematical properties of the cosine distance measure to transform the set-set search problem into a vector-vector search problem. However, this abovementioned transformation cannot handle the Euclidean-based version of the similarity measure. For this version, we devise a more elaborate transformation. For this latter transformation, we present algorithms for the general case, with sets of differing cardinalities. The underlying idea in both of these transformations is encoding a set of vectors A via |A| "long" independent representative vectors. Then, we are able to transform the set-set search problem into the well-studied approximate (ordinary) vector search problem. For both cosine-based and Euclidean-based similarity measures, the proposed approximate search achieves significant performance gains over an optimized, exact search on vector sets.

2021: Efficient Approximate Search for Sets of Vectors
Abstract: We consider a similarity measure between two sets $A$ and $B$ of vectors, that balances the average and maximum cosine distance between pairs of vectors, one from set $A$ and one from set $B$. As a motivation for this measure, we present lineage tracking in a database. To practically realize this measure, we need an approximate search algorithm that given a set of vectors $A$ and sets of vectors $B_1,...,B_n$, the algorithm quickly locates the set $B_i$ that maximizes the similarity measure. For the case where all sets are singleton sets, essentially each is a single vector, there are known efficient approximate search algorithms, e.g., approximated versions of tree search algorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and proximity graph algorithms. In this work, we present approximate search algorithms for the general case. The underlying idea in these algorithms is encoding a set of vectors via a"long"single vector. The proposed approximate approach achieves significant performance gains over an optimized, exact search on vector sets.

2021: Efficient Set of Vectors Search
Abstract: We consider a similarity measure between two sets ùê¥ and ùêµ of vectors, that balances the average and maximum cosine distance be-tween pairs of vectors, one from set ùê¥ and one from set ùêµ . As a motivation for this measure, we present lineage tracking in a data-base. To practically realize this measure, we need an approximate search algorithm that given a set of vectors ùê¥ and sets of vectors ùêµ 1 , ..., ùêµ ùëõ , the algorithm quickly locates the set ùêµ ùëñ that maximizes the similarity measure. For the case where all sets are singleton sets, essentially each is a single vector, there are known eÔ¨Écient approximate search algorithms, e.g., approximated versions of tree search algorithms, locality-sensitive hashing (LSH), vector quantization (VQ) and proximity graph algorithms. In this work, we present approximate search algorithms for the general case. The underlying idea in these algorithms is encoding a set of vectors via a ‚Äúlong‚Äù single vector.

2021: SURF: Optimized Data Distribution Technology
Abstract: None

2021: ML Based Lineage in Databases
Abstract: We track the lineage of tuples throughout their database lifetime. That is, we consider a scenario in which tuples (records) that are produced by a query may affect other tuple insertions into the DB, as part of a normal workflow. As time goes on, exact provenance explanations for such tuples become deeply nested, increasingly consuming space, and resulting in decreased clarity and readability. We present a novel approach for approximating lineage tracking, using a Machine Learning (ML) and Natural Language Processing (NLP) technique; namely, word embedding. The basic idea is summarizing (and approximating) the lineage of each tuple via a small set of constant-size vectors (the number of vectors per-tuple is a hyperparameter). Therefore, our solution does not suffer from space complexity blow-up over time, and it"naturally ranks"explanations to the existence of a tuple. We devise an alternative and improved lineage tracking mechanism, that of keeping track of and querying lineage at the column level; thereby, we manage to better distinguish between the provenance features and the textual characteristics of a tuple. We integrate our lineage computations into the PostgreSQL system via an extension (ProvSQL) and extensive experiments exhibit useful results in terms of accuracy against exact, semiring-based, justifications, especially for the column-based (CV) method which exhibits high precision and high per-level recall. In the experiments, we focus on tuples with \textit{multiple generations} of tuples in their lifelong lineage and analyze them in terms of direct and distant lineage.

2021: The SURF System for Continuous Data and Applications Placement Across Clouds
Abstract: None

2020: Machine Learning of SQL Queries Containment Rate and Result Cardinality
Abstract: 1

2020: Exploiting Latent Information in Databases via Database Embedding: technology, applications, ethics
Abstract: We are witnessing the emergence of AI-powered database systems, embedding AI-ideas and techniques in query processors, concurrency controllers, and more. We aim at improving relational querying, as well as other functionalities, by introducing another layer of data, word vectors, into traditional database systems. Word vectors originate in Natural Language Processing (NLP) where they are used to represent words in a language. In NLP, there are a number of methods for obtaining word vectors from text, we use a variation of one of these methods, word2vec. The idea in a nutshell is as follows: we produce text from a relation (or a view thereof) and then use this text to generate a model, i.e., a set of vectors, for all terms in the database. Once the model is available, we can formulate Cognitive Intelligence (CI) queries. These queries may be realized by SQL queries, enhanced by User Defined Functions (UDFs) that take advantage of the model to formulate conditions that were previously practically not expressible in SQL.

2020: ML Based Provenance in Databases
Abstract: None

2020: NN-based Transformation of Any SQL Cardinality Estimator for Handling DISTINCT, AND, OR and NOT
Abstract: SQL queries, with the AND, OR, and NOT operators, constitute a broad class of highly used queries. Thus, their cardinality estimation is important for query optimization. In addition, a query planner requires the set-theoretic cardinality (i.e., without duplicates) for queries with DISTINCT as well as in planning; for example, when considering sorting options. Yet, despite the importance of estimating query cardinalities in the presence of DISTINCT, AND, OR, and NOT, many cardinality estimation methods are limited to estimating cardinalities of only conjunctive queries with duplicates counted. 
The focus of this work is on two methods for handling this deficiency that can be applied to any limited cardinality estimation model. First, we describe a specialized deep learning scheme, PUNQ, which is tailored to representing conjunctive SQL queries and predicting the percentage of unique rows in the query's result with duplicate rows. Using the predicted percentages obtained via PUNQ, we are able to transform any cardinality estimation method that only estimates for conjunctive queries, and which estimates cardinalities with duplicates (e.g., MSCN), to a method that estimates queries cardinalities without duplicates. This enables estimating cardinalities of queries with the DISTINCT keyword. In addition, we describe a recursive algorithm, GenCrd, for extending any cardinality estimation method M that only handles conjunctive queries to one that estimates cardinalities for more general queries (that include AND, OR, and NOT), without changing the method M itself. 
Our evaluation is carried out on a challenging, real-world database with general queries that include either the DISTINCT keyword or the AND, OR, and NOT operators. Experimentally, we show that the proposed methods obtain accurate cardinality estimates with the same level of accuracy as that of the original transformed methods.

2019: Exploiting Latent Information in Relational Databases via Word Embedding and Application to Degrees of Disclosure
Abstract: Cognitive Databases is a new approach for enabling Artificial Intelligence (AI) capabilities as standard features within relational data-base systems. Relations are textified and the text is used to build a Word Embedding (WE) model that captures the latent relationships between database tokens of various data types. For each database token, the model includes a low dimensional vector (say, 200) that encodes the token‚Äôs relationships with other tokens. The vectors are used in the existing SQL query infrastructure via UDFs. Queries use the model vectors to express semantic similarity/dissimilarity, inductive reasoning, analogies and seamlessly utilize knowledge from external sources such as Wikipedia and PubMed. WE enables novel capabilities such as the controlled disclosure of database information in a variety of ways. The degree of disclosure may depend on the sensitivity of the information and the recipient‚Äôs need to know, e.g., test results may be considered sensitive and should be only be openly disclosed to divisions concerned with them. Disclosure may be viewed as a new kind of controlled sharing of information for cooperation and integration purposes. There are some challenges in integrating WE methods into the database engine, necessitating new techniques. There are also interesting theoretical problems concerning the WE coding power.

2019: Improved Cardinality Estimation by Learning Queries Containment Rates
Abstract: The containment rate of query Q1 in query Q2 over database D is the percentage of Q1's result tuples over D that are also in Q2's result over D. We directly estimate containment rates between pairs of queries over a specific database. For this, we use a specialized deep learning scheme, CRN, which is tailored to representing pairs of SQL queries. Result-cardinality estimation is a core component of query optimization. We describe a novel approach for estimating queries result-cardinalities using estimated containment rates among queries. This containment rate estimation may rely on CRN or embed, unchanged, known cardinality estimation methods. Experimentally, our novel approach for estimating cardinalities, using containment rates between queries, on a challenging real-world database, realizes significant improvements to state of the art cardinality estimation methods.

2019: Interactive 3D Visualization for Monitoring and Analysis of Geographical Traffic Data of Various Domains
Abstract: None

2019: Overview of the 2nd International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (aiDM'19)
Abstract: Recently, the Artificial Intelligence (AI) field has been experiencing a resurgence. AI broadly covers a wide swath of techniques which include logic-based approaches, probabilistic graphical models, and machine learning/deep learning approaches. Advances in hardware capabilities, such as Graphics Processing Units (GPUs), software components (e.g., accelerated libraries, programming frameworks), and systems infrastructures (e.g., GPU-enabled cloud providers) has led to a wide-spread adaptation of AI techniques to a variety of domains. Examples of such domains include image classification, autonomous driving, automatic speech recognition (ASR) and conversational systems (chatbots). AI techniques not only support multiple datatypes (e.g., free text, images, or speech), but are also available in various configurations, from personal devices to large-scale distributed systems.

