Recent papers for Tal Ayellet:

2024: Image-aware Evaluation of Generated Medical Reports
Abstract: The paper proposes a novel evaluation metric for automatic medical report generation from X-ray images, VLScore. It aims to overcome the limitations of existing evaluation methods, which either focus solely on textual similarities, ignoring clinical aspects, or concentrate only on a single clinical aspect, the pathology, neglecting all other factors. The key idea of our metric is to measure the similarity between radiology reports while considering the corresponding image. We demonstrate the benefit of our metric through evaluation on a dataset where radiologists marked errors in pairs of reports, showing notable alignment with radiologists' judgments. In addition, we provide a new dataset for evaluating metrics. This dataset includes well-designed perturbations that distinguish between significant modifications (e.g., removal of a diagnosis) and insignificant ones. It highlights the weaknesses in current evaluation metrics and provides a clear framework for analysis.

2024: MedCycle: Unpaired Medical Report Generation via Cycle-Consistency
Abstract: Generating medical reports for X-ray images presents a significant challenge, particularly in unpaired scenarios where access to paired image-report data for training is unavailable. Previous works have typically learned a joint embedding space for images and reports, necessitating a specific labeling schema for both. We introduce an innovative approach that eliminates the need for consistent labeling schemas, thereby enhancing data accessibility and enabling the use of incompatible datasets. This approach is based on cycle-consistent mapping functions that transform image embeddings into report embeddings, coupled with report auto-encoding for medical report generation. Our model and objectives consider intricate local details and the overarching semantic context within images and reports. This approach facilitates the learning of effective mapping functions, resulting in the generation of coherent reports. It outperforms state-of-the-art results in unpaired chest X-ray report generation, demonstrating improvements in both language and clinical metrics.

2024: MedRAT: Unpaired Medical Report Generation via Auxiliary Tasks
Abstract: Medical report generation from X-ray images is a challenging task, particularly in an unpaired setting where paired image-report data is unavailable for training. To address this challenge, we propose a novel model that leverages the available information in two distinct datasets, one comprising reports and the other consisting of images. The core idea of our model revolves around the notion that combining auto-encoding report generation with multi-modal (report-image) alignment can offer a solution. However, the challenge persists regarding how to achieve this alignment when pair correspondence is absent. Our proposed solution involves the use of auxiliary tasks, particularly contrastive learning and classification, to position related images and reports in close proximity to each other. This approach differs from previous methods that rely on pre-processing steps, such as using external information stored in a knowledge graph. Our model, named MedRAT, surpasses previous state-of-the-art methods, demonstrating the feasibility of generating comprehensive medical reports without the need for paired data or external tools.

2023: Fully-attentive iterative networks for region-based controllable image and video captioning
Abstract: None

2023: LIMITR: Leveraging Local Information for Medical Image-Text Representation
Abstract: Medical imaging analysis plays a critical role in the diagnosis and treatment of various medical conditions. This paper focuses on chest X-ray images and their corresponding radiological reports. It presents a new model that learns a joint X-ray image & report representation. The model is based on a novel alignment scheme between the visual data and the text, which takes into account both local and global information. Furthermore, the model integrates domain-specific information of two types—lateral images and the consistent visual structure of chest images. Our representation is shown to benefit three types of retrieval tasks: text-image retrieval, class-based retrieval, and phrase-grounding. Our code is publicly available1.

2023: PatchContrast: Self-Supervised Pre-training for 3D Object Detection
Abstract: Accurately detecting objects in the environment is a key challenge for autonomous vehicles. However, obtaining annotated data for detection is expensive and time-consuming. We introduce PatchContrast, a novel self-supervised point cloud pre-training framework for 3D object detection. We propose to utilize two levels of abstraction to learn discriminative representation from unlabeled data: proposal-level and patch-level. The proposal-level aims at localizing objects in relation to their surroundings, whereas the patch-level adds information about the internal connections between the object's components, hence distinguishing between different objects based on their individual components. We demonstrate how these levels can be integrated into self-supervised pre-training for various backbones to enhance the downstream 3D detection task. We show that our method outperforms existing state-of-the-art models on three commonly-used 3D detection datasets.

2023: A Game of Bundle Adjustment - Learning Efficient Convergence
Abstract: Bundle adjustment is the common way to solve localization and mapping. It is an iterative process in which a system of non-linear equations is solved using two optimization methods, weighted by a damping factor. In the classic approach, the latter is chosen heuristically by the Levenberg-Marquardt algorithm on each iteration. This might take many iterations, making the process computationally expensive, which might be harmful to real-time applications. We propose to replace this heuristic by viewing the problem in a holistic manner, as a game, and formulating it as a reinforcement-learning task. We set an environment which solves the non-linear equations and train an agent to choose the damping factor in a learned manner. We demonstrate that our approach considerably reduces the number of iterations required to reach the bundle adjustment’s convergence, on both synthetic and real-life scenarios. We show that this reduction benefits the classic approach and can be integrated with other bundle adjustment acceleration methods.

2023: k-NNN: Nearest Neighbors of Neighbors for Anomaly Detection
Abstract: Anomaly detection aims at identifying images that deviate significantly from the norm. We focus on algorithms that embed the normal training examples in space and, when given a test image, detect anomalies based on the features' distance to the k-nearest training neighbors. We propose a new operator that takes into account the varying structure & importance of the features in the embedding space. Interestingly, this is achieved by considering not only the nearest neighbors but also the neighbors of these neighbors (k-NNN). Our results demonstrate that by simply replacing the nearest neighbor component in existing algorithms with our k-NNN, while leaving the rest of the algorithms unchanged, the performance of each algorithm is improved. This holds true for both common homogeneous datasets, such as specific flowers, as well as for more diverse datasets.

2023: Differential effect of histone H3.3 depletion on retroviral repression in embryonic stem cells
Abstract: None

2022: ArcAid: Analysis of Archaeological Artifacts using Drawings
Abstract: Archaeology is an intriguing domain for computer vision. It suffers not only from shortage in (labeled) data, but also from highly-challenging data, which is often extremely abraded and damaged. This paper proposes a novel semi-supervised model for classification and retrieval of images of archaeological artifacts. This model utilizes unique data that exists in the domain—manual drawings made by special artists. These are used during training to implicitly transfer the domain knowledge from the drawings to their corresponding images, improving their classification results. We show that while learning how to classify, our model also learns how to generate drawings of the artifacts, an important documentation task, which is currently performed manually. Last but not least, we collected a new dataset of stamp-seals of the Southern Levant. Our code1 and dataset2 are publicly available.

2022: GraVoS: Voxel Selection for 3D Point-Cloud Detection
Abstract: 3D object detection within large 3D scenes is challenging not only due to the sparsity and irregularity of 3D point clouds, but also due to both the extreme foreground-background scene imbalance and class imbalance. A common approach is to add ground-truth objects from other scenes. Differently, we propose to modify the scenes by removing elements (voxels), rather than adding ones. Our approach selects the “meaningful” voxels, in a manner that addresses both types of dataset imbalance. The approach is general and can be applied to any voxel-based detector, yet the meaningfulness of a voxel is network-dependent. Our voxel selection is shown to improve the performance of several prominent 3D detection methods.

2022: Random Walks for Adversarial Meshes
Abstract: A polygonal mesh is the most-commonly used representation of surfaces in computer graphics. Therefore, it is not surprising that a number of mesh classification networks have recently been proposed. However, while adversarial attacks are wildly researched in 2D, the field of adversarial meshes is under explored. This paper proposes a novel, unified, and general adversarial attack, which leads to misclassification of several state-of-the-art mesh classification neural networks. Our attack approach is black-box, i.e. it has access only to the network’s predictions, but not to the network’s full architecture or gradients. The key idea is to train a network to imitate a given classification network. This is done by utilizing random walks along the mesh surface, which gather geometric information. These walks provide insight onto the regions of the mesh that are important for the correct prediction of the given classification network. These mesh regions are then modified more than other regions in order to attack the network in a manner that is barely visible to the naked eye.

2022: GraVoS: Gradient based Voxel Selection for 3D Detection
Abstract: 3D object detection within large 3D scenes is challenging not only due to the sparse and irregular 3D point clouds, but also due to the extreme foreground-background imbalance in the scene and class imbalance. A common approach is to add ground-truth objects from other scenes. Differently, we propose to modify the scenes by removing elements (voxels), rather than adding ones. Our approach selects the "meaningful" voxels, in a manner that addresses both types dataset imbalance. The approach is general and can be applied to any voxel-based detector, yet the meaningfulness of a voxel is network-dependent. Our voxel selection is shown to improve the performance of several prominent 3D detection methods.

2021: CloudWalker: 3D Point Cloud Learning by Random Walks for Shape Analysis
Abstract: Point clouds are gaining prominence as a method for representing 3D shapes, but its irregular structure poses a challenge for deep learning methods. In this paper we pro-pose CloudWalker, a novel method for learning 3D shapes using random walks. Previous works attempt to adapt Convolutional Neural Networks (CNNS) or impose a grid or mesh structure to 3D point clouds. This work presents a different approach to represent and learn the shape from a given point set. The key idea is to impose structure on the point set by multiple random walks through the cloud for exploring different regions of the 3D object. Then we learn a per-point and per-walk representation and aggregate multiple walk predictions at inference. Our approach achieves state-of-the-art results for two 3D shape analysis tasks: classiﬁcation and retrieval. Furthermore, we pro-pose a shape complexity indicator function that uses cross-walk and inter-walk variance measures to subdivide the shape space.

2021: AttWalk: Attentive Cross-Walks for Deep Mesh Analysis
Abstract: Mesh representation by random walks has been shown to benefit deep learning. Randomness is indeed a powerful concept. However, it comes with a price—some walks might wander around non-characteristic regions of the mesh, which might be harmful to shape analysis, especially when only a few walks are utilized. We propose a novel walk-attention mechanism that leverages the fact that multiple walks are used for a single mesh representation. The key idea is that the walks may provide each other with information regarding the meaningful (attentive) features of the mesh. We utilize this mutual information to extract a single descriptor of the mesh. This differs from common attention mechanisms that use attention to improve the representation of each individual descriptor. Our approach achieves SOTA results for two basic 3D shape analysis tasks: classification and retrieval. Even a handful of walks along a mesh suffice for learning. Furthermore, our approach provides insight into mesh importance detection.

2021: CloudWalker: Random walks for 3D point cloud shape analysis
Abstract: None

2021: Visual Navigation with Spatial Attention
Abstract: This work focuses on object goal visual navigation, aiming at finding the location of an object from a given class, where in each step the agent is provided with an egocentric RGB image of the scene. We propose to learn the agent’s policy using a reinforcement learning algorithm. Our key contribution is a novel attention probability model for visual navigation tasks. This attention encodes semantic information about observed objects, as well as spatial information about their place. This combination of the "what" and the "where" allows the agent to navigate toward the sought-after object effectively. The attention model is shown to improve the agent’s policy and to achieve state-of-the-art results on commonly-used datasets.

2020: MeshWalker
Abstract: Most attempts to represent 3D shapes for deep learning have focused on volumetric grids, multi-view images and point clouds. In this paper we look at the most popular representation of 3D shapes in computer graphics---a triangular mesh---and ask how it can be utilized within deep learning. The few attempts to answer this question propose to adapt convolutions & pooling to suit Convolutional Neural Networks (CNNs). This paper proposes a very different approach, termed MeshWalker to learn the shape directly from a given mesh. The key idea is to represent the mesh by random walks along the surface, which "explore" the mesh's geometry and topology. Each walk is organized as a list of vertices, which in some manner imposes regularity on the mesh. The walk is fed into a Recurrent Neural Network (RNN) that "remembers" the history of the walk. We show that our approach achieves state-of-the-art results for two fundamental shape analysis tasks: shape classification and semantic segmentation. Furthermore, even a very small number of examples suffices for learning. This is highly important, since large datasets of meshes are difficult to acquire.

2020: Trim24 and Trim33 Play a Role in Epigenetic Silencing of Retroviruses in Embryonic Stem Cells
Abstract: Embryonic stem cells (ESC) have the ability to epigenetically silence endogenous and exogenous retroviral sequences. Trim28 plays an important role in establishing this silencing, but less is known about the role other Trim proteins play. The Tif1 family is a sub-group of the Trim family, which possess histone binding ability in addition to the distinctive RING domain. Here, we have examined the interaction between three Tif1 family members, namely Trim24, Trim28 and Trim33, and their function in retroviral silencing. We identify a complex formed in ESC, comprised of these three proteins. We further show that when Trim33 is depleted, the complex collapses and silencing efficiency of both endogenous and exogenous sequences is reduced. Similar transcriptional activation takes place when Trim24 is depleted. Analysis of the H3K9me3 chromatin modification showed a decrease in this repressive mark, following both Trim24 and Trim33 depletion. As Trim28 is an identified binding partner of the H3K9 methyltransferase ESET, this further supports the involvement of Trim28 in the complex. The results presented here suggest that a complex of Tif1 family members, each of which possesses different specificity and efficiency, contributes to the silencing of retroviral sequences in ESC.

2020: Area Chairs
Abstract: Aaron Hertzmann, Adobe Adriana Kovashka, University of Pittsburgh Ajay Kumar, The Hong Kong Polytechnic University Aleix Martinez, The Ohio State University Aleš Leonardis, University of Birmingham Alessio Del Bue, Italian Institute of Technology (IIT) Alex Schwing, University of Illinois at Urbana-Champaign Alexander Toshev, Google Alexandre Alahi, EPFL Alexey Dosovitskiy, Google Ali Farhadi, University of Washington Amir Zamir, Stanford & EPFL Amit K. Roy-Chowdhury, University of California, Riverside Andreas Geiger, MPI-IS and University of Tuebingen Andrew Davison, Imperial College London Angel Chang, Simon Fraser University Angjoo Kanazawa, University of California Berkeley Anthony Hoogs, Kitware Antoni Chan, City University of Hong Kong, Hong, Kong Anurag Mittal, Indian Institute of Technology Madras Ayellet Tal, Technion Bastian Leibe, RWTH Aachen University Bjorn Ommer, Heidelberg University Boqing Gong, Google / ICSI Berkeley Bryan Russell, Adobe Research C.V. Jawahar, IIIT-Hyderabad Carl Olsson, Lund University, Sweden Carl Vondrick, Columbia University Caroline Pantofaru, Google Cewu Lu, Shanghai Jiao Tong University Charless Fowlkes, UC Irvine Chen Sun, Google Christian Wolf, INSA Lyon, France Christopher Pal, École Polytechnique de Montréal Cornelia Fermuller, University of Maryland, College Park Daphna Weinshall, Hebrew University David Forsyth, University of Illinois Urbana-Champaign David Fouhey, University of Michigan David Jacobs, University of Maryland David Wipf, Microsoft Research Deqing Sun, Google Derek Hoiem, University of Illinois at Urbana-Champaign Deva Ramanan, Carnegie Mellon University Diane Larlus, Naver Labs Europe Dilip Krishnan, Google

