Recent papers for David Azriel:

2024: The Pairwise Matching Design is Optimal under Extreme Noise and Assignments
Abstract: We consider the general performance of the difference-in-means estimator in an equally-allocated two-arm randomized experiment under common experimental endpoints such as continuous (regression), incidence, proportion, count and uncensored survival. We consider two sources of randomness: the subject-specific assignments and the contribution of unobserved subject-specific measurements. We then examine mean squared error (MSE) performance under a new, more realistic"simultaneous tail criterion". We prove that the pairwise matching design of Greevy et al. (2004) performs best asymptotically under this criterion when compared to other blocking designs. We also prove that the optimal design must be less random than complete randomization and more random than any deterministic, optimized allocation. Theoretical results are supported by simulations in all five response types.

2024: Surgery Duration Prediction Using Multi-Task Feature Selection
Abstract: Efficient optimization of operating room (OR) activity poses a significant challenge for hospital managers due to the complex and risky nature of the environment. The traditional “one size fits all” approach to OR scheduling is no longer practical, and personalized medicine is required to meet the diverse needs of patients, care providers, medical procedures, and system constraints within limited resources. This paper aims to introduce a scientific and practical tool for predicting surgery durations and improving OR performance for maximum benefit to patients and the hospital. Previous works used machine-learning models for surgery duration prediction based on preoperative data. The models consider covariates known to the medical staff at the time of scheduling the surgery. Given a large number of covariates, model selection becomes crucial, and the number of covariates used for prediction depends on the available sample size. Our proposed approach utilizes multi-task regression to select a common subset of predicting covariates for all tasks with the same sample size while allowing the model's coefficients to vary between them. A regression task can refer to a single surgeon or operation type or the interaction between them. By considering these diverse factors, our method provides an overall more accurate estimation of the surgery durations, and the selected covariates that enter the model may help to identify the resources required for a specific surgery. We found that when the regression tasks were surgeon-based or based on the pair of operation type and surgeon, our suggested approach outperformed the compared baseline suggested in a previous study. However, our approach failed to reach the baseline for an operation-type-based task. By accurately estimating surgery durations, hospital managers can provide care to a greater number of patients, optimize resource allocation and utilization, and reduce waste. This research contributes to the advancement of personalized medicine and provides a valuable tool for improving operational efficiency in the dynamic world of medicine.

2023: Optimal confidence interval for the difference of proportions
Abstract: Estimating the probability of the binomial distribution is a basic problem, which appears in almost all introductory statistics courses and is performed frequently in various studies. In some cases, the parameter of interest is a difference between two probabilities, and the current work studies the construction of confidence intervals for this parameter when the sample size is small. Our goal is to find the shortest confidence intervals under the constraint of coverage probability being larger than a predetermined level. For the two-sample case, there is no known algorithm that achieves this goal, but different heuristics procedures have been suggested, and the present work aims at finding optimal confidence intervals. In the one-sample case, there is a known algorithm that finds optimal confidence intervals presented by Blyth and Still (1983). It is based on solving small and local optimization problems and then using an inversion step to find the global optimum solution. We show that this approach fails in the two-sample case and therefore, in order to find optimal confidence intervals, one needs to solve a global optimization problem, rather than small and local ones, which is computationally much harder. We present and discuss the suitable global optimization problem. Using the Gurobi package we find near-optimal solutions when the sample sizes are smaller than 15, and we compare these solutions to some existing methods, both approximate and exact. We find that the improvement in terms of lengths with respect to the best competitor varies between 1.5% and 5% for different parameters of the problem. Therefore, we recommend the use of the new confidence intervals when both sample sizes are smaller than 15. Tables of the confidence intervals are given in the Excel file in this link.

2023: Functional Benefit and Orthotic Effect of Dorsiflexion-FES in Children with Hemiplegic Cerebral Palsy
Abstract: Functional electrical stimulation of the ankle dorsiflexor (DF-FES) may have advantages over ankle foot orthoses (AFOs) in managing pediatric cerebral palsy (CP). This study assessed the functional benefit and orthotic effect of DF-FES in children with hemiplegic CP. We conducted an open-label prospective study on children with hemiplegic CP ≥ 6 years who used DF-FES for five months. The functional benefit was assessed by repeated motor function tests and the measurement of ankle biomechanical parameters. Kinematic and spatiotemporal parameters were assessed by gait analysis after one and five months. The orthotic effect was defined by dorsiflexion ≥ 0° with DF-FES at either the mid or terminal swing. Among 26 eligible patients, 15 (median age 8.2 years, range 6–15.6) completed the study. After five months of DF-FES use, the results on the Community Balance and Mobility Scale improved, and the distance in the Six-Minute Walk Test decreased (six-point median difference, 95% CI (1.89, 8.1), –30 m, 95% CI (−83.67, −2.6), respectively, p < 0.05) compared to baseline. No significant changes were seen in biomechanical and kinematic parameters. Twelve patients (80%) who showed an orthotic effect at the final gait analysis experienced more supported walking over time, with a trend toward slower walking. We conclude that the continuous use of DF–FES increases postural control and may cause slower but more controlled gait.

2023: Optimal confidence interval for the difference between proportions
Abstract: None

2022: The Optimality of Blocking Designs in Equally and Unequally Allocated Randomized Experiments with General Response
Abstract: We consider the performance of the difference-in-means estimator in a two-arm randomized experiment under common experimental endpoints such as continuous (regression), incidence, proportion and survival. We examine performance under both equal and unequal allocation to treatment groups and we consider both the Neyman randomization model and the population model. We show that in the Neyman model, where the only source of randomness is the treatment manipulation, there is no free lunch: complete randomization is minimax for the estimator's mean squared error. In the population model, where each subject experiences response noise with zero mean, the optimal design is the deterministic perfect-balance allocation. However, this allocation is generally NP-hard to compute and moreover, depends on unknown response parameters. When considering the tail criterion of Kapelner et al. (2021), we show the optimal design is less random than complete randomization and more random than the deterministic perfect-balance allocation. We prove that Fisher's blocking design provides the asymptotically optimal degree of experimental randomness. Theoretical results are supported by simulations in all considered experimental settings.

2022: The role of pairwise matching in experimental design for an incidence outcome
Abstract: We consider the problem of evaluating designs for a two‐arm randomised experiment with an incidence (binary) outcome under a non‐parametric general response model. Our two main results are that the a priori pair matching design is (1) the optimal design as measured by mean squared error among all block designs which includes complete randomisation. And (2), this pair‐matching design is minimax, that is, it provides the lowest mean squared error under an adversarial response model. Theoretical results are supported by simulations and clinical trial data where we demonstrate the superior performance of pairwise matching designs under realistic conditions.

2022: A zero-estimator approach for estimating the signal level in a high-dimensional model-free setting
Abstract: None

2022: Empirical Bayes approach to Truth Discovery problems
Abstract: When aggregating information from conflicting sources, one's goal is to find the truth. Most real-value \emph{truth discovery} (TD) algorithms try to achieve this goal by estimating the competence of each source and then aggregating the conflicting information by weighing each source's answer proportionally to her competence. However, each of those algorithms requires more than a single source for such estimation and usually does not consider different estimation methods other than a weighted mean. Therefore, in this work we formulate, prove, and empirically test the conditions for an Empirical Bayes Estimator (EBE) to dominate the weighted mean aggregation. Our main result demonstrates that EBE, under mild conditions, can be used as a second step of any TD algorithm in order to reduce the expected error.

2022: Design choices in randomization tests that affect power
Abstract: Abstract We consider the problem of evaluating designs for a small-sample two-arm randomized experiment using the power of the one-sided randomization test as a criterion. Our evaluation assumes a linear response in one observed covariate, an unobserved component and an additive treatment effect where the model's randomness is due to different treatment allocations. It is well-known that the power depends on the allocations’ imbalance in the observed covariate. We show that power is additionally affected by two other design choices: the number of allocations and the degree of the allocations’ dependence. We prove that the more allocations, the higher the power and the lower the variability in power. Our theoretical findings and simulation studies show that the designs with the highest power provide thousands of highly independent allocations each providing nominal imbalance in the observed covariates. These high-powered designs exhibit less randomness than complete randomization and more randomness than recently proposed designs that employ numerical optimization. This advantage of high power is easily accessible to practicing experimenters via the popular rerandomization design and a greedy pair switching design, where both outperform complete randomization and numerical optimization. The tradeoff we find also provides a means to specify rerandomization’s imbalance threshold parameter.

2021: Optimal rerandomization designs via a criterion that provides insurance against failed experiments
Abstract: None

2021: Improved estimators for semi-supervised high-dimensional regression model
Abstract: We study a linear high-dimensional regression model in a semi-supervised setting, where for many observations only the vector of covariates $X$ is given with no response $Y$. We do not make any sparsity assumptions on the vector of coefficients, and aim at estimating $\mathrm{Var}(Y|X)$. We propose an estimator, which is unbiased, consistent, and asymptotically normal. This estimator can be improved by adding zero-estimators arising from the unlabelled data. Adding zero-estimators does not affect the bias and potentially can reduce variance. In order to achieve optimal improvement, many zero-estimators should be used, but this raises the problem of estimating many parameters. Therefore, we introduce covariate selection algorithms that identify which zero-estimators should be used in order to improve the above estimator. We further illustrate our approach for other estimators, and present an algorithm that improves estimation for any given variance estimator. Our theoretical results are demonstrated in a simulation study.

2021: Optimal minimax random designs for weighted least squares estimators
Abstract: 
 This work studies an experimental design problem where the values of a predictor variable, denoted by x, are to be determined with the goal of estimating a function m(x), which is observed with noise. A linear model is fitted to m(x) but it is not assumed that the model is correctly specified. It follows that the quantity of interest is the best linear approximation of m(x), which is denoted by ℓ(x). It is shown that in this framework the ordinary least squares estimator typically leads to an inconsistent estimation of ℓ(x), and rather weighted least squares should be considered. An asymptotic minimax criterion is formulated for this estimator, and a design that minimizes the criterion is constructed. An important feature of this problem is that the xs should be random, rather than fixed. Otherwise, the minimax risk is infinite. It is shown that the optimal random minimax design is different from its deterministic counterpart, which was studied previously, and a simulation study indicates that it generally performs better when m(x) is a quadratic or a cubic function. Another finding is that when the variance of the noise goes to infinity, the random and deterministic minimax designs coincide. The results are illustrated for polynomial regression models and a generalization is given in the Supplementary Material.

2021: Optimal designs for the development of personalized treatment rules
Abstract: We study the design of multi‐armed parallel group clinical trials to estimate personalized treatment rules that identify the best treatment for a given patient with given covariates. Assuming that the outcomes in each treatment arm are given by a homoscedastic linear model, with possibly different variances between treatment arms, and that the trial subjects form a random sample from an unselected overall population, we optimize the (possibly randomized) treatment allocation allowing the allocation rates to depend on the covariates. We find that, for the case of two treatments, the approximately optimal allocation rule does not depend on the value of the covariates but only on the variances of the responses. In contrast, for the case of three treatments or more, the optimal treatment allocation does depend on the values of the covariates as well as the true regression coefficients. The methods are illustrated with a recently published dietary clinical trial.

2020: Estimation of linear projections of non-sparse coefficients in high-dimensional regression
Abstract: : In this work we study estimation of signals when the number of parameters is much larger than the number of observations. A large body of literature assumes for these kind of problems a sparse structure where most of the parameters are zero or close to zero. When this assumption does not hold, one can focus on low-dimensional functions of the parameter vector. In this work we study one-dimensional linear projections. Speciﬁ-cally, in the context of high-dimensional linear regression, the parameter of interest is β and we study estimation of a T β . We show that a T ˆ β , where ˆ β is the least squares estimator, using pseudo-inverse when p > n , is minimax and admissible. Thus, for linear projections no regularization or shrinkage is needed. This estimator is easy to analyze and conﬁdence intervals can be constructed. We study a high-dimensional dataset from brain imaging where it is shown that the signal is weak, non-sparse and signiﬁcantly dif- ferent from zero.

2020: Optimal selection of a common subset of covariates for different regressions.
Abstract: Given a regression dataset of size $n$, most of the classical model selection literature treats the problem of selecting a subset of covariates to be used for prediction of future responses. In this paper we assume that a sample of $\cal J$ regression datasets of different sizes from a population of datasets having the same set of covariates and responses is observed. The goal is to select, for each $n$, a single subset of covariates to be used for prediction of future responses for any dataset of size $n$ from the population (which may or may not be in the sample of datasets). The regression coefficients used in the prediction are estimated using the $n$ observations consisting of covariates and responses in the sample for which prediction of future responses is to be done, and thus they differ across different samples. For example, if the response is a diagnosis, and the covariates are medical background variables and measurements, the goal is to select a standard set of measurements for different clinics, say, where each clinic may estimate and use its own coefficients for prediction (depending on local conditions, prevalence, etc.). The selected subset naturally depends on the sample size $n$, with a larger sample size allowing a more elaborate model. Since we consider prediction for any (or a randomly chosen) dataset in the population, it is natural to consider random covariates. If the population consists of datasets that are similar, our approach amounts to borrowing information, leading to a subset selection that is efficient for prediction. On the other hand, if the datasets are dissimilar, then our goal is to find a "compromise" subset of covariates for the different regressions.

2020: Better experimental design by hybridizing binary matching with imbalance optimization
Abstract: We present a new experimental design procedure that divides a set of experimental units into two groups in order to minimize error in estimating a treatment effect. One concern is the elimination of large covariate imbalance between the two groups before the experiment begins. Another concern is robustness of the design to misspecification in response models. We address both concerns in our proposed design: we first place subjects into pairs using optimal nonbipartite matching, making our estimator robust to complicated nonlinear response models. Our innovation is to keep the matched pairs extant, take differences of the covariate values within each matched pair, and then use the greedy switching heuristic of Krieger et al. (2019) or rerandomization on these differences. This latter step greatly reduces covariate imbalance. Furthermore, our resultant designs are shown to be nearly as random as matching, which is robust to unobserved covariates. When compared to previous designs, our approach exhibits significant improvement in the mean squared error of the treatment effect estimator when the response model is nonlinear and performs at least as well when the response model is linear. Our design procedure can be found as a method in the open source R package available on CRAN called GreedyExperimentalDesign.

2020: Optimal selection of sample-size dependent common subsets of covariates for multi-task regression prediction
Abstract: An analyst is given a training set consisting of regression datasets $D_j$ of different sizes, which are distributed according to some $G_j$, $j=1,\ldots,\cal J$, where the distributions $G_j$ are assumed to form a random sample generated by some common source. In particular, the $D_j$'s have a common set of covariates and they are all labeled. The training set is used by the analyst for selection of subsets of covariates denoted by ${P}^*(n)$, whose role is described next. The multi-task problem we consider is as follows: given a number of random labeled datasets (which may be in the training set or not) $D_{J_k}$ of size $n_k$, $k=1,\ldots,K$, estimate separately for each dataset the regression coefficients on the subset of covariates ${P}^*(n_k)$ and then predict future dependent variables given their covariates. Naturally, a large sample size $n_k$ of $D_{J_k}$ allows a larger subset of covariates, and the dependence of the size of the selected covariate subsets on $n_k$ is needed in order to achieve good prediction and avoid overfitting. Subset selection is notoriously difficult and computationally demanding, and requires large samples; using all the regression datasets in the training set together amounts to borrowing strength toward better selection under suitable assumptions. Furthermore, using common subsets for all regressions having a given sample size standardizes and simplifies the data collection and avoids having to select and use a different subset for each prediction task. Our approach is efficient when the relevant covariates for prediction are common to the different regressions, while the models' coefficients may vary between different regressions.

2020: Harmonizing Optimized Designs With Classic Randomization in Experiments
Abstract: Abstract There is a long debate in experimental design between the classic randomization design of Fisher, Yates, Kempthorne, Cochran, and those who advocate deterministic assignments based on notions of optimality. In nonsequential trials comparing treatment and control, covariate measurements for each subject are known in advance, and subjects can be divided into two groups based on a criterion of imbalance. With the advent of modern computing, this partition can be made nearly perfectly balanced via numerical optimization, but these allocations are far from random. These perfect allocations may endanger estimation relative to classic randomization because unseen subject-specific characteristics can be highly imbalanced. To demonstrate this, we consider different performance criterions such as Efron’s worst-case analysis and our original tail criterion of mean squared error. Under our tail criterion for the differences-in-mean estimator, we prove asymptotically that the optimal design must be more random than perfect balance but less random than completely random. Our result vindicates restricted designs that are used regularly such as blocking and rerandomization. For a covariate-adjusted estimator, balancing offers less rewards and it seems good performance is achievable with complete randomization. Further work will provide a procedure to find the explicit optimal design in different scenarios in practice. Supplementary materials for this article are available online.

2020: Improving the Power of the Randomization Test
Abstract: We consider the problem of evaluating designs for a two-arm randomized experiment with the criterion being the power of the randomization test for the one-sided null hypothesis. Our evaluation assumes a response that is linear in one observed covariate, an unobserved component and an additive treatment effect where the only randomness comes from the treatment allocations. It is well-known that the power depends on the allocations' imbalance in the observed covariate and this is the reason for the classic restricted designs such as rerandomization. We show that power is also affected by two other design choices: the number of allocations in the design and the degree of linear dependence among the allocations. We prove that the more allocations, the higher the power and the lower the variability in the power. Designs that feature greater independence of allocations are also shown to have higher performance. 
Our theoretical findings and extensive simulation studies imply that the designs with the highest power provide thousands of highly independent allocations that each provide nominal imbalance in the observed covariates. These high powered designs exhibit less randomization than complete randomization and more randomization than recently proposed designs based on numerical optimization. Model choices for a practicing experimenter are rerandomization and greedy pair switching, where both outperform complete randomization and numerical optimization. The tradeoff we find also provides a means to specify the imbalance threshold parameter when rerandomizing.

