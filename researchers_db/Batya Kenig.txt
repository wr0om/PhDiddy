2024: Enumeration of Minimal Hitting Sets Parameterized by Treewidth
Abstract: Enumerating the minimal hitting sets of a hypergraph is a problem which arises in many data management applications that include constraint mining, discovering unique column combinations, and enumerating database repairs. Previously, Eiter et al. showed that the minimal hitting sets of an $n$-vertex hypergraph, with treewidth $w$, can be enumerated with delay $O^*(n^{w})$ (ignoring polynomial factors), with space requirements that scale with the output size. We improve this to fixed-parameter-linear delay, following an FPT preprocessing phase. The memory consumption of our algorithm is exponential with respect to the treewidth of the hypergraph.

2023: Listing Small Minimal $s,t$-separators in FPT-Delay
Abstract: Let $G$ be an undirected graph, and $s,t$ distinguished vertices of $G$. A minimal $s,t$-separator is an inclusion-wise minimal vertex-set whose removal places $s$ and $t$ in distinct connected components. We present an algorithm for listing the minimal $s,t$-separators of a graph, whose cardinality is at most $k$, with FPT-delay, where the parameter depends only on $k$. This problem finds applications in various algorithms parameterized by treewidth, which include query evaluation in relational databases, probabilistic inference, and many more. We also present a simple algorithm that enumerates all of the (not necessarily minimal) $s,t$-separators of a graph in ranked order by size.

2023: Ranked Enumeration of Minimal Separators
Abstract: Let G be an undirected graph, and s, t distinguished vertices of G . A minimal s, t -separator is an inclusion-wise minimal vertex-set whose removal places s and t in distinct connected components. We present an algorithm for listing the minimal s, t -separators of a graph in non-decreasing order of cardinality, in polynomial-delay. This problem finds applications in various algorithms parameterized by treewidth, which include query evaluation in relational databases, probabilistic inference, and many more. In the process, we prove several results that are of independent interest. We establish a new island of tractability to the intensively studied 2-disjoint connected subgraphs problem [43], which is NP-complete even for restricted graph classes that include planar graphs [21], and prove new characterizations of minimal s, t -separators. Ours is the first to present a ranked enumeration algorithm for minimal separators where the delay is polynomial in the size of the input graph. 2012 ACM Subject Classification

2023: Approximate Implication for Probabilistic Graphical Models
Abstract: The graphical structure of Probabilistic Graphical Models (PGMs) represents the conditional independence (CI) relations that hold in the modeled distribution. Every separator in the graph represents a conditional independence relation in the distribution, making them the vehicle through which new conditional independencies are inferred and verified. The notion of separation in graphs depends on whether the graph is directed (i.e., a Bayesian Network), or undirected (i.e., a Markov Network). The premise of all current systems-of-inference for deriving CIs in PGMs, is that the set of CIs used for the construction of the PGM hold exactly. In practice, algorithms for extracting the structure of PGMs from data discover approximate CIs that do not hold exactly in the distribution. In this paper, we ask how the error in this set propagates to the inferred CIs read off the graphical structure. More precisely, what guarantee can we provide on the inferred CI when the set of CIs that entailed it hold only approximately? It has recently been shown that in the general case, no such guarantee can be provided. In this work, we prove new negative and positive results concerning this problem. We prove that separators in undirected PGMs do not necessarily represent approximate CIs. That is, no guarantee can be provided for CIs inferred from the structure of undirected graphs. We prove that such a guarantee exists for the set of CIs inferred in directed graphical models, making the $d$-separation algorithm a sound and complete system for inferring approximate CIs. We also establish improved approximation guarantees for independence relations derived from marginal and saturated CIs.

2022: Quantifying the Loss of Acyclic Join Dependencies
Abstract: Acyclic schemes posses known benefits for database design, speeding up queries, and reducing space requirements. An acyclic join dependency (AJD) is lossless with respect to a universal relation if joining the projections associated with the schema results in the original universal relation. An intuitive and standard measure of loss entailed by an AJD is the number of redundant tuples generated by the acyclic join. Recent work has shown that the loss of an AJD can also be characterized by an information-theoretic measure. Motivated by the problem of automatically fitting an acyclic schema to a universal relation, we investigate the connection between these two characterizations of loss. We first show that the loss of an AJD is captured using the notion of KL-Divergence. We then show that the KL-divergence can be used to bound the number of redundant tuples. We prove a deterministic lower bound on the percentage of redundant tuples. For an upper bound, we propose a random database model, and establish a high probability bound on the percentage of redundant tuples, which coincides with the lower bound for large databases.

2021: Enumerating Minimal Separators in Ranked Order
Abstract: Let G be an n-vertex graph, and s, t vertices of G. We present an efficient algorithm which enumerates the set of minimal st-separators of G in ascending order of cardinality, with a delay of O(n3.5) per separator. In particular, we present an algorithm that lists, in ascending order of cardinality, all minimal separators with at most k vertices. In that case, we show that the delay of the enumeration algorithm is O(kn2.5) per separator. Our process is based on a new method that can decide, in polynomial time, whether the set of minimal separators under certain inclusion, exclusion, and cardinality constraints is empty. 2012 ACM Subject Classification

2021: Approximate Implication with d-Separation
Abstract: The graphical structure of Probabilistic Graphical Models (PGMs) encodes the conditional independence (CI) relations that hold in the modeled distribution. Graph algorithms, such as d-separation, use this structure to infer additional conditional independencies, and to query whether a specific CI holds in the distribution. The premise of all current systems-of-inference for deriving CIs in PGMs, is that the set of CIs used for the construction of the PGM hold exactly. In practice, algorithms for extracting the structure of PGMs from data, discover approximate CIs that do not hold exactly in the distribution. In this paper, we ask how the error in this set propagates to the inferred CIs read off the graphical structure. More precisely, what guarantee can we provide on the inferred CI when the set of CIs that entailed it hold only approximately? It has recently been shown that in the general case, no such guarantee can be provided. We prove that such a guarantee exists for the set of CIs inferred in directed graphical models, making the d-separation algorithm a sound and complete system for inferring approximate CIs. We also prove an approximation guarantee for independence relations derived from marginal CIs.

2020: A Dichotomy for the Generalized Model Counting Problem for Unions of Conjunctive Queries
Abstract: We study the \em generalized model counting problem, defined as follows: given a database, and a set of deterministic tuples, count the number of subsets of the database that include all deterministic tuples and satisfy the query. This problem is computationally equivalent to the evaluation of the query over a tuple-independent probabilistic database where all tuples have probabilities in $\set0,\frac1 2, 1 $. Previous work has established a dichotomy for Unions of Conjunctive Queries (UCQ) when the probabilities are arbitrary rational numbers, showing that, for each query, its complexity is either in polynomial time or \#P-hard. The query is called \em safe in the first case, and \em unsafe in the second case. Here, we strengthen the hardness proof, by proving that an unsafe UCQ query remains \#P-hard even if the probabilities are restricted to $\set0,\frac1 2, 1 $. This requires a complete redesign of the hardness proof, using new techniques. A related problem is the \em model counting problem, which asks for the probability of the query when the input probabilities are restricted to $\set0,\frac1 2 $. While our result does not extend to model counting for all unsafe UCQs, we prove that model counting is \#P-hard for a class of unsafe queries called Type-I forbidden queries.

2019: Approximate Inference of Outcomes in Probabilistic Elections
Abstract: We study the complexity of estimating the probability of an outcome in an election over probabilistic votes. The focus is on voting rules expressed as positional scoring rules, and two models of probabilistic voters: the uniform distribution over the completions of a partial voting profile (consisting of a partial ordering of the candidates by each voter), and the Repeated Insertion Model (RIM) over the candidates, including the special case of the Mallows distribution. Past research has established that, while exact inference of the probability of winning is computationally hard (#P-hard), an additive polynomial-time approximation (additive FPRAS) is attained by sampling and averaging. There is often, though, a need for multiplicative approximation guarantees that are crucial for important measures such as conditional probabilities. Unfortunately, a multiplicative approximation of the probability of winning cannot be efficient (under conventional complexity assumptions) since it is already NP-complete to determine whether this probability is nonzero. Contrastingly, we devise multiplicative polynomial-time approximations (multiplicative FPRAS) for the probability of the complement event, namely, losing the election.

2019: Mining Approximate Acyclic Schemes from Relations
Abstract: Acyclic schemes have numerous applications in databases and in machine learning, such as improved design, more efficient storage, and increased performance for queries and machine learning algorithms. Multivalued dependencies (MVDs) are the building blocks of acyclic schemes. The discovery from data of both MVDs and acyclic schemes is more challenging than other forms of data dependencies, such as Functional Dependencies, because these dependencies do not hold on subsets of data, and because they are very sensitive to noise in the data; for example a single wrong or missing tuple may invalidate the schema. In this paper we present Maimon, a system for discovering approximate acyclic schemes and MVDs from data. We give a principled definition of approximation, by using notions from information theory, then describe the two components of Maimon: mining for approximate MVDs, then reconstructing acyclic schemes from approximate MVDs. We conduct an experimental evaluation of Maimon on 20 real-world datasets, and show that it can scale up to 1M rows, and up to 30 columns.

2018: Integrity Constraints Revisited: From Exact to Approximate Implication
Abstract: Integrity constraints such as functional dependencies (FD) and multi-valued
dependencies (MVD) are fundamental in database schema design. Likewise,
probabilistic conditional independences (CI) are crucial for reasoning about
multivariate probability distributions. The implication problem studies whether
a set of constraints (antecedents) implies another constraint (consequent), and
has been investigated in both the database and the AI literature, under the
assumption that all constraints hold exactly. However, many applications today
consider constraints that hold only approximately. In this paper we define an
approximate implication as a linear inequality between the degree of
satisfaction of the antecedents and consequent, and we study the relaxation
problem: when does an exact implication relax to an approximate implication? We
use information theory to define the degree of satisfaction, and prove several
results. First, we show that any implication from a set of data dependencies
(MVDs+FDs) can be relaxed to a simple linear inequality with a factor at most
quadratic in the number of variables; when the consequent is an FD, the factor
can be reduced to 1. Second, we prove that there exists an implication between
CIs that does not admit any relaxation; however, we prove that every
implication between CIs relaxes "in the limit". Then, we show that the
implication problem for differential constraints in market basket analysis also
admits a relaxation with a factor equal to 1. Finally, we show how some of the
results in the paper can be derived using the I-measure theory, which relates
between information theoretic measures and set theory. Our results recover, and
sometimes extend, previously known results about the implication problem: the
implication of MVDs and FDs can be checked by considering only 2-tuple
relations.

2018: A Query Engine for Probabilistic Preferences
Abstract: Models of uncertain preferences, such as Mallows, have been extensively studied due to their plethora of application domains. In a recent work, a conceptual and theoretical framework has been proposed for supporting uncertain preferences as first-class citizens in a relational database. The resulting database is probabilistic, and, consequently, query evaluation entails inference of marginal probabilities of query answers. In this paper, we embark on the challenge of a practical realization of this framework. We first describe an implementation of a query engine that supports querying probabilistic preferences alongside relational data. Our system accommodates preference distributions in the general form of the Repeated Insertion Model (RIM), which generalizes Mallows and other models. We then devise a novel inference algorithm for conjunctive queries over RIM, and show that it significantly outperforms the state of the art in terms of both asymptotic and empirical execution cost. We also develop performance optimizations that are based on sharing computation among different inference tasks in the workload. Finally, we conduct an extensive experimental evaluation and demonstrate that clear performance benefits can be realized by a query engine with built-in probabilistic inference, as compared to a stand alone implementation with a black-box inference solver.

2018: Probabilistic Inference Over Repeated Insertion Models
Abstract: 
 
 Distributions over rankings are used to model user preferences in various settings including political elections and electronic commerce. The Repeated Insertion Model (RIM) gives rise to various known probability distributions over rankings, in particular to the popular Mallows model. However, probabilistic inference on RIM is computationally challenging, and provably intractable in the general case. In this paper we propose an algorithm for computing the marginal probability of an arbitrary partially ordered set over RIM. We analyze the complexity of the algorithm in terms of properties of the model and the partial order, captured by a novel measure termed the "cover width." We also conduct an experimental study of the algorithm over serial and parallelized implementations. Building upon the relationship between inference with rank distributions and counting linear extensions, we investigate the inference problem when restricted to partial orders that lend themselves to efficient counting of their linear extensions.
 


2018: The Complexity of the Possible Winner Problem over Partitioned Preferences
Abstract: The Possible-Winner problem asks, given an election where the voters' preferences over the set of candidates is partially specified, whether a distinguished candidate can become a winner. In this work, we consider the computational complexity of Possible-Winner under the assumption that the voter preferences are $partitioned$. That is, we assume that every voter provides a complete order over sets of incomparable candidates (e.g., candidates are ranked by their level of education). We consider elections with partitioned profiles over positional scoring rules, with an unbounded number of candidates, and unweighted voters. Our first result is a polynomial time algorithm for voting rules with $2$ distinct values, which include the well-known $k$-approval voting rule. We then go on to prove NP-hardness for a class of rules that contain all voting rules that produce scoring vectors with at least $4$ distinct values.

2017: Querying Probabilistic Preferences in Databases
Abstract: We propose a novel framework wherein probabilistic preferences can be naturally represented and analyzed in a probabilistic relational database. The framework augments the relational schema with a special type of a relation symbol---a preference symbol. A deterministic instance of this symbol holds a collection of binary relations. Abstractly, the probabilistic variant is a probability space over databases of the augmented form (i.e., probabilistic database). Effectively, each instance of a preference symbol can be represented as a collection of parametric preference distributions such as Mallows. We establish positive and negative complexity results for evaluating Conjunctive Queries (CQs) over databases where preferences are represented in the Repeated Insertion Model (RIM), Mallows being a special case. We show how CQ evaluation reduces to a novel inference problem (of independent interest) over RIM, and devise a solver with polynomial data complexity.

2017: A Database Framework for Probabilistic Preferences
Abstract: Preferences are statements about the relative quality or desirability of items. Ever larger amounts of preference information are being collected and analyzed in a variety of domains, including recommendation systems [2, 16, 18], polling and election analysis [3, 6, 7, 15], and bioinformatics [1, 11,19]. Preferences are often inferred from indirect input (e.g., a ranked list may be inferred from individual choices), and are therefore uncertain in nature. This motivates a rich body of work on uncertain preference models in the statistics literature [14]. More recently, the machine learning community has been developing methods for effective modeling and efficient inference over preferences, with the Mallows model [13] receiving particular attention [4, 5, 12,17]. In this paper, we take the position that preference modeling and analysis should be accommodated within a general-purpose probabilistic database framework. Our framework is based on a deterministic concept that we proposed in a past vision paper [8]. In the present work we focus on handing uncertain preferences, and develop a representation of preferences within a probabilistic preference database, or PPD for short. This paper is an abbreviated version of our PODS 2017 paper, where an interested reader can find additional details about the formalism and proposed algorithmic solutions.

2016: Efficiently Enumerating Minimal Triangulations
Abstract: We present an algorithm that enumerates all the minimal triangulations of a graph in incremental polynomial time. Consequently, we get an algorithm for enumerating all the proper tree decompositions, in incremental polynomial time, where ``proper'' means that the tree decomposition cannot be improved by removing or splitting a bag. The algorithm can incorporate any method for (ordinary, single result) triangulation or tree decomposition, and can serve as an anytime algorithm to improve such a method. We describe an extensive experimental study of an implementation on real data from different fields. Our experiments show that the algorithm improves upon central quality measures over the underlying tree decompositions, and is able to produce a large number of high-quality decompositions.

2016: Exploiting the Hidden Structure of Junction Trees for MPE
Abstract: The role of decomposition-trees (also known as junction and clique trees) in probabilistic inference is widely known and has been the basis for many well known inference algorithms. Recent approaches have demonstrated that such trees have a “hidden structure”, which enables the characterization of tractable problem instances as well as lead to insights that enable boosting the performance of inference algorithms. We consider the MPE problem on a Boolean formula in CNF where each literal in the formula is associated with a weight. We describe techniques for exploiting the junction-tree structure of these formulas in the context of a branch-and-bound algorithm for MPE.

2016: On the Enumeration of all Minimal Triangulations
Abstract: We present an algorithm that enumerates all the minimal triangulations of a graph in incremental polynomial time. Consequently, we get an algorithm for enumerating all the proper tree decompositions, in incremental polynomial time, where "proper" means that the tree decomposition cannot be improved by removing or splitting a bag.

2016: On the Enumeration of Tree Decompositions
Abstract: Many intractable computational problems on graphs admit tractable algorithms when applied to trees or forests. Tree decomposition extracts a tree structure from a graph by grouping nodes into bags, where each bag corresponds to a single node in of the tree. The corresponding operation on hypergraphs is that of a generalized hypertree decomposition [10], which entails a tree decomposition of the primal graph (which has the same set of nodes, and an edge between every two nodes that co-occur in a hyperedge) and an assignment of a hyperedge cover to each bag [11]. Tree decomposition and generalized hypertree decomposition have a plethora of applications, including join optimization in databases [7, 10, 21], constraint-satisfaction problems [17], computation of Nash equilibria in games [10], analysis of probabilistic graphical models [18], and weighted model counting [16,19]. Past research has focused on obtaining a “good” tree decomposition for the given graph, where goodness is typically measured by means of the width—the maximal cardinality of a bag. Nevertheless, finding a tree decomposition of a minimal width is NP-hard [2]. Moreover, in various applications the measure of goodness is different from (though related to) the width [11,16]. Abseher et al. [1] empirically showed that the execution cost of dynamic programming algorithms over a tree decomposition is highly sensitive to features of the tree decomposition other than mere width; in particular, tree decompositions of the same width may entail highly diverging running times on the same problem instance. In this paper, we describe our ongoing effort on the task of enumerating all (or a subset of) the tree decompositions of a graph. Such algorithms have been proposed in the past for small graphs (representing database queries), without complexity guarantees [15, 21]. Our main result so far is an enumeration algorithm that runs in incremental polynomial time, and our current efforts are on a practical and effective implementation.

