Recent papers for Inbal Talgam-Cohen:

2024: Conformalized Strategy-Proof Auctions
Abstract: Auctions are key for maximizing sellers' revenue and ensuring truthful bidding among buyers. Recently, an approach known as differentiable economics based on machine learning (ML) has shown promise in learning powerful auction mechanisms for multiple items and participants. However, this approach has no guarantee of strategy-proofness at test time. Strategy-proofness is crucial as it ensures that buyers are incentivized to bid their true valuations, leading to optimal and fair auction outcomes without the risk of manipulation. In this work, we propose a formulation of statistical strategy-proofness auction mechanism, ensuring that the probability of regret exceeding a predefined threshold is strictly controlled. Building upon conformal prediction techniques, we develop an auction acceptance rule that leverages regret predictions to guarantee that the data-driven auction mechanism meets the statistical strategy-proofness requirement with high probability. Our approach represents a practical middle-ground between two extremes: forcing zero-regret at the cost of significant revenue loss, and naively using ML to construct auctions with the hope of attaining low regret at test time. Numerical experiments demonstrate the necessity of the proposed method, the validity of our theoretical result, and its applicability.

2024: Contracting with a Learning Agent
Abstract: Many real-life contractual relations differ completely from the clean, static model at the heart of principal-agent theory. Typically, they involve repeated strategic interactions of the principal and agent, taking place under uncertainty and over time. While appealing in theory, players seldom use complex dynamic strategies in practice, often preferring to circumvent complexity and approach uncertainty through learning. We initiate the study of repeated contracts with a learning agent, focusing on agents who achieve no-regret outcomes. Optimizing against a no-regret agent is a known open problem in general games; we achieve an optimal solution to this problem for a canonical contract setting, in which the agent's choice among multiple actions leads to success/failure. The solution has a surprisingly simple structure: for some $\alpha>0$, initially offer the agent a linear contract with scalar $\alpha$, then switch to offering a linear contract with scalar $0$. This switch causes the agent to ``free-fall'' through their action space and during this time provides the principal with non-zero reward at zero cost. Despite apparent exploitation of the agent, this dynamic contract can leave \emph{both} players better off compared to the best static contract. Our results generalize beyond success/failure, to arbitrary non-linear contracts which the principal rescales dynamically. Finally, we quantify the dependence of our results on knowledge of the time horizon, and are the first to address this consideration in the study of strategizing against learning agents.

2024: Incentivizing Quality Text Generation via Statistical Contracts
Abstract: While the success of large language models (LLMs) increases demand for machine-generated text, current pay-per-token pricing schemes create a misalignment of incentives known in economics as moral hazard: Text-generating agents have strong incentive to cut costs by preferring a cheaper model over the cutting-edge one, and this can be done"behind the scenes"since the agent performs inference internally. In this work, we approach this issue from an economic perspective, by proposing a pay-for-performance, contract-based framework for incentivizing quality. We study a principal-agent game where the agent generates text using costly inference, and the contract determines the principal's payment for the text according to an automated quality evaluation. Since standard contract theory is inapplicable when internal inference costs are unknown, we introduce cost-robust contracts. As our main theoretical contribution, we characterize optimal cost-robust contracts through a direct correspondence to optimal composite hypothesis tests from statistics, generalizing a result of Saig et al. (NeurIPS'23). We evaluate our framework empirically by deriving contracts for a range of objectives and LLM evaluation benchmarks, and find that cost-robust contracts sacrifice only a marginal increase in objective value compared to their cost-aware counterparts.

2024: MAC Advice for Facility Location Mechanism Design
Abstract: Algorithms with predictions have attracted much attention in the last years across various domains, including variants of facility location, as a way to surpass traditional worst-case analyses. We study the $k$-facility location mechanism design problem, where the $n$ agents are strategic and might misreport their location. Unlike previous models, where predictions are for the $k$ optimal facility locations, we receive $n$ predictions for the locations of each of the agents. However, these predictions are only"mostly"and"approximately"correct (or MAC for short) -- i.e., some $\delta$-fraction of the predicted locations are allowed to be arbitrarily incorrect, and the remainder of the predictions are allowed to be correct up to an $\varepsilon$-error. We make no assumption on the independence of the errors. Can such predictions allow us to beat the current best bounds for strategyproof facility location? We show that the $1$-median (geometric median) of a set of points is naturally robust under corruptions, which leads to an algorithm for single-facility location with MAC predictions. We extend the robustness result to a"balanced"variant of the $k$ facilities case. Without balancedness, we show that robustness completely breaks down, even for the setting of $k=2$ facilities on a line. For this"unbalanced"setting, we devise a truthful random mechanism that outperforms the best known result of Lu et al. [2010], which does not use predictions. En route, we introduce the problem of"second"facility location (when the first facility's location is already fixed). Our findings on the robustness of the $1$-median and more generally $k$-medians may be of independent interest, as quantitative versions of classic breakdown-point results in robust statistics.

2024: Algorithmic Contract Theory: A Survey
Abstract: A contract is an economic tool used by a principal to incentivize one or more agents to exert effort on her behalf, by defining payments based on observable performance measures. A key challenge addressed by contracts -- known in economics as moral hazard -- is that, absent a properly set up contract, agents might engage in actions that are not in the principal's best interest. Another common feature of contracts is limited liability, which means that payments can go only from the principal -- who has the deep pocket -- to the agents. With classic applications of contract theory moving online, growing in scale, and becoming more data-driven, tools from contract theory become increasingly important for incentive-aware algorithm design. At the same time, algorithm design offers a whole new toolbox for reasoning about contracts, ranging from additional tools for studying the tradeoff between simple and optimal contracts, through a language for discussing the computational complexity of contracts in combinatorial settings, to a formalism for analyzing data-driven contracts. This survey aims to provide a computer science-friendly introduction to the basic concepts of contract theory. We give an overview of the emerging field of"algorithmic contract theory"and highlight work that showcases the potential for interaction between the two areas. We also discuss avenues for future research.

2024: Strategy-Proof Auctions through Conformal Prediction
Abstract: Auctions are key for maximizing sellers' revenue and ensuring truthful bidding among buyers. Recently, an approach known as differentiable economics based on deep learning shows promise in learning optimal auction mechanisms for multiple items and participants. However, this approach has no guarantee of strategy-proofness at test time. Strategy-proofness is crucial as it ensures that buyers are incentivized to bid their true valuations, leading to optimal and fair auction outcomes without the risk of manipulation. Building on conformal prediction, we introduce a novel approach to achieve strategy-proofness with rigorous statistical guarantees. The key novelties of our method are: (i) the formulation of a regret prediction model, used to quantify at test time violations of strategy-proofness; and (ii) an auction acceptance rule that leverages the predicted regret to ensure that for a new auction, the data-driven mechanism meets the strategy-proofness requirement with high probability (e.g., 99\%). Numerical experiments demonstrate the necessity for rigorous guarantees, the validity of our theoretical results, and the applicability of our proposed method.

2024: Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts
Abstract: The increasing deployment of AI is shaping the future landscape of the internet, which is set to become an integrated ecosystem of AI agents. Orchestrating the interaction among AI agents necessitates decentralized, self-sustaining mechanisms that harmonize the tension between individual interests and social welfare. In this paper we tackle this challenge by synergizing reinforcement learning with principal-agent theory from economics. Taken separately, the former allows unrealistic freedom of intervention, while the latter struggles to scale in sequential settings. Combining them achieves the best of both worlds. We propose a framework where a principal guides an agent in a Markov Decision Process (MDP) using a series of contracts, which specify payments by the principal based on observable outcomes of the agent's actions. We present and analyze a meta-algorithm that iteratively optimizes the policies of the principal and agent, showing its equivalence to a contraction operator on the principal's Q-function, and its convergence to subgame-perfect equilibrium. We then scale our algorithm with deep Q-learning and analyze its convergence in the presence of approximation error, both theoretically and through experiments with randomly generated binary game-trees. Extending our framework to multiple agents, we apply our methodology to the combinatorial Coin Game. Addressing this multi-agent sequential social dilemma is a promising first step toward scaling our approach to more complex, real-world instances.

2024: Principal-Agent Reinforcement Learning
Abstract: Contracts are the economic framework which allows a principal to delegate a task to an agent—despite misaligned interests, and even without directly observing the agent’s actions. In many modern reinforcement learning settings, self-interested agents learn to perform a multi-stage task delegated to them by a principal. We explore the significant potential of utilizing contracts to incentivize the agents. We model the delegated task as an MDP, and study a stochastic game between the principal and agent where the principal learns what contracts to use, and the agent learns an MDP policy in response. We present a learning-based algorithm for optimizing the principal’s contracts, which provably converges to the subgame-perfect equilibrium of the principal-agent game. A deep RL implementation allows us to apply our method to very large MDPs with unknown transition dynamics. We extend our approach to multiple agents, and demonstrate its relevance to resolving a canonical sequential social dilemma with minimal intervention to agent rewards.

2023: Delegated Classification
Abstract: When machine learning is outsourced to a rational agent, conflicts of interest might arise and severely impact predictive performance. In this work, we propose a theoretical framework for incentive-aware delegation of machine learning tasks. We model delegation as a principal-agent game, in which accurate learning can be incentivized by the principal using performance-based contracts. Adapting the economic theory of contract design to this setting, we define budget-optimal contracts and prove they take a simple threshold form under reasonable assumptions. In the binary-action case, the optimality of such contracts is shown to be equivalent to the classic Neyman-Pearson lemma, establishing a formal connection between contract design and statistical hypothesis testing. Empirically, we demonstrate that budget-optimal contracts can be constructed using small-scale data, leveraging recent advances in the study of learning curves and scaling laws. Performance and economic outcomes are evaluated using synthetic and real-world classification tasks.

2023: A Random Dictator Is All You Need
Abstract: We study information aggregation with a decision-maker aggregating binary recommendations from symmetric agents. Each agent’s recommendation depends on her private information about a hidden state. While the decision-maker knows the prior distribution over states and the marginal distribution of each agent’s recommendation, the recommendations are adversarially correlated. The decision-maker’s goal is choosing a robustly optimal aggregation rule. We prove that for a large number of agents for the three standard robustness paradigms (maximin, regret, and approximation ratio), the unique optimal aggregation rule is “random dictator.” We further characterize the minimal regret for any number of agents through concavification. (JEL D81, D82, D83)

2023: Algorithmic Harm in Consumer Markets
Abstract: 
 Machine learning algorithms are increasingly able to predict what goods and services particular people will buy, and at what price. It is possible to imagine a situation in which relatively uniform, or coarsely set, prices and product characteristics are replaced by far more in the way of individualization. Companies might, for example, offer people shirts and shoes that are particularly suited to their situations, that fit with their particular tastes, and that have prices that fit their personal valuations. In many cases, the use of algorithms promises to increase efficiency and to promote social welfare; it might also promote fair distribution. But when consumers suffer from an absence of information or from behavioral biases, algorithms can cause serious harm. Companies might, for example, exploit such biases in order to lead people to purchase products that have little or no value for them or to pay too much for products that do have value for them. Algorithmic harm, understood as the exploitation of an absence of information or of behavioral biases, can disproportionately affect members of identifiable groups, including women and people of color. Since algorithms exacerbate the harm caused to imperfectly informed and imperfectly rational consumers, their increasing use provides fresh support for existing efforts to reduce information and rationality deficits, especially through optimally designed disclosure mandates. In addition, there is a more particular need for algorithm-centered policy responses. Specifically, algorithmic transparency—transparency about the nature, uses, and consequences of algorithms—is both crucial and challenging; novel methods designed to open the algorithmic “black box” and “interpret” the algorithm’s decision-making process should play a key role. In appropriate cases, regulators should also police the design and implementation of algorithms, with a particular emphasis on the exploitation of an absence of information or of behavioral biases.

2023: Algorithmic Cheap Talk
Abstract: The literature on strategic communication originated with the influential cheap talk model, which precedes the Bayesian persuasion model by three decades. This model describes an interaction between two agents: sender and receiver. The sender knows some state of the world which the receiver does not know, and tries to influence the receiver's action by communicating a cheap talk message to the receiver. This paper initiates the systematic algorithmic study of cheap talk in a finite environment (i.e., a finite number of states and receiver's possible actions). We first prove that approximating the sender-optimal or the welfare-maximizing cheap talk equilibrium up to a certain additive constant or multiplicative factor is NP-hard. We further prove that deciding whether there exists an equilibrium in which the receiver gets utility higher than the trivial utility he can guarantee is NP-hard. Fortunately, we identify two naturally-restricted cases that admit efficient algorithms for finding a sender-optimal equilibrium - a constant number of states or a receiver having only two actions.

2023: Deep Contract Design via Discontinuous Networks
Abstract: Contract design involves a principal who establishes contractual agreements about payments for outcomes that arise from the actions of an agent. In this paper, we initiate the study of deep learning for the automated design of optimal contracts. We introduce a novel representation: the Discontinuous ReLU (DeLU) network, which models the principal's utility as a discontinuous piecewise affine function of the design of a contract where each piece corresponds to the agent taking a particular action. DeLU networks implicitly learn closed-form expressions for the incentive compatibility constraints of the agent and the utility maximization objective of the principal, and support parallel inference on each piece through linear programming or interior-point methods that solve for optimal contracts. We provide empirical results that demonstrate success in approximating the principal's utility function with a small number of training samples and scaling to find approximately optimal contracts on problems with a large number of actions and outcomes.

2023: Universally Robust Information Aggregation for Binary Decisions
Abstract: We study a setting with a decision maker making a binary decision by aggregating information from symmetric agents. Each agent provides the decision maker a recommendation depending on her private signal about the hidden state. We assume that agents are truthful - an agent recommends guessing the more likely state based on her information. This assumption is natural if the agents are unaware of how the decision-maker will aggregate their recommendations. While the decision maker has a prior distribution over the hidden state and knows the marginal distribution of each agent's private signal, the correlation between these signals is chosen adversarially. The decision maker's goal is choosing an information aggregation rule that is robustly optimal.

2023: Technical Note - Incomplete Information VCG Contracts for Common Agency
Abstract: The “common agency” model, introduced by Bernheim and Whinston in 1986 combines the fundamental challenge of the principal–agent model with the challenges of coordinating multiple principals. In “Incomplete information VCG contracts for common agency,” Alon, Talgam-Cohen, Lavi, and Shamash show that the class of common agency settings for which there exists a contract that guarantees truthfulness of all principals, welfare maximization, and the two standard properties from contract theory—limited liability for the agent and individual rationality for the principals—is identifiable by a polynomial-time algorithm. Furthermore, for these settings, the authors design a polynomial-time computable contract: given valuation reports from the principals, it returns, if possible for the setting, a payment scheme for the agent that constitutes a contract with all desired properties.

2022: Interdependent Public Projects
Abstract: In the interdependent values (IDV) model introduced by Milgrom and Weber [1982], agents have private signals that capture their information about different social alternatives, and the valuation of every agent is a function of all agent signals. While interdependence has been mainly studied for auctions, it is extremely relevant for a large variety of social choice settings, including the canonical setting of public projects. The IDV model is very challenging relative to standard independent private values, and welfare guarantees have been achieved through two alternative conditions known as {\em single-crossing} and {\em submodularity over signals (SOS)}. In either case, the existing theory falls short of solving the public projects setting. Our contribution is twofold: (i) We give a workable characterization of truthfulness for IDV public projects for the largest class of valuations for which such a characterization exists, and term this class \emph{decomposable valuations}; (ii) We provide possibility and impossibility results for welfare approximation in public projects with SOS valuations. Our main impossibility result is that, in contrast to auctions, no universally truthful mechanism performs better for public projects with SOS valuations than choosing a project at random. Our main positive result applies to {\em excludable} public projects with SOS, for which we establish a constant factor approximation similar to auctions. Our results suggest that exclusion may be a key tool for achieving welfare guarantees in the IDV model.

2022: Bayesian Analysis of Linear Contracts
Abstract: We study a generalization of both the classic single-dimensional mechanism design problem, and the hidden-action principal-agent problem of contract theory [c.f., Alon et al. 2021]. In this setting, the principal seeks to incentivize an agent with a private Bayesian type to take a costly action. The goal is to design an incentive compatible menu of contracts which maximizes the expected revenue.

2022: Interdependent Public Projects ∗
Abstract: ,

2022: Information Design in the Principal-Agent Problem
Abstract: We study a variant of the principal-agent problem in which the principal does not directly observe the agent's effort outcome; rather, she gets a signal about the agent's action according to a variable information structure designed by a regulator. We consider both the case of a risk-neutral and of a risk-averse agent, focusing mainly on a setting with a limited liability assumption. We provide a clean characterization for implementability of actions and utility profiles by any information structure, which turns out to be simple thresholds on the utilities. We further study naturally constrained information structures in which the signal emitted from any action is either the action itself or some actions nearby. We show that the worst implementable welfare deteriorates gracefully as the information structure becomes noisier. Finally, we show that our clean characterization does not generalize to a larger class of signaling constraints. In fact, even deciding whether a certain action is implementable by some constrained information structure from this class is NP-complete in the general setting.

2022: Distributional Robustness: From Pricing to Auctions
Abstract: We study robust mechanism design for revenue maximization when selling a single item in an auction, assuming that only the mean of the value distribution and an upper bound on the bidders' valuations for the item are known. Robust mechanism design is a rising alternative to Bayesian mechanism design, which yields designs that do not rely on assumptions like full distributional knowledge, but rather only partial knowledge of the distributions. We seek a mechanism that maximizes revenue over the worst-case distribution compatible with the known parameters. Such a mechanism arises as an equilibrium of a zero-sum game between the seller and an adversary who chooses the distribution, and so can be referred to as the max-min mechanism. Carrasco et al. [2018] derive the max-min pricing when the seller faces a single bidder for the item. We go from max-min pricing to max-min auctions by studying the canonical setting of two i.i.d. bidders, and show the max-min mechanism is the second-price auction with a randomized reserve. We derive a closed-form solution for the distribution over reserve prices, as well as the worst-case value distribution, for which there is simple economic intuition. We also derive a closed-form solution for the max-min reserve price distribution for any number of bidders, and we show that unlike the case of two bidders, a second-price auction with a randomized reserve cannot be an equilibrium for more than two bidders. Our technique for solving the zero-sum game is quite different than that of Carrasco et al. -- we focus on a reduced zero-sum game, where the seller can only choose a distribution for a second-price auction with a randomized reserve price (rather than any mechanism). We then analyze a discretized version of the setting to find conditions an equilibrium would satisfy. By refining the discretization grid, we are able to achieve differential equations, and solving them yields closed-form non-discretized distributions. The resulting distributions for the seller and the adversary are later shown to be an equilibrium for the reduced zero-sum game. For the two-bidder case, we expand our result to an equilibrium of the original zero-sum game, where the seller is not limited to second price auctions with reserve. The full version of the paper is available at https://arxiv.org/abs/2205.09008.

