Recent papers for Shimkin Nahum:

2023: Altitude-Loss Optimal Glides in Engine Failure Emergencies - Accounting for Ground Obstacles and Wind
Abstract: Engine failure is a recurring emergency in General Aviation and fixed-wing UAVs, often requiring the pilot or remote operator to carry out carefully planned glides to safely reach a candidate landing strip. We tackle the problem of minimizing the altitude loss of a thrustless aircraft flying towards a designated target position. Extending previous work on optimal glides without obstacles, we consider here trajectory planning of optimal gliding in the the presence of ground obstacles, while accounting for wind effects. Under simplifying model assumptions, in particular neglecting the effect of turns, we characterize the optimal solution as comprising straight glide segments between iteratively-determined extreme points on the obstacles. Consequently, the optimal trajectory is included in an iteratively-defined reduced visibility graph, and can be obtained by a standard graph search algorithm, such as A$^*$. We further quantify the effect of turns to verify a safe near-optimal glide trajectory. We apply our algorithm on a Cessna 172 model, in realistic scenarios, demonstrating both the altitude-loss optimal trajectory calculation, and determination of airstrip reachability.

2023: Markov decision processes with burstiness constraints
Abstract: None

2021: A Backpropagation Approach for Distributed Resource Allocation
Abstract: Network resource allocation through Network Utility Maximization (NUM) is one of the fundamental problems in the realm of networked systems. In the NUM framework, the network comprises a set of nodes each of which is associated with a utility function, and the goal is to distribute resources across nodes so as to maximize the sum of the nodes utilities. In this paper, we propose a novel backpropagation approach for distributed resource allocation. The internal flow of resources among nodes is governed by the network dynamics, assumed to be captured through a directed acyclic graph (DAG). Control is exercised as an external injection of limited resources at some nodes, where the goal is to determine the optimal amount of resources to be injected at nodes, under the NUM framework. To that aim, we present a novel forward-backward algorithm, inspired by neural network training, wherein flows of resources are transferred during the forward step, and gradients are backpropagated at the backward step. Based on such gradients, the controls are adjusted, considering two variations of the algorithm under synchronous and asynchronous settings. The proposed algorithms are distributed, in the sense that information in transferred only between neighboring nodes in the network. In addition, they are suitable for continued operation, so that the optimum resource allocation is tracked as conditions gradually change. We formally establish convergence of the proposed algorithms, and numerically compare the speed of convergence under the asynchronous setting against its synchronous counterpart. Together, our results advance the state-of-the-art in the realm of NUM under nonlinear constraints, indicating how to leverage a backpropagation approach for that matter.

2021: Control of Vibratory MEMS Gyroscope With the Drive Mode Excited Through Parametric Resonance
Abstract: 
 In this paper, we present a control strategy for a micro-electro-mechanical gyroscope with a drive mode excited through parametric resonance. The reduced order two degrees-of-freedom model of the device is built, and the drive mode control is implemented using phase-locked loop (PLL) and automatic gain control (AGC) loop. A sense mode vibration control algorithm is developed as well for enhanced sensor performance. The analysis of the drive mode control loops is conducted using the multiple scales method. The robustness of the suggested control loops to parameters perturbation is demonstrated using the model. A simplified linear model of the control loops is shown to predict the device behavior with good accuracy.

2021: Cooperative Multi-Agent Path Finding: Beyond Path Planning and Collision Avoidance
Abstract: We introduce the Cooperative Multi-Agent Path Finding (Co-MAPF) problem, an extension to the classical MAPF problem, where cooperative behavior is incorporated. In this setting, a group of autonomous agents operate in a shared environment and have to complete cooperative tasks while avoiding collisions with each other. This extension naturally models many real-world applications, where groups of agents must work together to complete a given task. To this end, we formalize the Co-MAPF problem and introduce Cooperative Conflict-Based Search (Co-CBS), a CBS-based algorithm for solving the problem optimally for a wide set of Co-MAPF problems. Co-CBS uses a cooperation-planning module integrated into CBS such that cooperation planning is decoupled from path planning, while ensuring that paths obtained are optimal. Finally, we present empirical results on several MAPF benchmarks demonstrating our algorithm's properties.

2020: Planning for Cooperative Multiple Agents with Sparse Interaction Constraints
Abstract: We consider the problem of cooperative multi-agent planning (MAP) in a deterministic environment, with a completely observable state. Most tractable algorithms for MAP problems assume sparse interactions among agents and ex-ploitable problem structure. We consider a speciﬁc model for representing interactions among agents using soft cooperation constraints (SCC) , which enables a compact representation of symmetric dependencies. We present a two-step planning algorithm that breaks down a multi-agent problem with K agents, to multiple instances of independent single-agent problems, such that the aggregation of the single-agent plans is optimal for the group. We propose an efﬁcient algorithm for computing the single-agent optimal plan under a given set of soft constraints, denoted as the response function . We then utilize a well-known graphical model for efﬁcient min-sum optimization in order to ﬁnd the optimal aggregation of the single agent response functions. The proposed planning al-gorithm is complete, optimal, and effective when interactions among the agents are sparse. We further indicate some useful extensions to the basic SCC formulation presented here.

2020: Dynamic Scheduling of Multiclass Many-Server Queues with Abandonment: The Generalized cμ/h Rule
Abstract: In “Dynamic Scheduling of Multiclass Many-Server Queues with Abandonment: The Generalized cμ/h Rule,” Long, Shimkin, Zhang, and Zhang propose three scheduling policies to cope with any general cost...

2019: Deep Randomized Least Squares Value Iteration
Abstract: None

2019: ILS-SUMM: Iterated Local Search for Unsupervised Video Summarization
Abstract: In recent years, there has been an increasing interest in building video summarization tools, where the goal is to automatically create a short summary of an input video that properly represents the original content. We consider shot-based video summarization where the summary consists of a subset of the video shots which can be of various lengths. A straightforward approach to maximize the representativeness of a subset of shots is by minimizing the total distance between shots and their nearest selected shots. We formulate the task of video summarization as an optimization problem with a knapsack-like constraint on the total summary duration. Previous studies have proposed greedy algorithms to solve this problem approximately, but no experiments were presented to measure the ability of these methods to obtain solutions with low total distance. Indeed, our experiments on video summarization datasets show that the success of current methods in obtaining results with low total distance still has much room for improvement. In this paper, we develop ILS-SUMM, a novel video summarization algorithm to solve the subset selection problem under the knapsack constraint. Our algorithm is based on the well-known metaheuristic optimization framework - Iterated Local Search (ILS), known for its ability to avoid weak local minima and obtain a good near-global minimum. Extensive experiments show that our method finds solutions with significantly better total distance than previous methods. Moreover, to indicate the high scalability of ILS-SUMM, we introduce a new dataset consisting of videos of various lengths.

2019: Max-Range Glides in Engine Cutoff Emergencies Under Severe Wind
Abstract: Engine cutoff is a recurring emergency in general aviation. It may be caused by an engine malfunction, fuel leak, or improper aircraft maintenance. Such an event, coupled with adverse weather, may ...

2018: On the Computation of Dynamic User Equilibrium in the Multiclass Transient Fluid Queue
Abstract: We consider the arrival timing problem faced by multiclass strategic customers to a single queue. The customers sensitivities to delay as well as service completion time preferences may be heterogeneous and the latter may vary non linearly with time. This captures many realistic settings where customers have preferences on when to arrive at a queue. We consider a fluid setup, so each customer is a point in a continuum and service rate is deterministic. This problem has been well studied in the transportation literature as the bottleneck model and the equilibrium customer arrival profile is shown to uniquely exist using intricate fixed point arguments. We develop a simple, elegant and geometrically insightful iterative method to arrive at this equilibrium profile, and provide an equally simple uniqueness proof. Further, under somewhat stringent assumptions, we arrive at the rate of convergence of the proposed algorithm. The simple geometric proof allows easy incorporation of useful extensions - to illustrate, we consider time varying service rates where the equilibrium profile is easily computed. Further, our results easily extend to the case of customers balking when their costs are above a class dependent threshold.

2018: PAC Bandits with Risk Constraints
Abstract: We study the problem of best arm identiﬁcation with risk constraints within the setting of ﬁxed conﬁdence pure exploration bandits (PAC bandits). The goal is to stop as fast as possible, and with high conﬁdence return an arm whose mean is (cid:15) -close to the best arm among those that satisfy a risk constraint, namely their α -quantile functions are larger than a threshold β . For this risk-sensitive bandit problem, we propose an al-gorithm and prove an upper-bound on its sample complexity for the general case of sub-Gaussian arms’ distributions. We also prove a lower-bound for this general case that shows our derived upper-bound is near-optimal (up to logarithmic factors). Both our upper and lower bounds have similar form to the risk-neutral PAC bandits results of (Even-Dar et al. 2006) and (Mannor and Tsitsiklis 2004), respectively. We also prove a lower-bound for our problem when the arms’ distributions are Gaussian, which is smaller than our general lower-bound, but is stronger in the sense that it applies to any instance of the (Gaussian) problem. This lower-bound is in terms of the KL divergence and has similar behavior to the risk-neutral PAC bandits results of (Kaufmann et al. 2016).

2017: Learning Control for Air Hockey Striking Using Deep Reinforcement Learning
Abstract: We consider the task of learning control policies for a robotic mechanism striking a puck in an air hockey game. The control signal is a direct command to the robot's motors. We employ a model free deep reinforcement learning framework to learn the motoric skills of striking the puck accurately in order to score. We propose certain improvements to the standard learning scheme which make the deep Q-learning algorithm feasible when it might otherwise fail. Our improvements include integrating prior knowledge into the learning scheme, and accounting for the changing distribution of samples in the experience replay buffer. Finally we present our simulation results for aimed striking which demonstrate the successful learning of this task, and the improvement in algorithm stability due to the proposed modifications.

2016: PAC Lower Bounds and Efficient Algorithms for The Max \(K\)-Armed Bandit Problem
Abstract: We consider the Max K-Armed Bandit problem, where a learning agent is faced with several stochastic arms, each a source of i.i.d. rewards of unknown distribution. At each time step the agent chooses an arm, and observes the reward of the obtained sample. Each sample is considered here as a separate item with the reward designating its value, and the goal is to find an item with the highest possible value. Our basic assumption is a known lower bound on the tail function of the reward distributions. Under the PAC framework, we provide a lower bound on the sample complexity of any (&epsilon, δ)-correct algorithm, and propose an algorithm that attains this bound up to logarithmic factors. We provide an analysis of the robustness of the proposed algorithm to the model assumptions, and further compare its performance to the simple non-adaptive variant, in which the arms are chosen randomly at each stage.

2016: Chapter 8: Nonlinear filters
Abstract: None

2016: Averaged-DQN: Variance Reduction and Stabilization for Deep Reinforcement Learning
Abstract: Instability and variability of Deep Reinforcement Learning (DRL) algorithms tend to adversely affect their performance. Averaged-DQN is a simple extension to the DQN algorithm, based on averaging previously learned Q-values estimates, which leads to a more stable training procedure and improved performance by reducing approximation error variance in the target values. To understand the effect of the algorithm, we examine the source of value function estimation errors and provide an analytical comparison within a simplified model. We further present experiments on the Arcade Learning Environment benchmark that demonstrate significantly improved stability and performance due to the proposed extension.

2016: Deep Reinforcement Learning with Averaged Target DQN
Abstract: The commonly used Q-learning algorithm combined with function approximation induces systematic overestimations of state-action values. These systematic errors might cause instability, poor performance and sometimes divergence of learning. In this work, we present the AVERAGED TARGET DQN (ADQN) algorithm, an adaptation to the DQN class of algorithms which uses a weighted average over past learned networks to reduce generalization noise variance. As a consequence, this leads to reduced overestimations, more stable learning process and improved performance. Additionally, we analyze ADQN variance reduction along trajectories and demonstrate the performance of ADQN on a toy Gridworld problem, as well as on several of the Atari 2600 games from the Arcade Learning Environment.

2016: Dynamic Games for Analyzing Competition in the Internet and in On-Line Social Networks
Abstract: None

2016: Pure Exploration for Max-Quantile Bandits
Abstract: None

2015: The Max K-Armed Bandit: A PAC Lower Bound and tighter Algorithms
Abstract: We consider the Max $K$-Armed Bandit problem, where a learning agent is faced with several sources (arms) of items (rewards), and interested in finding the best item overall. At each time step the agent chooses an arm, and obtains a random real valued reward. The rewards of each arm are assumed to be i.i.d., with an unknown probability distribution that generally differs among the arms. Under the PAC framework, we provide lower bounds on the sample complexity of any $(\epsilon,\delta)$-correct algorithm, and propose algorithms that attain this bound up to logarithmic factors. We compare the performance of this multi-arm algorithms to the variant in which the arms are not distinguishable by the agent and are chosen randomly at each stage. Interestingly, when the maximal rewards of the arms happen to be similar, the latter approach may provide better performance.

