Recent papers for Cidon Israel:

2022: CloudCast: Characterizing Public Clouds Connectivity
Abstract: Public clouds are one of the most thriving technologies of the past decade. Major applications over public clouds require world-wide distribution and large amounts of data exchange between their distributed servers. To that end, major cloud providers have invested tens of billions of dollars in building world-wide inter-region networking infrastructure that can support high performance communication into, out of, and across public cloud geographic regions. In this paper, we lay the foundation for a comprehensive study and real time monitoring of various characteristic of networking within and between public clouds. We start by presenting CloudCast, a world-wide and expandable measurements and analysis system, currently (January 2019)collecting data from three major public clouds (AWS, GCPand Azure), 59 regions, 1184 intra-cloud and 2238 cross-cloud links (each link represents a direct connection between a pair of regions), amounting to a total of 3422 continuously monitored links and providing active measurements every minute.CloudCast is composed of measurement agents automatically installed in each public cloud region, centralized control, measurement data base, analysis engine and visualization tools. Then we turn to analyze the latency measurement data collected over almost a year . Our analysis yields surprising results. First, each public cloud exhibits a unique set of link latency behaviors along time. Second, using a novel, fair evaluation methodology, termed similar links, we compare the three clouds. Third, we prove that more than 50% of all links do not provide the optimal RTT through the methodology of triangles. Triangles also provide a framework to get around bottlenecks, benefiting not only the majority (53%-70%) of the cross-cloud links by 30% to 70%, but also a significant portion (29%-45%) of intra-cloud links by 14%-33%.

2021: Revitalizing the public internet by making it extensible
Abstract: There is now a significant and growing functional gap between the public Internet, whose basic architecture has remained unchanged for several decades, and a new generation of more sophisticated private networks. To address this increasing divergence of functionality and overcome the Internet's architectural stagnation, we argue for the creation of an Extensible Internet (EI) that supports in-network services that go beyond best-effort packet delivery. To gain experience with this approach, we hope to soon deploy both an experimental version (for researchers) and a prototype version (for early adopters) of EI. In the longer term, making the Internet extensible will require a community to initiate and oversee the effort; this paper is the first step in creating such a community.

2019: The Risks of WebGL: Analysis, Evaluation and Detection
Abstract: None

2019: Energy oriented EDF for real-time systems
Abstract: Energy is a major concern when designing real-time systems. A common method for saving energy while still guaranteeing the real-time constraints is to embed dynamic voltage and frequency scaling (DVFS) mechanisms and dynamic power management (DPM) mechanisms within a real-time scheduling algorithm such as EDF. This paper proposes a new extension to the EDF scheduler, termed energy oriented EDF (EO-EDF). The new scheduler makes it possible to change the original EDF task execution order to better utilise the slack time and thus decrease the energy consumption, while still meeting the task deadlines. The new task order is defined according to a novel criterion we invented, termed task prediction order (TPO). The paper introduces two new versions of the EO-EDF scheduler, termed TPO-EDF and STPO-EDF. While STPO-EDF applies the TPO criterion in a static manner, TPO-EDF allows it to be used dynamically. We simulate the new proposed algorithms using both synthetic workloads and real-time benchmarks. The evaluations show that integrating both the TPO-EDF and STPO-EDF scheduling algorithms with DVFS and DPM mechanisms achieves an energy savings of 30% on average, in comparison with current known EDF based scheduling utilising DVFS and DPM mechanisms.

2018: Pied Piper: Rethinking Internet Data Delivery
Abstract: We contend that, analogously to the transition from resource-limited on-prem computing to resource-abundant cloud computing, Internet data delivery should also be adapted to a reality in which the cloud offers a virtually unlimited resource, i.e., network capacity, and virtualization enables delegating local tasks, such as routing and congestion control, to the cloud. This necessitates rethinking the traditional roles of inter- and intra-domain routing and conventional end-to-end congestion control. 
We introduce Optimized Cloudified Delivery (OCD), a holistic approach for optimizing joint Internet/cloud data delivery, and evaluate OCD through hundreds of thousands of file downloads from multiple locations. We start by examining an OCD baseline approach: traffic from a source A to a destination B successively passes through two cloud virtual machines operating as relays - nearest to A and B; and the two cloud relays employ TCP split. 
We show that even this naive strategy can outperform recently proposed improved end-to-end congestion control paradigms (BBR and PCC) by an order of magnitude. 
Next, we present a protocol-free, ideal pipe model of data transmission, and identify where today's Internet data delivery mechanisms diverge from this model. We then design and implement OCD Pied Piper. Pied Piper leverages various techniques, including novel kernel-based transport-layer accelerations, to improve the Internet-Cloud interface so as to approximately match the ideal network pipe model.

2017: SPACE: Semi-Partitioned CachE for Energy Efficient, Hard Real-Time Systems
Abstract: Multi-core processors are increasingly popular because they yield higher performance, but they also present new challenges for hard real-time systems in that they make it much more difficult to estimate a task's worst-case execution time (WCET). Partitioned cache architecture is being used to ease the problem by providing an isolated execution environment for each thread. Although simple to implement and use, this method may be sub-optimal with respect to both energy consumption and performance since it prevents taking advantage of information shared across threads for both instructions and data. This work presents a new cache architecture termed SPACE (Semi-Partitioned CachE) that makes it possible to leverage information sharing, yielding in turn a tighter WCET. The SPACE architecture together with our new WCET algorithm can be used to maintain the predictability of the execution time of the parallel threads while reducing the overall energy consumption of the system. The new proposed cache architecture was implemented using Verilog and deployed on a Xilinx MicroBlaze multi-core design for testing, validation and measurements. The application level experiments were conducted using the Chronos tool for estimation and the Wattch/SimpleScalar simulator for execution. Using three real-time programs–a radar tracker, a DES encryption algorithm, and an FM radio–we showed that SPACE together with the enhanced WCET algorithm reduce the average system WCET of these applications by 31 percent and reduce the actual energy consumption by 18 percent in comparison with other cache architectures.

2016: Design and dynamic management of hierarchical NoCs
Abstract: None

2015: Average latency and link utilization analysis of heterogeneous wormhole NoCs
Abstract: None

2015: Heterogeneous NoC Router Architecture
Abstract: We introduce a novel heterogeneous NoC router architecture, supporting different link bandwidths and different number of virtual channels (VCs) per unidirectional port. The NoC router is based on shared-buffer architecture and has the advantages of ingress and egress bandwidth decoupling, and better performance as compared with input-buffer router architecture. We present the challenges facing the design of such heterogeneous NoC router, and describe how this router architecture addresses them. We introduce and formally prove a novel approach that reduces the number of required middle shared-buffers without affecting the performance of the router. In comparison with an optimal input-buffer homogeneous router, our NoC router improves saturation throughput by 6-47 percent for standard traffic patterns. The router achieves significant run-time improvement for NoC-based CMP running PARSEC benchmarks. It offers better scalability, area, and power reduction of 15-60 percent, for NoC based CMPs of size 4 × 4 up to 16 × 16, as compared with optimal input-buffer homogeneous and heterogeneous routers.

2014: Designing single-cycle long links in hierarchical NoCs
Abstract: None

2014: MDP based optimal pricing for a cloud computing queueing model
Abstract: None

2014: PACK: Prediction-Based Cloud Bandwidth and Cost Reduction System
Abstract: In this paper, we present PACK (Predictive ACKs), a novel end-to-end traffic redundancy elimination (TRE) system, designed for cloud computing customers. Cloud-based TRE needs to apply a judicious use of cloud resources so that the bandwidth cost reduction combined with the additional cost of TRE computation and storage would be optimized. PACK's main advantage is its capability of offloading the cloud-server TRE effort to end-clients, thus minimizing the processing costs induced by the TRE algorithm. Unlike previous solutions, PACK does not require the server to continuously maintain clients' status. This makes PACK very suitable for pervasive computation environments that combine client mobility and server migration to maintain cloud elasticity. PACK is based on a novel TRE technique, which allows the client to use newly received chunks to identify previously received chunk chains, which in turn can be used as reliable predictors to future transmitted chunks. We present a fully functional PACK implementation, transparent to all TCP-based applications and network devices. Finally, we analyze PACK benefits for cloud users, using traffic traces from various sources.

2013: Dynamic traffic distribution among hierarchy levels in hierarchical Networks-on-Chip (NoCs)
Abstract: As the number of modules grows, performance scalability of planar topology Networks-on-Chip (NoCs) becomes limited due to the increasing hop-distances. The growing hop-distance affects both end-to-end network latency and overall network saturation. Hierarchical topologies provide better traffic hop distance and therefore are more adequate for large systems. However, the introduction of hierarchical NoCs offers new challenges. In particular, how to distribute the traffic among the hierarchy levels to effectively utilize the hierarchical structure. In this paper we propose a dynamic traffic distribution scheme that adapts traffic distribution among the hierarchy levels to the changing traffic conditions. We evaluate our scheme with packet-accurate simulations and show that it enables to realize the potential of hierarchical NoCs in latency reduction under both light and heavy traffic loads.

2013: Design Tradeoffs of Long Links in Hierarchical Tiled Networks-on-Chip
Abstract: Hierarchical topologies are frequently proposed for large Networks-on-Chip (NoCs). Hierarchical architectures utilize, at the upper levels, long links of the order of the die size. RC delays of long links might reach dozens of clock cycles in advanced technology nodes, if delay reduction techniques (e.g. wire sizing and repeater insertion) are not applied. Some proposals assume that long links can be adjusted to satisfy timing requirements but lack a deep evaluation of the tradeoffs and costs. Other proposals assume that long links must be pipelined, but do not provide a comprehensive justification. In this paper we evaluate the efficiency and the system costs of wire sizing and repeater insertion as methods to reduce link delays in hierarchical NoCs. We present a unified interconnect cost function that accounts for power and wiring overheads of these methods. Then, we quantify the costs of modifying long links in typical hierarchical NoCs for different target clock frequencies and technology nodes. Although long links might undergo aggressive adjustments, we find these overall costs to be low at the system level for many typical cases, taking into account that there are only a few long links in most proposed hierarchical NoC architectures.

2013: Prudent Opportunistic Cognitive Radio Access Protocols
Abstract: None

2013: Gana: A novel low-cost conflict-free NoC architecture
Abstract: Similar to off-chip networks, current NoC architectures are based on the store and forward of uncoordinated end-to-end packet transmissions through autonomous buffered routers. However, the monolithic nature and the small physical dimensions of on chip networks open up the opportunity for much more tightly controlled architectures. We present GANA, a new Global Arbiter NoC Architecture. In GANA, the transmission of end-to-end data is timed by a global arbiter in a way that avoids any queuing in the network. The arbitration takes into account the complete transfer of the end-to-end packets through the entire network path, avoiding any intermediate queuing and hop-by-hop packet arbitration. Consequently, buffers and arbiters are no longer required in the routers, resulting in smaller area and low power consumption. It is demonstrated through detailed design and synthesis that the additional area of the central arbiter and the control path are negligible in comparison to the provided area saving. For example, an 8× 8 GANA consumes only 16% of the area of an equivalent autonomous NoC while providing a better end-to-end throughput. The end-to-end performance of GANA at high network loads is typically much better than in a distributed-control NOC, because resource contention and queuing in the network are avoided. This comes at the cost of a few percentage increase in latency at light loads due to the additional arbitration phase. GANA architecture combines the inherent benefits of a network (parallelism and spatial reuse of links) with the inherent benefits of high integration (global view of the system state, central control, and synchronization). The scalability of GANA is evaluated analytically, showing that it can be superior to fully-distributed networks in systems up to a size of about 100 modules manufactured in 45nm technology, which can be used today as well as in the foreseeable future.

2013: Optimal scheduling in the hybrid-cloud
Abstract: The emerging hybrid cloud architecture allows organizations to optimize their computation needs and costs by maintaining their private computational infrastructure at high utilization and meeting peak requirements by offloading selected tasks to the public cloud. Consequently, there is a need to devise efficient systems equipped with online task cloudbursting algorithms that optimize the overall cost while maintaining adequate quality of service. Such algorithms must take into account the difference in communication and computational requirements associated with different tasks. For example, it is clear that when two tasks have the same local computational requirements, the one with the lower cloudbursting cost is a better candidate to be off-loaded and sent to the cloud. In this paper, we address the case in which arriving tasks have the same computational cost but different communication costs. We design scheduling system based on online decision algorithms driven by the user's local infrastructure constraints. We model the online scheduling problem as Markov Decision Process (MDP) problem and provide optimal policies for scheduling tasks either locally or remotely. We further explore the usage of MDP in different scenarios and prove the structural properties of the optimal policies in order to incorporate them into the decision engine. The design of the practical scheduling system is supported by the analytical results and numerical evaluations. We demonstrate the practical computational advantage of threshold type policies and provide an insight into their dependence on system parameters.

2012: Handling global traffic in future CMP NoCs
Abstract: It was recently shown that if computation locality is properly employed, Chip-Multi-Processors (CMP) traffic patterns can be modeled with a bandwidth version of Rent's rule. The Communication Probability Distributions (CPD) derived from the Rent's rule imply that most end to end packets are exchanged by nearest-neighbors. We show that while packets exchanged with nearest-neighbor dominate peer to peer traffic, their contribution to the overall NoC traffic decreases rapidly as the system grows. Correspondingly, the bandwidth consumed by long distance packets (a. ka. global packets) becomes dominant starting from medium-size systems, despite their low injection rate. To accommodate this phenomenon, we introduce PyraMesh - a novel family of multilevel hierarchical 2D mesh topologies resembling a pyramid structure. In PyraMesh, global packets are separated from the local ones and routed through the upper levels of the hierarchy. PyraMesh is shown to improve light-load latencies and raise the saturation point of the network to higher injection rates, as compared with previously presented NoC topologies.

2012: Delay analysis of wormhole based heterogeneous NoC
Abstract: We introduce delay phenomena of a wormhole routing based NoC with variable link capacities and a variable number of virtual channels per link. We also demonstrate how these phenomena can be used to develop a delay analysis. Hence, one can use these phenomena to analyze different heterogeneous NoC architectures and traffic scenarios, which cannot be analyzed by any existing NoC delay analysis. Further details about these phenomena and the delay evaluation methodology can be found in [1].

2012: On the Capacity of Bufferless Networks-on-Chip
Abstract: Networks-on-Chip (NoCs) form an emerging paradigm for communications within chips. In particular, bufferless NoCs require significantly less area and power consumption, but also pose novel major scheduling problems to achieve full capacity. In this paper, we provide first insights on the capacity of bufferless NoCs. In particular, we present optimal periodic schedules for several bufferless NoCs with a complete-exchange traffic pattern. These schedules particularly fit distributed-programming models and network congestion-control mechanisms. In addition, for general traffic patterns, we also introduce efficient greedy scheduling algorithms, that often outperform simple greedy online algorithms and cannot have deadlocks. Finally, using network simulations, we quantify the speedup of our suggested algorithms, and show how they improve throughput by up to 35 percent on a torus network.

