Recent papers for Danny Raz:

2024: A Framework for Anomaly Detection in Blockchain Networks With Sketches
Abstract: A blockchain is a distributed ledger composed of immutable blocks of data that often refer to money transfers. As blockchain networks gain popularity, there is a rising concern for security against malicious and hacking users. Detection anomalies and unusual account activities can be based on comparing upcoming activity with recent and historical data. However, the size and rapid growth of the complete blockchain history can result in slow and expensive processing. This paper proposes a solution to this challenge by analyzing summarized block data structures, known as sketches, instead of the entire blockchain. Sketches are commonly used in computer systems and blockchain networks to provide efficient query executions while maintaining a compact data representation. This study explores the use of sketches, such as Bloom Filter and HyperLogLog, to identify suspicious accounts without requiring the examination of the entire blockchain data. We design solutions for anomaly detection of certain goals that may be indications of known attacks. We develop methods to identify accounts with high transaction volume, frequency, and node degree. Furthermore, the innovation of this paper lies in the generalization of sketch-based anomaly detection through a generic solution capable of addressing diverse queries. We conduct experiments based on real Ethereum data and compare the accuracy, time complexity, and memory usage of our algorithms with traditional detection algorithms that rely on the complete blockchain data. Our results indicate that sketch-based anomaly detection methods can provide a practical and scalable solution for detecting anomalies in transactions on blockchain networks. We managed to reduce the amount of memory used by the detection process by 90%-96% and reduce the time complexity by 86% while maintaining high accuracy.

2023: Cold Start for Cloud Anomaly Detection
Abstract: Cloud providers need to constantly monitor their network and provide accurate timely alerts when the service level degrades. In order to do so, many providers use Anomaly Detection (AD) systems that detect deviation of the network parameters from the normal pattern. However, the accuracy of such systems strongly depends on acquiring enough data to learn the normal behavior. This problem, known as cold start, limits the ability to detect anomalies of newly created objects and thus significantly reduces the coverage of VM anomaly detection systems.In this paper we address this problem in the context of modeling VM traffic patterns in a big cloud provider setting. We first observe that the models of the deployed VMs are clustered into a relatively small number of clusters. Thus, a small number of appropriately selected models can provide an accurate modeling for a large fraction of the VMs. We then turn to the algorithmic problem and show how to efficiently find an appropriate model for a specific newly created VM. Our evaluation, based on a large set of VMs from a major cloud provider, indicates that using our algorithms, one can significantly improve anomaly detection coverage while maintaining a compatible accuracy level.

2022: Almost Tight Bounds for Online Facility Location in the Random-Order Model
Abstract: We study the online facility location problem with uniform facility costs in the random-order model. Meyerson's algorithm [FOCS'01] is arguably the most natural and simple online algorithm for the problem with several advantages and appealing properties. Its analysis in the random-order model is one of the cornerstones of random-order analysis beyond the secretary problem. Meyerson's algorithm was shown to be (asymptotically) optimal in the standard worst-case adversarial-order model and $8$-competitive in the random order model. While this bound in the random-order model is the long-standing state-of-the-art, it is not known to be tight, and the true competitive-ratio of Meyerson's algorithm remained an open question for more than two decades. We resolve this question and prove tight bounds on the competitive-ratio of Meyerson's algorithm in the random-order model, showing that it is exactly $4$-competitive. Following our tight analysis, we introduce a generic parameterized version of Meyerson's algorithm that retains all the advantages of the original version. We show that the best algorithm in this family is exactly $3$-competitive. On the other hand, we show that no online algorithm for this problem can achieve a competitive-ratio better than $2$. Finally, we prove that the algorithms in this family are robust to partial adversarial arrival orders.

2022: A case for an open customizable cloud network
Abstract: Cloud computing is transforming networking landscape over the last few years. The first order of business for major cloud providers today is to attract as many organizations as possible to their own clouds. To that end cloud providers offer a new generation of managed network solutions to connect the premises of the enterprises to their clouds. To serve their customers better and to innovate fast, major cloud providers are currently on the route to building their own "private Internets", which are idiosyncratic. On the other hand, customers that do not want to stay locked by vendors and who want flexibility in using best-for-the-task services spanning multiple clouds and, possibly, their own premises, seek for solutions that will provide smart overlay connectivity across clouds. The result of these developments is a multiplication of closed idiosyncratic solutions rather than an open standardized ecosystem. In this editorial note we argue for desirability of such an ecosystem, outline the main requirements and sketch possible solutions. We focus on enterprise as our primary use case and illustrate the main ideas through it, but the same principles apply to various different use cases.

2022: Bandwidth resource allocation in integrated access and backhaul networks
Abstract: One of the promising technologies that allows currently deployed 5G and the anticipated 6G networks to cope with the ever increasing demand for high throughput low latency data services is Integrated Access and Backhaul. Self driving cars, augmented reality games and large scale data streaming are simple examples of new applications that require a large amount of low latency traffic. Integrated Access and Backhaul can provide better service to such applications by extending the traditional cellular access and combining access and backhaul resources. However, the actual performance gain depends on the specific allocation of the radio resources. In this paper we address this challenge and study new ways to allocate bandwidth across such networks. We formulate the IAB Resource Allocation Problem (IABrap) and provide a novel approximation algorithm with guaranteed performance to solve it. We also study a new, ML method, that is based on applying GNN (Graph Neural Network) to this problem. We evaluate the expected performance of both methods in realistic scenarios using a self-developed network simulator. Our results indicate that combining traditional algorithmic techniques with state of art ML can provide better practical algorithms.

2022: Dynamic VNF Placement in 5G Edge Nodes
Abstract: The ongoing transition into 5G networks is enabled in part by the combination of NFV (Network Function Virtualization) and MEC (Multi-access Edge Computing), two promising paradigms that allow executing ultra-low-latency network services on edge nodes, physically closer to the clients. However, orchestrating this complex distributed environment and especially provisioning services in a timely manner, in order to address the dynamic workload, remained a big challenge. In this paper we address this challenge and study ways to dynamically place network functions at edge nodes, across the network, in a way that maximizes client satisfaction, we measure this satisfaction by the number of clients that received their desired services in a manner that holds these required services low-latency demands. In order to balance between the dynamic workload and the non-negligible cost of replacing the functions at the edge, we partition the time into epochs and reassign VNFs (Virtual Network Functions) only at the beginning of each epoch. Our theoretical analysis, based on studying a simple variant of the online problem, shows that the data from the last epoch can provide guarantees on the expected performance. We then evaluate the actual performance of our algorithm based on extensive simulations over real data. The results indicate that our new algorithm can be deployed in a realistic 5G setting, generating an overall dynamic solution that outperforms currently used methods.

2022: Efficient Resource-Constrained Monitoring
Abstract: Monitoring network traffic is an important building block for various management and security systems. Typically, the number of active flows in a network node is much larger than the number of available monitoring resources, making it imprac-tical to maintain a "per-flow" state at the node. This situation gave rise to the recent interest in streaming algorithms where complex data structures are used to perform monitoring tasks efficiently. However, these solutions often require complicated "per-packet" operations, which are not feasible in current devices line-rate. Even when the amortized (expected average) complexity is O(1) operations per-packet, some packets may experience a much longer delay, which again is impractical. In this dissertation we study three important monitoring problems (that were recently studied in the context of streaming algorithms) and for each of them we present practical, efficient resource-constrained algorithms.

2021: Routing-Oblivious Network-Wide Measurements
Abstract: The recent introduction of SDN allows deploying new centralized network algorithms that dramatically improve network operations. In such algorithms, the centralized controller obtains a network-wide view by merging measurement data from Network Measurement Points (NMPs). A fundamental challenge is that several NMPs may count the same packet, reducing the accuracy of the measurement. Existing solutions circumvent this problem by assuming that each packet traverses a single NMP or that the routing is fixed and known. This work suggests novel algorithms for three fundamental network-wide measurement problems without making any assumptions on the topology and routing and without modifying the underlying traffic. Specifically, this work introduces two algorithms for estimating the number of (distinct) packets or byte volume in the measurement, estimating per-flow packet and byte counts, and finding the heavy hitter flows. Our work includes formal accuracy guarantees and an extensive evaluation consisting of the realistic fat-tree topology and three real network traces. Our evaluation shows that our algorithms outperform existing works and provide accurate measurements within reasonable space parameters.

2021: Containers Resource Allocation in Dynamic Cloud Environments
Abstract: Containers technology has become very popular in recent years, since it allows users to focus on designing their applications in a modular way and abstracting away the environments in which they actually run. Cloud providers such as AWS (Amazon Web Services) and GCP (Google Cloud Platform) offer their users managed containers platforms that orchestrate, schedule and execute multiple containers over a multi-tenant cloud infrastructure. As these services gain popularity, it is becoming more and more challenging to manage them in a way that effectively utilized the existing resources. The latter has a significant economical impact on cloud providers when it comes to their compute infrastructure investment costs and the price they can offer to their customers. In this paper, we approach this challenge by developing multidimensional container resource allocation algorithms designed to be deployed in dynamic cloud environments with different types of applications under varying loads scenarios. Our algorithms allocate for each container an available engine to execute it, in a way that maximizes the overall revenue. We design our algorithms and provide a constant worst-case approximation bound using the Local Ratio technique. Our evaluation, based on real-world scenarios, indicates that the performance of our algorithms is up to a factor of two better than the performance of existing scheduling algorithms, when the available resources are scarce.

2021: Online Weighted Bipartite Matching with a Sample
Abstract: We study the classical online bipartite matching problem: One side of the graph is known and vertices of the other side arrive online. It is well known that when the graph is edge-weighted, and vertices arrive in an adversarial order, no online algorithm has a nontrivial competitive-ratio. To bypass this hurdle we modify the rules such that the adversary still picks the graph but has to reveal a random part (say half) of it to the player. The remaining part is given to the player in an adversarial order. This models practical scenarios in which the online algorithm has some history to learn from. This way of modeling a history was formalized recently by the authors (SODA 20) and was called the AOS model (for Adversarial Online with a Sample). It allows developing online algorithms for the secretary problem that compete even when the secretaries arrive in an adversarial order. Here we use the same model to attack the much more challenging matching problem. We analyze a natural algorithmic framework that decides how to match an arriving vertex v by applying an oﬄine matching algorithm to v and the sample. We get roughly 1 / 4 of the maximum weight by applying the oﬄine greedy matching algorithm to the sample and v . Our analysis ties the performance of this algorithm to the performance of the oﬄine greedy matching on the online part and we also prove that it is tight. Surprisingly, when replacing greedy with an optimal algorithm for maximum matching, no constant competitive-ratio can be guaranteed when the size of the sample is comparable to the size of the online part. However, when the sample is quadratic in the size of the online part, we do get a competitive-ratio of 1 /e .

2021: An almost optimal approximation algorithm for monotone submodular multiple knapsack
Abstract: None

2021: On the Practical Detection of Heavy Hitter Flows
Abstract: The detection of of Heavy Hitter (HH) flows in a network device is a critical building block in many control and management tasks. A flow is considered a Heavy Hitter flow if its portion from the total traffic surpasses a given threshold. One of the most important aspect of this detection is its practicality; i.e., being able to work in line rate using the available scarce local memory in the device. In this paper, we present a practical heavy hitters detection algorithm that requires a constant amount of memory (not related to the number of flows or the number of packets) and performs at most O(1) operation per packet to keep with line rate. We present an analysis of errors for our algorithm and compare it to state-of-the-art monitoring solutions, showing a superior performance where the allocated memory is less than 1 MB. In particular, we are able to detect more HH flows with less false positive without increasing the per-packet processing time.

2021: Online Weighted Matching with a Sample
Abstract: We study the greedy-based online algorithm for edge-weighted matching with (one-sided) vertex arrivals in bipartite graphs, and edge arrivals in general graphs. This algorithm was first studied more than a decade ago by Korula and Pál for the bipartite case in the random-order model. While the weighted bipartite matching problem is solved in the random-order model, this is not the case in recent and exciting online models in which the online player is provided with a sample, and the arrival order is adversarial. The greedy-based algorithm is arguably the most natural and practical algorithm to be applied in these models. Despite its simplicity and appeal, and despite being studied in multiple works, the greedy-based algorithm was not fully understood in any of the studied online models, and its actual performance remained an open question for more than a decade. We provide a thorough analysis of the greedy-based algorithm in several online models. For vertex arrivals in bipartite graphs, we characterize the exact competitive-ratio of this algorithm in the random-order model, for any arrival order of the vertices subsequent to the sampling phase (adversarial and random orders in particular). We use it to derive tight analysis in the recent adversarial-order model with a sample (AOS model) for any sample size, providing the first result in this model beyond the simple secretary problem. Then, we generalize and strengthen the black box method of converting results in the random-order model to single-sample prophet inequalities, and use it to derive the state-of-the-art single-sample prophet inequality for the problem. Finally, we use our new techniques to analyze the greedy-based algorithm for edge arrivals in general graphs and derive results in all the mentioned online models. In this case as well, we improve upon the state-of-the-art single-sample prophet inequality. Blavatnik School of Computer Science, Tel Aviv University, Israel. Email: haimk@tau.ac.il. Computer Science Department, Technion, Israel. Emails: {dnaori,danny}@cs.technion.ac.il.

2021: Scalable Blockchain Anomaly Detection with Sketches
Abstract: The growing popularity of Blockchain networks attracts also malicious and hacking users. Effectively detecting inappropriate and malicious activity should thus be a top priority for safeguarding blockchain networks and services. Blockchain behavior analysis can be used to detect unusual account activities or time periods with network-wide irregular properties. Thus, optimized anomaly detection based on historical data is an essential task for securing transactions and services. However, processing the complete blockchain history can be slow and costly due to its large size and rapid growth. In this paper we suggest addressing this challenge by analyzing summarized blocks data structures, called sketches, rather than the entire blockchain. Sketches are common data structures used in computer systems and blockchain networks, to allow compact data representation while supporting efficient executions of particular queries. We study how sketches can be used to detect suspicious accounts or time periods without the need to maintain or go through the entire blockchain data. We design solutions for the major known attacks and conduct experiments to evaluate them based on real Ethereum data. We compare the accuracy, run-time and memory usage of our algorithms with traditional detection algorithms relying on the complete blockchain data. Our results indicate that sketch-based anomaly detection methods can provide a practical scalable solution for detecting anomalies in blockchain networks.

2021: General Knapsack Problems in a Dynamic Setting
Abstract: The world is dynamic and changes over time, thus any optimization problem used to model real life problems must address this dynamic nature, taking into account the cost of changes to a solution over time. The multistage model was introduced with this goal in mind. In this model we are given a series of instances of an optimization problem, corresponding to different times, and a solution is provided for each instance. The strive for obtaining near-optimal solutions for each instance on one hand, while maintaining similar solutions for consecutive time units on the other hand, is quantified and integrated into the objective function. In this paper we consider the Generalized Multistage $d$-Knapsack problem, a generalization of the multistage variants of the Multiple Knapsack problem, as well as the $d$-Dimensional Knapsack problem. We present a PTAS for Generalized Multistage $d$-Knapsack.

2020: NFV Placement in Resource-Scarce Edge Nodes
Abstract: Multi-access Edge Computing (MEC) is a new networking paradigm considered to be one of the enablers of 5G networks. In particular, it allows for network operators to provide low latency services by moving the service logic from centralized datacenters to small distributed locations at the edge of a network. However, computing and storage resources at these edge nodes are scarce and thus efficient resource allocation becomes an essential building block in any MEC orchestration solution.In this paper we address one particular challenge in this domain - how to place network functions at the edge nodes in a way that maximizes the customers benefit. Thus, we formulate the Capacitated MEC Allocation Problem (CMAP) and provide multiple algorithms with analytical performance guarantees for this problem. Furthermore, we use extensive simulations to evaluate the performance of our algorithms in realistic scenarios and show that they outperform both the analytical worst case guarantees, as well as currently used network function placement methods.

2020: Routing Oblivious Measurement Analytics
Abstract: Network-wide traffic analytics are often needed for various network monitoring tasks. These measurements are often performed by collecting samples at network switches, which are then sent to the controller for aggregation. However, performing such analytics without “overcounting’' flows or packets that traverse multiple measurement switches is challenging. Therefore, existing solutions often simplify the problem by making assumptions on the routing or measurement switch placement. We introduce AROMA, a measurement infrastructure that generates a uniform sample of packets and flows regardless of the topology, workload and routing. Therefore, AROMA can be deployed in many settings, and can also work in the data plane using programmable PISA switches. The AROMA infrastructure includes controller algorithms that approximate a variety of essential measurement tasks while providing formal accuracy guarantees. Using extensive simulations on real-world network traces, we show that our algorithms are competitively accurate compared to the best existing solutions despite the fact that they make no assumptions on the underlying network or the placement of measurement switches.

2020: Online Placement of Virtual Machines with Prior Data
Abstract: The cloud computing market has a wide variety of customers that deploy various applications from deep learning to classical web services. Each application may have different computing, memory and networking requirements, and each customer may be willing to pay a different price for the service. When a request for a VM arrives, the cloud provider decides online whether to serve it or not and which resources to allocate for this purpose. The goal is to maximize the revenue while obeying the constraints imposed by the limited physical infrastructure and its layout.Although requests arrive online, cloud providers are not entirely in the dark; historical data is readily available and may contain strong indications regarding future requests. Thus, standard theoretical models that assume the online player has no prior knowledge are inadequate. In this paper, we adopt a recent theoretical model for the design and analysis of online algorithms that allows taking such historical data into account. We develop new competitive online algorithms for multidimensional resource allocation and analyze their guaranteed performance. Moreover, using extensive simulation over real data from Google and AWS, we show that our new approach yields much higher revenue to cloud providers than currently used heuristics.

2020: A (1 − e − 1 − ε ) -Approximation for the Monotone Submodular Multiple Knapsack Problem
Abstract: We study the problem of maximizing a monotone submodular function subject to a Multiple Knapsack constraint (SMKP) . The input is a set I of items, each associated with a non-negative weight, and a set of bins having arbitrary capacities. Also, we are given a submodular, monotone and non-negative function f over subsets of the items. The objective is to ﬁnd a subset of items A ⊆ I and a packing of these items in the bins, such that f ( A ) is maximized. SMKP is a natural extension of both Multiple Knapsack and the problem of monotone submodular maximization subject to a knapsack constraint. Our main result is a nearly optimal polynomial time (1 − e − 1 − ε )-approximation algorithm for the problem, for any ε > 0. Our algorithm relies on a reﬁned analysis of techniques for constrained submodular optimization combined with sophisticated application of tools used in the development of approximation schemes for packing problems.

2020: On the Practical Detection of Hierarchical Heavy Hitters
Abstract: Finding the network’s heaviest flows is an important and challenging network monitoring task and a critical building block for many other applications. In the hierarchical heavy hitters (HHH) problem, one needs to identify the most frequent network IP-prefixes hierarchically. This is a challenging task since the number of relevant IP-prefixes of flows in a busy router is much higher than the number of counters. To address this point, many streaming algorithms were recently developed, but they use complex data-structures and usually have non-constant per-packet update-time, preventing them from being deployed in line-speed. A randomized constant-time algorithm was proposed recently; however, it is only applicable to extremely large streams. In this paper, we propose a constant-time algorithm for detecting the HHH that does not have any convergence requirements and achieves comparable results to state of the art. Furthermore, our algorithm uses only efficient built-in counters available in current network devices, making it deployable on commercially off-the-shelf network gear. We provide an analytical study of the problem and show, using emulation over real traffic, that our algorithm performs at least as well as the best-known streaming algorithms without performing expensive per-packet operations or requiring convergence periods.

