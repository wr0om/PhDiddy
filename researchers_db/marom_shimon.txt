Recent papers for Marom Shimon:

2023: A biophysical perspective on the resilience of neuronal excitability across timescales
Abstract: None

2022: Lost knowledge
Abstract: None

2022: Identifying regulation with adversarial surrogates
Abstract: Homeostasis, the ability to maintain a relatively constant internal environment in the face of perturbations, is a hallmark of biological systems. It is believed that this constancy is achieved through multiple internal regulation and control processes. Given observations of a system, or even a detailed model of one, it is both valuable and extremely challenging to extract the control objectives of the homeostatic mechanisms. In this work, we develop a robust data-driven method to identify these objectives, namely to understand: “what does the system care about?”. We propose an algorithm, Identifying Regulation with Adversarial Surrogates (IRAS), that receives an array of temporal measurements of the system, and outputs a candidate for the control objective, expressed as a combination of observed variables. IRAS is an iterative algorithm consisting of two competing players. The first player, realized by an artificial deep neural network, aims to minimize a measure of invariance we refer to as the coefficient of regulation. The second player aims to render the task of the first player more difficult by forcing it to extract information about the temporal structure of the data, which is absent from similar ‘surrogate’ data. We test the algorithm on two synthetic and one natural data set, demonstrating excellent empirical results. Interestingly, our approach can also be used to extract conserved quantities, e.g., energy and momentum, in purely physical systems, as we demonstrate empirically.

2022: How Are Nerve Cells And Artificial Intelligence Similar?
Abstract: In the field of artificial intelligence, which has a large influence on our lives today, the term “neural network” has been gaining popularity. It usually refers to a dense web of simple units, each of which may be in one of two states (on/off) and impacts of the state of other units connected to it. What exactly is the relationship between the way a nerve cell acts and the way artificial intelligence works? How is the action of an artificial neural network similar to a network of neurons in the human brain? This article tries to answer these questions. We will summarize how thinking happens, provide a short description of how a nerve cell works, describe the similarities between a nerve cell and a basic unit of a logical system, and finally show how connecting several such units is the basis for artificial intelligence.

2019: Inhibition increases response variability and reduces stimulus discrimination in random networks of cortical neurons
Abstract: None

2019: A Biohybrid Setup for Coupling Biological and Neuromorphic Neural Networks
Abstract: Developing technologies for coupling neural activity and artificial neural components, is key for advancing neural interfaces and neuroprosthetics. We present a biohybrid experimental setting, where the activity of a biological neural network is coupled to a biomimetic hardware network. The implementation of the hardware network (denoted NeuroSoC) exhibits complex dynamics with a multiplicity of time-scales, emulating 2880 neurons and 12.7 M synapses, designed on a VLSI chip. This network is coupled to a neural network in vitro, where the activities of both the biological and the hardware networks can be recorded, processed, and integrated bidirectionally in real-time. This experimental setup enables an adjustable and well-monitored coupling, while providing access to key functional features of neural networks. We demonstrate the feasibility to functionally couple the two networks and to implement control circuits to modify the biohybrid activity. Overall, we provide an experimental model for neuromorphic-neural interfaces, hopefully to advance the capability to interface with neural activity, and with its irregularities in pathology.

2018: Inhibition in Random Neuronal Networks Enhances Response Variability and Disrupts Stimulus Discrimination
Abstract: Inhibition is considered to shape neural activity, and broaden its pattern repertoire. In the sensory organs, where the anatomy of neural circuits is highly structured, lateral inhibition sharpens contrast among stimulus properties. The impact of inhibition on stimulus processing and the involvement of lateral inhibition is less clear when activity propagates to the less-structured relay stations. Here we take a synthetic approach to disentangle the impacts of inhibition from that of specialized anatomy on the repertoire of evoked activity patterns, and as a result, the network capacity to uniquely represent different stimuli. To this aim, we blocked inhibition in randomly rewired networks of cortical neurons in-vitro, and quantified response variability and stimulus discrimination among stimuli provided at different spatial loci, before and after the blockade. We show that blocking inhibition quenches variability of responses evoked by repeated stimuli through any spatial source; for all tested response features. Despite the sharpening role of inhibition in the highly structured sensory organs, in these random networks we find that blocking inhibition enhances stimulus discrimination between spatial sources of stimulation, when based on response features that emphasize the relation among spike times recorded through different electrodes. We further show that under intact inhibition, responses to a given stimulus are a noisy version of those revealed by blocking inhibition; such that intact inhibition disrupts an otherwise coherent, wave propagation of activity.

2018: Visual detection of time-varying signals: Opposing biases and their timescales
Abstract: Human visual perception is a complex, dynamic and fluctuating process. In addition to the incoming visual stimulus, it is affected by many other factors including temporal context, both external and internal to the observer. In this study we investigate the dynamic properties of psychophysical responses to a continuous stream of visual near-threshold detection tasks. We manipulate the incoming signals to have temporal structures with various characteristic timescales. Responses of human observers to these signals are analyzed using tools that highlight their dynamical features as well. Our experiments show two opposing biases that shape perceptual decision making simultaneously: positive recency, biasing towards repeated response; and adaptation, entailing an increased probability of changed response. While both these effects have been reported in previous work, our results shed new light on the timescales involved in these effects, and on their interplay with varying inputs. We find that positive recency is a short-term bias, inversely correlated with response time, suggesting it can be compensated by afterthought. Adaptation, in contrast, reflects trends over longer times possibly including multiple previous trials. Our entire dataset, which includes different input signal temporal structures, is consistent with a simple model with the two biases characterized by a fixed parameter set. These results suggest that perceptual biases are inherent features which are not flexible to tune to input signals.

2018: Closed-loop control of a modular neuromorphic biohybrid
Abstract: Neural networks modularity is a major challenge for the development of control circuits of neural activity. Under physiological limitations, the accessible regions for external stimulation are possibly different from the functionally relevant ones, requiring complex indirect control designs. Moreover, control over one region might affect activity of other downstream networks, once sparse connections exist. We address these questions by developing a hybrid device of a cortical culture functionally integrated with a biomimetic hardware neural network. This design enables the study of modular networks controllability, while connectivity is well-defined and key features of cortical networks are accessible. Using a closed-loop control to monitor the activity of the coupled hybrid, we show that both modules are congruently modified, in the macroscopic as well as the microscopic activity levels. Control impacts efficiently the activity on both sides whether the control circuit is an indirect series one, or implemented independently only on one of the modules. Hence, these results present global functional impacts of a local control intervention. Overall, this strategy provides an experimental access to the controllability of neural activity irregularities, when embedded in a modular organization.

2018: Cellular function given parametric variation in the Hodgkin and Huxley model of excitability
Abstract: Significance Macroscopic cellular function is maintained despite extensive variations in underlying elementary constituents, including the size of the cell, and the number, distribution, and kinetics of their proteins. Here, we take advantage of the sound theoretical and experimental basis of action potential generation to analyze macroscopic cellular invariance given microscopic variation. This analysis points to a significant gap between the high-dimensional level of description captured by biophysical measurements of channel function and the lower, physiological dimensionality, to which cellular function is sensitive. When examined in a lower dimension, a simple rule that relies on sodium channel slow inactivation provides a powerful homeostatic control mechanism that maintains excitability amid changes in protein concentrations and their kinetics. How is reliable physiological function maintained in cells despite considerable variability in the values of key parameters of multiple interacting processes that govern that function? Here, we use the classic Hodgkin–Huxley formulation of the squid giant axon action potential to propose a possible approach to this problem. Although the full Hodgkin–Huxley model is very sensitive to fluctuations that independently occur in its many parameters, the outcome is in fact determined by simple combinations of these parameters along two physiological dimensions: structural and kinetic (denoted S and K, respectively). Structural parameters describe the properties of the cell, including its capacitance and the densities of its ion channels. Kinetic parameters are those that describe the opening and closing of the voltage-dependent conductances. The impacts of parametric fluctuations on the dynamics of the system—seemingly complex in the high-dimensional representation of the Hodgkin–Huxley model—are tractable when examined within the S–K plane. We demonstrate that slow inactivation, a ubiquitous activity-dependent feature of ionic channels, is a powerful local homeostatic control mechanism that stabilizes excitability amid changes in structural and kinetic parameters.

2016: Long-range synchrony and emergence of neural reentry
Abstract: None

2016: Long-range synchrony and emergence of reentry in neural networks
Abstract: Synchronization across long neural distances is a functionally important phenomenon. In order to access the mechanistic basis of longrange synchrony, we constructed an experimental model that enables monitoring of spiking activities over centimeter scale distances in large random networks of cortical neutrons. We show that the mode of synchrony over these distances depends upon a length scale, λ, which is the minimal path that activity should travel through before meeting its point of origin ready for reactivation. When λ is experimentally made larger than the physical dimension of the network, distant neuronal populations operate synchronously, giving rise to irregularly occurring network-wide events that last hundreds of milliseconds to couple of seconds. In contrast, when λ approaches the dimension of the network, a continuous self-sustained reentry propagation emerges, a regular dynamical mode that is marked by precise spatiotemporal patterns (‘synfire chains’) that may last many minutes. These results contribute to discussions on the origin of different modes of neural synchrony in normal and pathological conditions. synchronization — length-scale — reentry — synfire-chains — disinhibition 1 Significance Statement The mode of synchrony a neural network resumes is a critical determinant of its function. The number of microscopic mechanisms that impact on the macroscopic mode of synchrony is immense. Here we extract a lumped physical parameter (λ), which is the minimal path that activity should travel through before meeting its point of origin ready for reactivation. We show that the value of λ controls the mode of synchrony in a network of biological neurons. As such it promotes the understanding of synchrony modes otherwise masked by the richness of underlying microscopic complexity. The hope is that the insights gained in this study will cater to manipulation of the phenomena in pathological conditions. 1 ar X iv :1 60 3. 01 16 0v 1 [ qbi o. N C ] 3 M ar 2 01 6

2016: Emergence and maintenance of excitability: kinetics over structure
Abstract: None

2016: Chapter 7 Closing Dewey ’ s Circuit
Abstract: One hundred and twenty years ago, the American philosopher and psychologist John Dewey (Fig. 1) published his seminal paper The Reflex Arc Concept in Psychology in the Psychological Review (Dewey, 1896). In this paper, Dewey challenged the reflex arc, a by-then (and since then, as we will soon demonstrate) consensual unifying framework for action and perception. The framework, advanced by European experimental psychologists, pertains to a general interpretation that was referred to, at the time, as “structural psychology.” Advocates of this framework, which Dewey so fiercely opposed, viewed psychological processes as sequences of distinct steps that are executed in a timely and precise manner. The structure of the system—the identity and location of the elements executing the different stages of the process—is at the epicenter of interest. Dewey, a key proponent of the philosophy of Pragmatism and one of the founders of the Chicago group of psychologists, sought to advance an alternative, “functional psychology,” focussing on system-environment interactions and their value in achieving functionally meaningful goals. Functional psychologists did not ignore or deny the impacts of structures and mechanisms inherent to the individual in the emergence of behavior; likewise, structural psychologists did not ignore or deny the functional attributes of behavior. Rather, the main difference between these two strands of academic psychology pertained to the methods that are most likely to produce understanding of behavior. Structuralists sought to identify program-like processes hidden deep inside the machine, the human brain; functionalists could not see how the emergence of behavior can be understood in isolation from coupled subject-environment dynamics. In this context, Marom (2015) offered to use the more indicative terms structural-programmatic and functional-dynamic to designate the two stances. In this chapter, we juxtapose these two stances, discuss the methodological reasons for the dominance of the structural-programmatic stance in neuroscience, and offer closed-loop methodologies as a functional-dynamic alternative for studying action and perception as a complete circuit.

2015: Universality, complexity and the praxis of biology: Two case studies.
Abstract: None

2015: Slow dynamics in features of synchronized neural network responses
Abstract: In this report trial-to-trial variations in the synchronized responses of neural networks are explored over time scales of minutes, in ex-vivo large scale cortical networks. We show that sub-second measures of the individual synchronous response, namely—its latency and decay duration, are related to minutes-scale network response dynamics. Network responsiveness is reflected as residency in, or shifting amongst, areas of the latency-decay plane. The different sensitivities of latency and decay durations to synaptic blockers imply that these two measures reflect aspects of inhibitory and excitatory activities. Taken together, the data suggest that trial-to-trial variations in the synchronized responses of neural networks might be related to effective excitation-inhibition ratio being a dynamic variable over time scales of minutes.

2015: dynamics of neuronal threshold Interactions between network synchrony and the
Abstract: None

2015: Science, Psychoanalysis, and the Brain: Preface and Acknowledgments
Abstract: None

2015: Science, Psychoanalysis, and the Brain: Language Relations
Abstract: None

2015: Science, Psychoanalysis, and the Brain: Sempiterna Temptatio
Abstract: None

