Recent papers for Aharon Ben Tal:

2024: Constructing Uncertainty Sets for Robust Risk Measures: A Composition of $\phi$-Divergences Approach to Combat Tail Uncertainty
Abstract: Risk measures, which typically evaluate the impact of extreme losses, are highly sensitive to misspecification in the tails. This paper studies a robust optimization approach to combat tail uncertainty by proposing a unifying framework to construct uncertainty sets for a broad class of risk measures, given a specified nominal model. Our framework is based on a parametrization of robust risk measures using two (or multiple) $\phi$-divergence functions, which enables us to provide uncertainty sets that are tailored to both the sensitivity of each risk measure to tail losses and the tail behavior of the nominal distribution. In addition, our formulation allows for a tractable computation of robust risk measures, and elicitation of $\phi$-divergences that describe a decision maker's risk and ambiguity preferences.

2022: An Algorithm for Maximizing a Convex Function Based on Its Minimum
Abstract: In this paper, an algorithm for maximizing a convex function over a convex feasible set is proposed. The algorithm, called CoMax, consists of two phases: in phase 1, a feasible starting point is obtained that is used in a gradient ascent algorithm in phase 2. The main contribution of the paper is connected to phase 1; five different methods are used to approximate the original NP-hard problem of maximizing a convex function (MCF) by a tractable convex optimization problem. All the methods use the minimizer of the convex objective function in their construction. In phase 2, the gradient ascent algorithm yields stationary points to the MCF problem. The performance of CoMax is tested on a wide variety of MCF problems, demonstrating its efficiency.

2022: Convex Maximization via Adjustable Robust Optimization
Abstract: Maximizing a convex function over convex constraints is an NP-hard problem in general. We prove that such a problem can be reformulated as an adjustable robust optimization (ARO) problem in which each adjustable variable corresponds to a unique constraint of the original problem. We use ARO techniques to obtain approximate solutions to the convex maximization problem. In order to demonstrate the complete approximation scheme, we distinguish the cases in which we have just one nonlinear constraint and multiple linear constraints. Concerning the first case, we give three examples in which one can analytically eliminate the adjustable variable and approximately solve the resulting static robust optimization problem efficiently. More specifically, we show that the norm constrained log-sum-exp (geometric) maximization problem can be approximated by (convex) exponential cone optimization techniques. Concerning the second case of multiple linear constraints, the equivalent ARO problem can be represented as an adjustable robust linear optimization problem. Using linear decision rules then returns a safe approximation of the constraints. The resulting problem is a convex optimization problem, and solving this problem gives an upper bound on the global optimum value of the original problem. By using the optimal linear decision rule, we obtain a lower bound solution as well. We derive the approximation problems explicitly for quadratic maximization, geometric maximization, and sum-of-max-linear-terms maximization problems with multiple linear constraints. Numerical experiments show that, contrary to the state-of-the-art solvers, we can approximate large-scale problems swiftly with tight bounds. In several cases, we have equal upper and lower bounds, which concludes that we have global optimality guarantees in these cases. Summary of Contribution: Maximizing a convex function over a convex set is a hard optimization problem. We reformulate this problem as an optimization problem under uncertainty, which allows us to transfer the hardness of this problem from its nonconvexity to the uncertainty of the new problem. The equivalent uncertain optimization problem can be relaxed tightly by using adjustable robust optimization techniques. In addition to building a new bridge between convex maximization and robust optimization, this approach also gives us strong algorithms that improve the state-of-the-art optimization solvers both in solution time and quality for various convex maximization problems.

2022: Code and Data Repository for An Algorithm for Maximizing a Convex Function Based on its Minimum
Abstract: The goal of this software is to maximize convex functions over a convex feasible set.

2021: Beyond local optimality conditions: the case of maximizing a convex function
Abstract: In this paper, we design an algorithm for maximizing a convex function over a convex feasible set. The algorithm consists of two phases: in phase 1 a feasible solution is obtained that is used as an initial starting point in phase 2. In the latter, a biconvex problem equivalent to the original problem is solved by employing an alternating direction method. The main contribution of the paper is connected to the first phase. We identify a kind of global optimality condition which says that “The maximizer of a convex objective function is the furthest point from the minimizer”. Using this principle, we develop several ways to compute this ‘furthest point’, focusing on methods that lead to computationally efficient algorithms. The performance of the overall algorithm is tested on a wide variety of problems, demonstrating its efficiency.

2020: Tractable approximation of hard uncertain optimization problems
Abstract: ,

2018: The Power of Duality
Abstract: None

2018: Robust Optimization with Ambiguous Stochastic Constraints Under Mean and Dispersion Information
Abstract: In this paper we consider ambiguous stochastic constraints under partial information consisting of means and dispersion measures of the underlying random parameters. Whereas the past literature used the variance as the dispersion measure, here we use the mean absolute deviation from the mean (MAD). This makes it possible to use the 1972 result of Ben-Tal and Hochman (BH) in which tight upper and lower bounds on the expectation of a convex function of a random variable are given. First, we use these results to treat ambiguous expected feasibility constraints to obtain exact reformulations for both functions that are convex and concave in the components of the random variable. This approach requires, however, the independence of the random variables and, moreover, may lead to an exponential number of terms in the resulting robust counterparts. We then show how upper bounds can be constructed that alleviate the independence restriction, and require only a linear number of terms, by exploiting models in which random variables are linearly aggregated. Moreover, using the BH bounds we derive three new safe tractable approximations of chance constraints of increasing computational complexity and quality. In a numerical study, we demonstrate the efficiency of our methods in solving stochastic optimization problems under mean-MAD ambiguity.

2018: A tractable approach for designing piecewise affine policies in two-stage adjustable robust optimization
Abstract: None

2018: A multi-period unit commitment problem under a new hybrid uncertainty set for a renewable energy source
Abstract: None

2017: Extending the Scope of Robust Quadratic Optimization
Abstract: We derive computationally tractable formulations of the robust counterparts of convex quadratic and conic quadratic constraints that are concave in matrix-valued uncertain parameters. We do this for a broad range of uncertainty sets. Our results provide extensions to known results from the literature. We also consider hard quadratic constraints: those that are convex in uncertain matrix-valued parameters. For the robust counterpart of such constraints, we derive inner and outer tractable approximations. As an application, we show how to construct a natural uncertainty set based on a statistical confidence set around a sample mean vector and covariance matrix and use this to provide a tractable reformulation of the robust counterpart of an uncertain portfolio optimization problem. We also apply the results of this paper to norm approximation problems. Summary of Contribution: This paper develops new theoretical results and algorithms that extend the scope of a robust quadratic optimization problem. More specifically, we derive computationally tractable formulations of the robust counterparts of convex quadratic and conic quadratic constraints that are concave in matrix-valued uncertain parameters. We also consider hard quadratic constraints: those that are convex in uncertain matrix-valued parameters. For the robust counterpart of such constraints, we derive inner and outer tractable approximations.

2017: Computing the Channel Capacity of a Communication System Affected by Uncertain Transition Probabilities
Abstract: We study the problem of computing the capacity of a discrete memoryless channel under uncertainty affecting the channel law matrix, and possibly with a constraint on the average cost of the input distribution. The problem has been formulated in the literature as a max–min problem. We use the robust optimization methodology to convert the max–min problem to a standard convex optimization problem. For small-sized problems, and for many types of uncertainty, such a problem can be solved in principle using interior point methods (IPMs). However, for large-scale problems, IPMs are not practical. Here, we suggest an <inline-formula> <tex-math notation="LaTeX">$\mathcal {O}(1/T)$ </tex-math></inline-formula> first-order algorithm based on <xref ref-type="bibr" rid="ref1">[1]</xref> which is applied directly to the max–min problem.

2017: Robust optimization of uncertain multistage inventory systems with inexact data in decision rules
Abstract: None

2016: Robust optimization of uncertain multistage inventory systems with inexact data in decision rules
Abstract: None

2016: On the average performance of the adjustable RO and its use as an offline tool for multi-period production planning under uncertainty
Abstract: None

2016: Computational Methods for Solving Nonconvex Block-Separable Constrained Quadratic Problems
Abstract: Nonconvex quadratically constrained quadratic programs (QCQPs) with block-separable convex constraints are generally NP-hard. These kinds of problems appear in many applications such as estimation and control, complex unimodular programming, and MAX-CUT type problems. Semidefinite relaxation is the best known upper bound approximation for QCQP with block-separable constraints. We suggest the block optimal descent (BOD) algorithm to obtain a lower approximation. We show that this algorithm utilizes block hidden convexity to apply block alternating minimization and has a sublinear rate of convergence. An improved approximation is obtained by using a novel approach, Lagrange guided descent (LGD), which finds a “good” initial point based on the semidefinite programming (SDP) relaxation solution. A quantitative study shows the LGD has superior performance over BOD.

2016: On the average performance of the adjustable RO and its use as an offline tool for multi-period production planning under uncertainty
Abstract: None

2016: A Tractable Approach for designing Piecewise Affine Policies in Dynamic Robust Optimization
Abstract: We consider the problem of designing piecewise affine policies for two-stage adjustable robust linear optimization problems under right hand side uncertainty. It is well known that a piecewise affine policy is optimal although the number of pieces can be exponentially large. A significant challenge in designing a practical piecewise affine policy is constructing good pieces of the uncertainty set. Here we address this challenge by introducing a new framework in which the uncertainty set is “approximated” by a “dominating” simplex. The corresponding policy is then based on the map from the uncertainty set to the simplex. Although our piecewise affine policy has exponentially many pieces, it can be computed efficiently by solving a compact linear program. Furthermore, the performance of our policy is significantly better than the affine policy for many important uncertainty sets both theoretically and numerically. For instance, for hypersphere uncertainty set, our piecewise affine policy can be computed by an LP and gives a O(m)-approximation whereas the affine policy requires us to solve a second order cone program and has a worst-case performance bound of O( √ m). To the best of our knowledge, this is the first tractable approach for designing piecewise affine policies with significantly improved theoretical performance guarantees.

2015: Globalized Robust Optimization for Nonlinear Uncertain Inequalities
Abstract: Robust optimization is a methodology that can be applied to problems that are affected by uncertainty in the problem’s parameters. The classical robust counterpart (RC) of the problem requires the solution to be feasible for all uncertain parameter values in a so-called uncertainty set, and offers no guarantees for parameter values outside this uncertainty set. The globalized robust counterpart (GRC) extends this idea by allowing controlled constraint violations in a larger uncertainty set. The constraint violations are controlled by the distance of the parameter to the original uncertainty set. We derive tractable GRCs that extend the initial GRCs in the literature: our GRC is applicable to nonlinear constraints instead of only linear or conic constraints, and the GRC is more flexible with respect to both the uncertainty set and distance measure function, which are used to control the constraint violations. In addition, we present a GRC approach that can be used to provide an extended trade-off overview between the objective value and several robustness measures.

2015: Exact Robust Counterparts of Ambiguous Stochastic Constraints Under Mean and Dispersion Information
Abstract: In this paper we consider ambiguous stochastic constraints under partial information consisting of means and dispersion measures of the underlying random parameters. Whereas the past literature used the variance as the dispersion measure, here we use the mean absolute deviation from the mean (MAD). This makes it possible to use the old result of Ben-Tal and Hochman (1972) in which tight upper and lower bounds on the expectation of a convex function of a random variable are given. We use these bounds to derive exact robust counterparts of expected feasibility of convex constraints and to construct new safe tractable approximations of chance constraints. Numerical examples show our method to be applicable to numerous applications of Robust Optimization, e.g., where implementation error or linear decision rules are present. Also, we show that the methodology can be used for optimization the average-case performance of worst-case optimal Robust Optimization solutions.

