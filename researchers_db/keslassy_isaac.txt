Recent papers for Keslassy Isaac:

2023: Dragonfly: In-Flight CCA Identification
Abstract: We introduce the Dragonfly system, which is designed to classify on the fly the congestion control algorithm of any flow that crosses a given router, starting at any time, and quickly reach a reasonable accuracy. To do so, we discuss the unique challenges of real-time congestion control classification. We explain how the number of bytes of the flow within the shared router queue contains an intrinsic memory that significantly helps real-time classification. However, we show that this number of bytes is not straightforward to compute in real time, and introduce ways to do so. We further design an eBPF-based scalable traffic-collection system that helps dynamically filter specific flows at high rates. Finally, we evaluate our Dragonfly system using a variety of platforms, and show that it clearly outperforms state-of-the-art algorithms.

2023: QueuePilot: Reviving Small Buffers With a Learned AQM Policy
Abstract: There has been much research effort on using small buffers in backbone routers, to provide lower delays for users and free up capacity for vendors. Unfortunately, with small buffers, the droptail policy has an excessive loss rate, and existing AQM (active queue management) policies can be unreliable.We introduce QueuePilot, an RL (reinforcement learning)-based AQM that enables small buffers in backbone routers, trading off high utilization with low loss rate and short delay. QueuePilot automatically tunes the ECN (early congestion notification) marking probability. After training once offline with a variety of settings, QueuePilot produces a single lightweight policy that can be applied online without further learning. We evaluate QueuePilot on real networks with hundreds of TCP connections, and show how its performance in small buffers exceeds that of existing algorithms, and even exceeds their performance with larger buffers.

2022: CloudPilot: Flow Acceleration in the Cloud
Abstract: TCP-split proxies have been previously studied as an efficient mechanism to improve the rate of connections with large round trip times. These works focused on improving a single flow. In this paper, we investigate how strategically deploying TCP-split proxies in the cloud can improve the performance of geo-distributed applications entailing multiple flows interconnecting globally-distributed sources and destinations using different communication patterns, and being subject to budget limitations. We present CloudPilot, a Kubernetes-based system that measures communication parameters across different cloud regions, and uses these measurements to deploy cloud proxies in optimized locations on multiple cloud providers. To this end, we model cloud proxy acceleration and define a novel cloud-proxy placement problem. Since this problem is NP-Hard, we suggest a few efficient heuristics to solve it. Finally, we find that our cloud-proxy optimization can improve performance by an average of 3.6× for four different use cases.

2021: Load balancing with JET: just enough tracking for connection consistency
Abstract: Hash-based stateful load-balancers employ connection tracking to avoid per-connection-consistency (PCC) violations that lead to broken connections. In this paper, we propose Just Enough Tracking (JET), a new algorithmic framework that significantly reduces the size of the connection tracking tables for hash-based stateful load-balancers without increasing PCC violations. Under mild assumptions on how backend servers are added, JET adapts consistent hash techniques to identify which connections do not need to be tracked. We provide a model to identify these safe connections and a pluggable framework with appealing theoretical guarantees that supports a variety of consistent hash and connection-tracking modules. We implement JET in two different environments and with four different consistent hash techniques. Using a series of evaluations, we demonstrate that JET requires connection-tracking tables that are an order of magnitude smaller than those required with full connection tracking while preserving PCC and balance properties. In addition, JET often increases the lookup rate due to improved caching.

2021: On the Persistent-Idle Load Distribution Policy Under Batch Arrivals and Random Service Capacity
Abstract: Practical considerations of present technological uses of load-balancing policies include the capability to function under server heterogeneity and the need to reduce communication overhead associated with information about the queue states. Under such constraints, state-of-the-art loadbalancing approaches either do not cover the full stability region or provide poor performance. To address this challenge, the Persistent-Idle (PI) policy was recently introduced, where servers only update the dispatcher when they become idle, and the dispatcher always sends jobs to the last server that reported being idle. This policy was proved to achieve the stability region and to operate with low communication overhead (in a sense made precise) for Bernoulli arrivals and heterogeneous servers under the assumption that their service capacities are deterministic and constant. Aiming at a broader range of models that are relevant in applications, we consider in this paper batch arrivals and service capacities that vary over time according to stochastic processes, that may have distinct statistical characteristics across servers. Our main theoretical contribution is to show that the stability region is achieved by this policy in the case of two servers. Then, using extensive simulations, the performance is evaluated for a larger number of heterogeneous servers. PI always appears to be stable and achieves good performance while incurring a negligible communication overhead.

2020: Persistent-Idle Load-Distribution
Abstract: A parallel server system is considered in which a dispatcher routes incoming jobs to a fixed number of heterogeneous servers, each with its own queue. Much effort has been previously made to design policies that use limited state information (e.g., the queue lengths in a small subset of the set of servers, or the identity of the idle servers). However, existing policies either do not achieve the stability region or perform poorly in terms of job completion time. We introduce Persistent-Idle (PI), a new, perhaps counterintuitive, load-distribution policy that is designed to work with limited state information. Roughly speaking, PI always routes to the server that has last been idle. Our main result is that this policy achieves the stability region. Because it operates quite differently from existing policies, our proof method differs from standard arguments in the literature. Specifically, large time properties of reflected random walk, along with a careful choice of a Lyapunov function, are combined to obtain a Lyapunov condition over sufficiently long-time intervals. We also provide simulation results that indicate that job completion times under PI are low for different choices of system parameters, compared with several state-of-the-art load-distribution schemes.

2020: Sequential Zeroing: Online Heavy-Hitter Detection on Programmable Hardware
Abstract: F1ows that have exceeded a given percentage of the last sliding window of N packets, denoted as heavy-hitter flows, require special handling, since they may disrupt the service of other flows or may be indicative of malicious traffic. However, even when equipped with a programmable switch, it is unclear how to detect heavy hitters on a per-packet basis, while obeying the stringent switch memory access rates. For instance, existing solutions, such as HashPipe, cannot detect heavy hitters without halving the line rate and do not support sliding windows. To the best of our knowledge, this paper is the first to present heavy-hitter detection solutions that provide per-packet granularity at line-rate performance. We realize this by introducing (1) Modulo sketching, a novel counting algorithm that reuses counters and limits the impact of smaller flows beyond early processing stages; and (2) Sequential Zeroing, a new approach to extending interval-based schemes to sliding window measurements. Our solutions are extensively evaluated, both via simulations and experiments on a Netronome SmartNIC, and demonstrate significant performance gains over the state-of-theart.

2020: LSQ: Load Balancing in Large-Scale Heterogeneous Systems With Multiple Dispatchers
Abstract: Nowadays, the efficiency and even the feasibility of traditional load-balancing policies are challenged by the rapid growth of cloud infrastructure and the increasing levels of server heterogeneity. In such heterogeneous systems with many load-balancers, traditional solutions, such as <inline-formula> <tex-math notation="LaTeX">$JSQ$ </tex-math></inline-formula>, incur a prohibitively large communication overhead and detrimental incast effects due to herd behavior. Alternative low-communication policies, such as <inline-formula> <tex-math notation="LaTeX">$JSQ(d)$ </tex-math></inline-formula> and the recently proposed <inline-formula> <tex-math notation="LaTeX">$JIQ$ </tex-math></inline-formula>, are either unstable or provide poor performance. We introduce the <italic>Local Shortest Queue (</italic> <inline-formula> <tex-math notation="LaTeX">$LSQ$ </tex-math></inline-formula><italic>)</italic> family of load balancing algorithms. In these algorithms, each dispatcher maintains its own, local, and possibly outdated view of the server queue lengths, and keeps using <inline-formula> <tex-math notation="LaTeX">$JSQ$ </tex-math></inline-formula> on its local view. A small communication overhead is used infrequently to update this local view. We formally prove that as long as the error in these local estimates of the server queue lengths is bounded <italic>in expectation</italic>, the entire system is strongly stable. Finally, in simulations, we show how simple and stable <inline-formula> <tex-math notation="LaTeX">$LSQ$ </tex-math></inline-formula> policies exhibit appealing performance and significantly outperform existing low-communication policies, while using an equivalent communication budget. In particular, our simple policies often outperform even <inline-formula> <tex-math notation="LaTeX">$JSQ$ </tex-math></inline-formula> due to their reduction of herd behavior. We further show how, by relying on smart servers (<italic>i.e.,</italic> advanced pull-based communication), we can further improve performance and lower communication overhead.

2019: Sizing router buffers (redux)
Abstract: The queueing delay faced by a packet is arguably the largest source of uncertainty during its journey. It therefore seems crucial that we understand how big the buffers should be in Internet routers. Our 2004 Sigcomm paper revisited the existing rule of thumb that a buffer should hold one bandwidth-delay product of packets. We claimed that for long-lived TCP flows, it could be reduced by √N, where N is the number of active flows, potentially reducing the required buffers by well over 90% in Internet backbone routers. One might reasonably expect that such a result, which supports cheaper routers with smaller buffers, would be embraced by the ISP community. In this paper we revisit the result 15 years later, and explain where it has succeeded and failed to affect how buffers are sized.

2019: Replicate to the shortest queues
Abstract: None

2019: Links as a Service (LaaS): Guaranteed Tenant Isolation in the Shared Cloud
Abstract: The most demanding tenants of shared clouds require complete isolation from their neighbors, in order to guarantee that their application performance is not affected by other tenants. Unfortunately, while shared clouds can offer an option, whereby tenants obtain dedicated servers, they do not offer any network provisioning service, which would shield these tenants from network interference. In this paper, we introduce links as a service (LaaS), a new abstraction for cloud service that provides isolation of network links. Each tenant gets an exclusive set of links forming a virtual fat-tree, and is guaranteed to receive the exact same bandwidth and delay as if it were alone in the shared cloud. Consequently, each tenant can use the forwarding method that best fits its application. Under simple assumptions, using bipartite graph properties and pigeonhole-based analysis, we derive theoretical conditions for enabling the LaaS without capacity over-provisioning in fat-trees. New tenants are only admitted in the network, when they can be allocated hosts and links that maintain these conditions. We also provide new results on the numbers of tenants and hosts that can fit while guaranteeing network isolation. The LaaS is implementable with common network gear, tested to scale to large networks, and provides full tenant isolation at the cost of a limited reduction in the cloud utilization.

2019: Subdiffusive Load Balancing in Time-Varying Queueing Systems
Abstract: The degree to which delays or queue lengths equalize under load-balancing algorithms gives a good indication of their performance. Some of the most well-known results in this context are concerned with the asymptotic behavior of the delay or queue length at the diffusion scale under a critical load condition, where arrival and service rates do not vary with time. For example, under the join-the-shortest-queue policy, the queue length deviation process, defined as the difference between the greatest and smallest queue length as it varies over time, is at a smaller scale (subdiffusive) than that of queue lengths (diffusive).

2019: RADE: resource-efficient supervised anomaly detection using decision tree-based ensemble methods
Abstract: None

2018: When Bh Sequences Meet Bloom Filters
Abstract: Bloom filters and Counting Bloom Filters (CBFs) are widely used in networking device algorithms. They implement fast set representations to support membership queries with limited error. Unlike Bloom filters, CBFs also support element deletions. In the first part of the talk, I will introduce a new general method based on variable increments to improve the efficiency of CBFs and their variants. I will demonstrate that this method can always achieve a lower false positive rate and a lower overflow probability bound than CBFs in practical systems.

2018: Memento: Making Sliding Windows Efficient for Heavy Hitters
Abstract: Cloud operators require timely identification of Heavy Hitters (HH) and Hierarchical Heavy Hitters (HHH) for applications such as load balancing, traffic engineering, and attack mitigation. However, existing techniques are slow in detecting new heavy hitters. In this paper, we present the case for identifying heavy hitters through sliding windows. Sliding windows are quicker and more accurate to detect new heavy hitters than current interval-based methods, but to date had no practical algorithms. Accordingly, we introduce, design, and analyze the Memento family of sliding window algorithms for the HH and HHH problems in the single-device and network-wide settings. We use extensive evaluations to show that our single-device solutions are orders of magnitude faster than existing sliding window techniques and comparable in speed to state-of-the-art non-windowed sampling based technique. Furthermore, we exemplify our network-wide HHH detection capabilities on a realistic testbed. To that end, we implemented Memento as an open-source extension to the popular HAProxy cloud load-balancer. In our evaluations, using an HTTP flood by 50 subnets, our network-wide approach detected the new subnets faster and reduced the number of undetected flood requests by up to $37\times $ compared to the alternatives.

2018: AnchorHash: A Scalable Consistent Hash
Abstract: Consistent hashing is a central building block in many networking applications, such as maintaining connection affinity of TCP flows. However, current consistent hashing solutions do not ensure full consistency under arbitrary changes or scale poorly in terms of memory footprint, update time and key lookup complexity. We present AnchorHash, a scalable and fully-consistent hashing algorithm. AnchorHash achieves high key lookup rate, low memory footprint and low update time. We formally establish its strong theoretical guarantees, and present an advanced implementation with a memory footprint of only a few bytes per resource. Moreover, evaluations indicate that AnchorHash scales on a single core to 100 million resources while still achieving a key lookup rate of more than 15 million keys per second.

2018: Pied Piper: Rethinking Internet Data Delivery
Abstract: We contend that, analogously to the transition from resource-limited on-prem computing to resource-abundant cloud computing, Internet data delivery should also be adapted to a reality in which the cloud offers a virtually unlimited resource, i.e., network capacity, and virtualization enables delegating local tasks, such as routing and congestion control, to the cloud. This necessitates rethinking the traditional roles of inter- and intra-domain routing and conventional end-to-end congestion control. 
We introduce Optimized Cloudified Delivery (OCD), a holistic approach for optimizing joint Internet/cloud data delivery, and evaluate OCD through hundreds of thousands of file downloads from multiple locations. We start by examining an OCD baseline approach: traffic from a source A to a destination B successively passes through two cloud virtual machines operating as relays - nearest to A and B; and the two cloud relays employ TCP split. 
We show that even this naive strategy can outperform recently proposed improved end-to-end congestion control paradigms (BBR and PCC) by an order of magnitude. 
Next, we present a protocol-free, ideal pipe model of data transmission, and identify where today's Internet data delivery mechanisms diverge from this model. We then design and implement OCD Pied Piper. Pied Piper leverages various techniques, including novel kernel-based transport-layer accelerations, to improve the Internet-Cloud interface so as to approximately match the ideal network pipe model.

2018: Unspread the Jam: Scheduling Traffic Lights to Reduce Congestion
Abstract: In this paper, we consider the practical problem of scheduling traffic lights to reduce the average vehicle waiting times. We find that existing scheduling algorithms have lackluster performance. Instead, we introduce two algorithms. First, extended CMSM (eCMSM), which extends CMSM from a switch scheduling model to a general traffic-light scheduling model. We prove that eCMSM can optimally schedule any traffic batch. Second, we introduce Front-Pressure (FP), which aims to further reduce the average waiting time at general intersections. We then evaluate empirically these two algorithms. We find that when using them, the best average waiting time can be improved in 98% of the simulations when compared to several existing algorithms, most significantly in congested settings.

2017: Randomized load balancing in heavy tra c
Abstract: We consider three randomized schemes for load balancing among a xed number, N , of resources, and analyze them in the heavy tra c limit. The rst is join the shortest queue, where arrivals are routed to the shortest among d randomly chosen queues, where d ∈ {2, . . . , N}. The second is redundancy routing, where jobs are replicated d times, routed simultaneously to d randomly chosen queues, and all but the rst copy to be admitted into service are canceled. The third model, that we refer to as replicate to the shortest queues, combines the rst two policies, by replicating d times but sending the copies to the shortest d out of the N queues. We show that under the rst two policies, randomized load balancing dramatically a ects the heavy tra c asymptotics. Namely, it gives rise to di usion scale perturbations of the queue length away from zero, where otherwise (i.e., when d = 1) these perturbations are at the uid scale. For all three models, su cient conditions for state space collapse are provided, and di usion limits are established. AMS subject classi cation: 60F170, 60J60, 60K25, 93E20

2017: Routing Keys
Abstract: The network plays a key role in High-Performance Computing (HPC) system efficiency. Unfortunately, current HPC routing solutions are not application-aware, and therefore cannot deal with the sudden HPC traffic bursts and their resulting congestion peaks.To address this problem, we introduce Routing Keys, a scalable routing paradigm for HPC networks that decouples intra- and inter-application flow contention. Our Application Routing Key (ARK) algorithm proactively allows each self-aware application to route its flows according to a predetermined routing key, i.e., its own intra-application contention-free routing. In addition, in our Network Routing Key (NRK) algorithm, a centralized scheduler chooses between several routing keys for the communication phases of each application, and therefore reduces inter-application contention while maintaining intra-application contention-free routing and avoiding scalability issues. Using extensive evaluations, we show that both ARK and NRK significantly improve the communication runtime by up to 2.7x.

