Recent papers for Sason Igal:

2025: On Counting H-Intersecting Families and Graph Homomorphisms
Abstract: This work leverages Shearer's inequalities to derive a new upper bound on the maximum cardinality of a family of graphs on a fixed number of vertices, in which every pair of graphs shares a fixed common subgraph. The derived bound is expressed in terms of the chromatic number of the shared subgraph. Additionally, Shearer's inequalities, in conjunction with properties of the Shannon entropy, are employed to establish bounds related to the enumeration of graph homomorphisms, providing further insights into the interplay between combinatorial structures and information-theoretic principles.

2024: On Spectral Graph Determination
Abstract: The study of spectral graph determination is a fascinating area of research in spectral graph theory and algebraic combinatorics. This field focuses on examining the spectral characterization of various classes of graphs, developing methods to construct or distinguish cospectral nonisomorphic graphs, and analyzing the conditions under which a graph’s spectrum uniquely determines its structure. This paper presents an overview of both classical and recent advancements in these topics, along with newly obtained proofs of some existing results, which offer additional insights.

2023: Observations on graph invariants with the Lovász $ \vartheta $-function
Abstract: This paper delves into three research directions, leveraging the Lovász $ \vartheta $-function of a graph. First, it focuses on the Shannon capacity of graphs, providing new results that determine the capacity for two infinite subclasses of strongly regular graphs, and extending prior results. The second part explores cospectral and nonisomorphic graphs, drawing on a work by Berman and Hamud (2024), and it derives related properties of two types of joins of graphs. For every even integer such that $ n \geq 14 $, it is constructively proven that there exist connected, irregular, cospectral, and nonisomorphic graphs on $ n $ vertices, being jointly cospectral with respect to their adjacency, Laplacian, signless Laplacian, and normalized Laplacian matrices, while also sharing identical independence, clique, and chromatic numbers, but being distinguished by their Lovász $ \vartheta $-functions. The third part focuses on establishing bounds on graph invariants, particularly emphasizing strongly regular graphs and triangle-free graphs, and compares the tightness of these bounds to existing ones. The paper derives spectral upper and lower bounds on the vector and strict vector chromatic numbers of regular graphs, providing sufficient conditions for the attainability of these bounds. Exact closed-form expressions for the vector and strict vector chromatic numbers are derived for all strongly regular graphs and for all graphs that are vertex- and edge-transitive, demonstrating that these two types of chromatic numbers coincide for every such graph. This work resolves a query regarding the variant of the $ \vartheta $-function by Schrijver and the identical function by McEliece et al. (1978). It shows, by a counterexample, that the $ \vartheta $-function variant by Schrijver does not possess the property of the Lovász $ \vartheta $-function of forming an upper bound on the Shannon capacity of a graph. This research paper also serves as a tutorial of mutual interest in zero-error information theory and algebraic graph theory.

2023: Observations on the Lovász θ-Function, Graph Capacity, Eigenvalues, and Strong Products
Abstract: This paper provides new observations on the Lovász θ-function of graphs. These include a simple closed-form expression of that function for all strongly regular graphs, together with upper and lower bounds on that function for all regular graphs. These bounds are expressed in terms of the second-largest and smallest eigenvalues of the adjacency matrix of the regular graph, together with sufficient conditions for equalities (the upper bound is due to Lovász, followed by a new sufficient condition for its tightness). These results are shown to be useful in many ways, leading to the determination of the exact value of the Shannon capacity of various graphs, eigenvalue inequalities, and bounds on the clique and chromatic numbers of graphs. Since the Lovász θ-function factorizes for the strong product of graphs, the results are also particularly useful for parameters of strong products or strong powers of graphs. Bounds on the smallest and second-largest eigenvalues of strong products of regular graphs are consequently derived, expressed as functions of the Lovász θ-function (or the smallest eigenvalue) of each factor. The resulting lower bound on the second-largest eigenvalue of a k-fold strong power of a regular graph is compared to the Alon–Boppana bound; under a certain condition, the new bound is superior in its exponential growth rate (in k). Lower bounds on the chromatic number of strong products of graphs are expressed in terms of the order and the Lovász θ-function of each factor. The utility of these bounds is exemplified, leading in some cases to an exact determination of the chromatic numbers of strong products or strong powers of graphs. The present research paper is aimed to have tutorial value as well.

2022: Information Inequalities via Submodularity and a Problem in Extremal Graph Theory
Abstract: The present paper offers, in its first part, a unified approach for the derivation of families of inequalities for set functions which satisfy sub/supermodularity properties. It applies this approach for the derivation of information inequalities with Shannon information measures. Connections of the considered approach to a generalized version of Shearer’s lemma, and other related results in the literature are considered. Some of the derived information inequalities are new, and also known results (such as a generalized version of Han’s inequality) are reproduced in a simple and unified way. In its second part, this paper applies the generalized Han’s inequality to analyze a problem in extremal graph theory. This problem is motivated and analyzed from the perspective of information theory, and the analysis leads to generalized and refined bounds. The two parts of this paper are meant to be independently accessible to the reader.

2022: Divergence Measures: Mathematical Foundations and Applications in Information-Theoretic and Statistical Problems
Abstract: Data science, information theory, probability theory, statistical learning, statistical signal processing, and other related disciplines greatly benefit from non-negative measures of dissimilarity between pairs of probability measures [...].

2021: On Two-Stage Guessing
Abstract: Stationary memoryless sources produce two correlated random sequences Xn and Yn. A guesser seeks to recover Xn in two stages, by first guessing Yn and then Xn. The contributions of this work are twofold: (1) We characterize the least achievable exponential growth rate (in n) of any positive ρ-th moment of the total number of guesses when Yn is obtained by applying a deterministic function f component-wise to Xn. We prove that, depending on f, the least exponential growth rate in the two-stage setup is lower than when guessing Xn directly. We further propose a simple Huffman code-based construction of a function f that is a viable candidate for the minimization of the least exponential growth rate in the two-stage guessing setup. (2) We characterize the least achievable exponential growth rate of the ρ-th moment of the total number of guesses required to recover Xn when Stage 1 need not end with a correct guess of Yn and without assumptions on the stationary memoryless sources producing Xn and Yn.

2021: A Generalized Information-Theoretic Approach for Bounding the Number of Independent Sets in Bipartite Graphs
Abstract: This paper studies the problem of upper bounding the number of independent sets in a graph, expressed in terms of its degree distribution. For bipartite regular graphs, Kahn (2001) established a tight upper bound using an information-theoretic approach, and he also conjectured an upper bound for general graphs. His conjectured bound was recently proved by Sah et al. (2019), using different techniques not involving information theory. The main contribution of this work is the extension of Kahn’s information-theoretic proof technique to handle irregular bipartite graphs. In particular, when the bipartite graph is regular on one side, but may be irregular on the other, the extended entropy-based proof technique yields the same bound as was conjectured by Kahn (2001) and proved by Sah et al. (2019).

2021: On Strong Data-Processing and Majorization Inequalities with Applications to Coding Problems
Abstract: This work provides data-processing and majorization inequalities for f -divergences, and it considers some of their applications to coding problems. This work also provides tight bounds on the Rényi entropy of a function of a discrete random variable with a finite number of possible values, where the considered function is not one-to-one, and their derivation is based on majorization and the Schur-concavity of the Rényi entropy. One application of the f -divergence inequalities refers to the performance analysis of list decoding with either fixed or variable list sizes; some earlier bounds on the list decoding error probability are reproduced in a unified way, and new bounds are obtained and exemplified numerically. Another application is related to a study of the quality of approximating a probability mass function, which is induced by the leaves of a Tunstall tree, by an equiprobable distribution. The compression rates of finite-length Tunstall codes are further analyzed for asserting their closeness to the Shannon entropy of a memoryless and stationary discrete source. In view of the tight bounds for the Rényi entropy and the work by Campbell, non-asymptotic bounds are derived for lossless data compression of discrete memoryless sources.

2021: Entropy-Based Proofs of Combinatorial Results on Bipartite Graphs
Abstract: This work considers new entropy-based proofs of some known, or otherwise refined, combinatorial bounds for bipartite graphs. These include upper bounds on the number of the independent sets, lower bounds on the minimal number of colors in constrained edge coloring, and lower bounds on the number of walks of a given length in bipartite graphs. The proofs of these combinatorial results rely on basic properties of the Shannon entropy.

2020: On Relations Between the Relative Entropy and χ2-Divergence, Generalizations and Applications
Abstract: This paper is focused on a study of integral relations between the relative entropy and the chi-squared divergence, which are two fundamental divergence measures in information theory and statistics, a study of the implications of these relations, their information-theoretic applications, and some generalizations pertaining to the rich class of f-divergences. Applications that are studied in this paper refer to lossless compression, the method of types and large deviations, strong data–processing inequalities, bounds on contraction coefficients and maximal correlation, and the convergence rate to stationarity of a type of discrete-time Markov chains.

2020: An Information-Theoretic Proof of a Bound on the Number of Independent Sets in Bipartite Graphs
Abstract: The present paper provides an information-theoretic proof of Kahn's conjecture (2001) for a tight upper bound on the number of independent sets in a graph, where our proof applies to bipartite graphs that are regular on one side (the other side may be irregular). It extends the entropy-based proof for regular bipartite graphs (Kahn, 2001). This conjecture has been recently proved for general graphs by a group at MIT (2019), utilizing an interesting approach which is unrelated to information theory.

2020: An Information-Theoretic Proof of a Tight Bound on the Number of Independent Sets in Graphs
Abstract: The present paper provides an information-theoretic proof of Kahn’s conjecture (2001) for a tight upper bound on the number of independent sets in irregular graphs. This conjecture has been recently proved by a group at MIT (2019), by utilizing an interesting approach which is unrelated to information theory. This work provides an alternative, information-theoretic, proof which generalizes Kahn’s proof in the regular setting to the general (irregular) setting. The present proof partially relies on a proper utilization of Shearer’s lemma.

2020: Some Useful Integral Representations for Information-Theoretic Analyses
Abstract: This work is an extension of our earlier article, where a well-known integral representation of the logarithmic function was explored and was accompanied with demonstrations of its usefulness in obtaining compact, easily-calculable, exact formulas for quantities that involve expectations of the logarithm of a positive random variable. Here, in the same spirit, we derive an exact integral representation (in one or two dimensions) of the moment of a nonnegative random variable, or the sum of such independent random variables, where the moment order is a general positive non-integer real (also known as fractional moments). The proposed formula is applied to a variety of examples with an information-theoretic motivation, and it is shown how it facilitates their numerical evaluations. In particular, when applied to the calculation of a moment of the sum of a large number, n, of nonnegative random variables, it is clear that integration over one or two dimensions, as suggested by our proposed integral representation, is significantly easier than the alternative of integrating over n dimensions, as needed in the direct calculation of the desired moment.

2020: Exact Expressions in Source and Channel Coding Problems Using Integral Representations
Abstract: We explore known integral representations of the logarithmic and power functions, and demonstrate their usefulness for information-theoretic analyses. We obtain compact, easily–computable exact formulas for several source and channel coding problems that involve expectations and higher moments of the logarithm of a positive random variable and the moment of order ρ>0 of a non-negative random variable (or the sum of i.i.d. positive random variables). These integral representations are used in a variety of applications, including the calculation of the degradation in mutual information between the channel input and output as a result of jamming, universal lossless data compression, Shannon and Rényi entropy evaluations, and the ergodic capacity evaluation of the single-input, multiple–output (SIMO) Gaussian channel with random parameters (known to both transmitter and receiver). The integral representation of the logarithmic function and its variants are anticipated to serve as a rigorous alternative to the popular (but non–rigorous) replica method (at least in some situations).

2019: On Data-Processing and Majorization Inequalities for f-Divergences with Applications
Abstract: This paper is focused on the derivation of data-processing and majorization inequalities for f-divergences, and their applications in information theory and statistics. For the accessibility of the material, the main results are first introduced without proofs, followed by exemplifications of the theorems with further related analytical results, interpretations, and information-theoretic applications. One application refers to the performance analysis of list decoding with either fixed or variable list sizes; some earlier bounds on the list decoding error probability are reproduced in a unified way, and new bounds are obtained and exemplified numerically. Another application is related to a study of the quality of approximating a probability mass function, induced by the leaves of a Tunstall tree, by an equiprobable distribution. The compression rates of finite-length Tunstall codes are further analyzed for asserting their closeness to the Shannon entropy of a memoryless and stationary discrete source. Almost all the analysis is relegated to the appendices, which form the major part of this manuscript.

2019: An Integral Representation of the Logarithmic Function with Applications in Information Theory
Abstract: We explore a well-known integral representation of the logarithmic function, and demonstrate its usefulness in obtaining compact, easily computable exact formulas for quantities that involve expectations and higher moments of the logarithm of a positive random variable (or the logarithm of a sum of i.i.d. positive random variables). The integral representation of the logarithm is proved useful in a variety of information-theoretic applications, including universal lossless data compression, entropy and differential entropy evaluations, and the calculation of the ergodic capacity of the single-input, multiple-output (SIMO) Gaussian channel with random parameters (known to both transmitter and receiver). This integral representation and its variants are anticipated to serve as a useful tool in additional applications, as a rigorous alternative to the popular (but non-rigorous) replica method (at least in some situations).

2018: Tight Bounds on the Rényi Entropy via Majorization with Applications to Guessing and Compression
Abstract: This paper provides tight bounds on the Rényi entropy of a function of a discrete random variable with a finite number of possible values, where the considered function is not one to one. To that end, a tight lower bound on the Rényi entropy of a discrete random variable with a finite support is derived as a function of the size of the support, and the ratio of the maximal to minimal probability masses. This work was inspired by the recently published paper by Cicalese et al., which is focused on the Shannon entropy, and it strengthens and generalizes the results of that paper to Rényi entropies of arbitrary positive orders. In view of these generalized bounds and the works by Arikan and Campbell, non-asymptotic bounds are derived for guessing moments and lossless data compression of discrete memoryless sources.

2018: On f-Divergences: Integral Representations, Local Behavior, and Inequalities
Abstract: This paper is focused on f-divergences, consisting of three main contributions. The first one introduces integral representations of a general f-divergence by means of the relative information spectrum. The second part provides a new approach for the derivation of f-divergence inequalities, and it exemplifies their utility in the setup of Bayesian binary hypothesis testing. The last part of this paper further studies the local behavior of f-divergences.

2018: Non-Asymptotic Bounds for Optimal Fixed-to-Variable Lossless Compression without Prefix Constraints
Abstract: Bounds on optimal guessing moments serve to improve non-asymptotic bounds on the cumulant generating function of the codeword lengths for fixed-to-variable optimal lossless source coding without prefix constraints. Non-asymptotic bounds on the reliability function of discrete memoryless sources are presented as well. Lower bounds on the cumulant generating function of the codeword lengths are given, by means of the smooth Rényi entropy, for source codes that allow decoding errors.

