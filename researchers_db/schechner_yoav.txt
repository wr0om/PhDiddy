Recent papers for Schechner Yoav:

2024: Cloud Characterization by Computed Tomography Methods using a Satellite Formation of 10 Small Satellites for Improved Climate Prediction
Abstract: None

2024: Optical Tomography of Clouds and Atmospheric Turbulence from Space and Ground-based Cameras
Abstract: Novel tomographic principles yield 3D atmospheric fields using multi-view imagery. Turbulence strength is mapped by observing scintillation of bulbs. Extinction in clouds is mapped volumetrically from polarimetric cameras onboard a satellite formation.

2024: Learned 3D volumetric recovery of clouds and its uncertainty for climate analysis
Abstract: Significant uncertainty in climate prediction and cloud physics is tied to observational gaps relating to shallow scattered clouds. Addressing these challenges requires remote sensing of their three-dimensional (3D) heterogeneous volumetric scattering content. This calls for passive scattering computed tomography (CT). We design a learning-based model (ProbCT) to achieve CT of such clouds, based on noisy multi-view spaceborne images. ProbCT infers - for the first time - the posterior probability distribution of the heterogeneous extinction coefficient, per 3D location. This yields arbitrary valuable statistics, e.g., the 3D field of the most probable extinction and its uncertainty. ProbCT uses a neural-field representation, making essentially real-time inference. ProbCT undergoes supervised training by a new labeled multi-class database of physics-based volumetric fields of clouds and their corresponding images. To improve out-of-distribution inference, we incorporate self-supervised learning through differential rendering. We demonstrate the approach in simulations and on real-world data, and indicate the relevance of 3D recovery and uncertainty to precipitation and renewable energy.

2024: Success Probability in Multi-View Imaging
Abstract: Platforms such as robots, security cameras, drones and satellites are used in multi-view imaging for three-dimensional (3D) recovery by stereoscopy or tomography. Each camera in the setup has a field of view (FOV). Multi-view analysis requires overlap of the FOVs of all cameras, or a significant subset of them. However, the success of such methods is not guaranteed, because the FOVs may not sufficiently overlap. The reason is that pointing of a camera from a mount or platform has some randomness (noise), due to imprecise platform control, typical to mechanical systems, and particularly moving systems such as satellites. So, success is probabilistic. This paper creates a framework to analyze this aspect. This is critical for setting limitations on the capabilities of imaging systems, such as resolution (pixel footprint), FOV, the size of domains that can be captured, and efficiency. The framework uses the fact that imprecise pointing can be mitigated by self-calibration - provided that there is sufficient overlap between pairs of views and sufficient visual similarity of views. We show an example considering the design of a formation of nanosatellites that seek 3D reconstruction of clouds.

2024: NeMF: Neural Microphysics Fields.
Abstract: Inverse problems in scientific imaging often seek physical characterization of heterogeneous scene materials. The scene is thus represented by physical quantities, such as the density and sizes of particles (microphysics) across a domain. Moreover, the forward image formation model is physical. An important case is that of clouds, where microphysics in three dimensions (3D) dictate the cloud dynamics, lifetime and albedo, with implications to Earth's energy balance, sustainable energy and rainfall. Current methods, however, recover very degenerate representations of microphysics. To enable 3D volumetric recovery of all the required microphysical parameters, we introduce the neural microphysics field (NeMF). It is based on a deep neural network, whose input is multi-view polarization images. NeMF is pre-trained through supervised learning. Training relies on polarized radiative transfer, and noise modeling in polarization-sensitive sensors. The results offer unprecedented recovery, including droplet effective variance. We test NeMF in rigorous simulations and demonstrate it using real-world polarization-image data.

2024: Elemental Characterization of Ambient Particulate Matter for a Globally Distributed Monitoring Network: Methodology and Implications.
Abstract: Global ground-level measurements of elements in ambient particulate matter (PM) can provide valuable information to understand the distribution of dust and trace elements, assess health impacts, and investigate emission sources. We use X-ray fluorescence spectroscopy to characterize the elemental composition of PM samples collected from 27 globally distributed sites in the Surface PARTiculate mAtter Network (SPARTAN) over 2019-2023. Consistent protocols are applied to collect all samples and analyze them at one central laboratory, which facilitates comparison across different sites. Multiple quality assurance measures are performed, including applying reference materials that resemble typical PM samples, acceptance testing, and routine quality control. Method detection limits and uncertainties are estimated. Concentrations of dust and trace element oxides (TEO) are determined from the elemental dataset. In addition to sites in arid regions, a moderately high mean dust concentration (6 μg/m3) in PM2.5 is also found in Dhaka (Bangladesh) along with a high average TEO level (6 μg/m3). High carcinogenic risk (>1 cancer case per 100000 adults) from airborne arsenic is observed in Dhaka (Bangladesh), Kanpur (India), and Hanoi (Vietnam). Industries of informal lead-acid battery and e-waste recycling as well as coal-fired brick kilns likely contribute to the elevated trace element concentrations found in Dhaka.

2023: Using Zodiacal Light For Spaceborne Calibration Of Polarimetric Imagers.
Abstract: We propose that spaceborne polarimetric imagers can be calibrated, or self-calibrated using zodiacal light (ZL). ZL is created by a cloud of interplanetary dust particles. It has a significant degree of polarization in a wide field of view. From space, ZL is unaffected by terrestrial disturbances. ZL is insensitive to the camera location, so it is suited for simultaneous cross-calibration of satellite constellations. ZL changes on a scale of months, thus being a quasi-constant target in realistic calibration sessions. We derive a forward model for polarimetric image formation. Based on it, we formulate an inverse problem for polarimetric calibration and self-calibration, as well as an algorithm for the solution. The methods here are demonstrated in simulations. Towards these simulations, we render polarized images of the sky, including ZL from space, polarimetric disturbances, and imaging noise.

2023: PARS - Path Recycling and Sorting for Efficient Cloud Tomography
Abstract: Inverse rendering estimates scene characteristics from image data. We derive an efficient framework for inverse rendering and specifically computed tomography (CT) of volumetric scattering objects. We focus on clouds, which have a key role in the climate system and require efficient analysis at a huge scale. Data for such reconstruction are multiview images of each cloud taken simultaneously. This acquisition mode is expected by upcoming future spaceborne imagers, such as CloudCT. Prior art shows that scattering CT can rely on Monte–Carlo (MC) light transport. This approach usually iterates differentiable radiative transfer, requiring many sampled paths per iteration. We present an acceleration approach: path recycling and sorting (PARS). It efficiently uses paths from previous iterations for estimating a loss gradient at the current iteration. This reduces the iteration run time. PARS enables further efficient realizations. Specifically, sorting paths according to their size accelerates implementations on a graphical processing unit (GPU). PARS, however, requires a correction operation for unbiased gradient estimation. This can be achieved by utilizing a well-established concept from MC integration methods, as we show in this paper. We derive the theory of PARS and demonstrate its efficiency on cloud tomography of both synthetic and real-world scenes. Moreover, we demonstrate PARS on simple reflectometry examples.

2023: Retrieving 3D distributions of atmospheric particles using Atmospheric Tomography with 3D Radiative Transfer – Part 1: Model description and Jacobian calculation
Abstract: Abstract. Our global understanding of clouds and aerosols relies on the remote sensing of their optical, microphysical, and macrophysical properties using, in part, scattered solar radiation. These retrievals assume that clouds and aerosols form plane-parallel, homogeneous layers and utilize 1D radiative transfer (RT) models, limiting the detail that can be retrieved about the 3D variability in cloud and aerosol fields and inducing biases in the retrieved properties for highly heterogeneous structures such as cumulus clouds and smoke plumes. To overcome these limitations, we introduce and validate an algorithm for retrieving the 3D optical or microphysical properties of atmospheric particles using multi-angle, multi-pixel radiances and a 3D RT model. The retrieval software, which we have made publicly available, is called Atmospheric Tomography with 3D Radiative Transfer (AT3D). It uses an iterative, local optimization technique to solve a generalized least squares problem and thereby find a best-fitting atmospheric state. The iterative retrieval uses a fast, approximate Jacobian calculation, which we have extended from Levis et al. (2020) to accommodate open and periodic horizontal boundary conditions (BCs) and an improved treatment of non-black surfaces. We validated the accuracy of the approximate Jacobian calculation for
derivatives with respect to both the 3D volume extinction coefficient and
the parameters controlling the open horizontal boundary conditions across
media with a range of optical depths and single-scattering properties and
find that it is highly accurate for a majority of cloud and aerosol fields
over oceanic surfaces. Relative root mean square errors in the approximate
Jacobian for a 3D volume extinction coefficient in media with cloud-like
single-scattering properties increase from 2 % to 12 % as the maximum optical depths (MODs) of the medium increase from 0.2 to 100.0 over surfaces with Lambertian albedos <0.2. Over surfaces with albedos of 0.7, these errors increase to 20 %. Errors in the approximate Jacobian for the optimization of open horizontal boundary conditions exceed 50 %, unless the plane-parallel media providing the boundary conditions are optically very thin (∼0.1). We use the theory of linear inverse RT to provide insight into the physical
processes that control the cloud tomography problem and identify its
limitations, supported by numerical experiments. We show that the Jacobian
matrix becomes increasing ill-posed as the optical size of the medium
increases and the forward-scattering peak of the phase function decreases. This suggests that tomographic retrievals of clouds will become increasingly difficult as clouds become optically thicker. Retrievals of asymptotically thick clouds will likely require other sources of information to be successful. In Loveridge et al. (2023a; hereafter Part 2), we examine how the accuracy of the retrieved 3D volume extinction coefficient varies as the optical size of the target medium increases using synthetic data. We do this to explore how the increasing error in the approximate Jacobian and the increasingly ill-posed nature of the inversion in the optically thick limit affect the retrieval. We also assess the accuracy of retrieved optical depths and compare them to retrievals using 1D radiative transfer.


2023: Retrieving 3D distributions of atmospheric particles using Atmospheric Tomography with 3D Radiative Transfer – Part 2: Local optimization
Abstract: Abstract. Our global understanding of clouds and aerosols relies on the remote sensing of their optical, microphysical, and macrophysical properties using, in part, scattered solar radiation. Current retrievals assume clouds and aerosols form plane-parallel, homogeneous layers and utilize 1D radiative transfer (RT) models. These assumptions limit the detail that can be retrieved about the 3D variability in the cloud and aerosol fields and induce biases in the retrieved properties for highly heterogeneous structures such as cumulus clouds and smoke plumes. In Part 1 of this two-part study, we validated a tomographic method that utilizes multi-angle passive imagery to retrieve 3D distributions of species using 3D RT to overcome these issues. That validation characterized the uncertainty in the approximate Jacobian used in the tomographic retrieval over a wide range of atmospheric and surface conditions for several horizontal boundary conditions. Here, in Part 2, we test the algorithm's effectiveness on synthetic data to test whether the retrieval accuracy is limited by the use of the approximate Jacobian. We retrieve 3D distributions of a volume extinction coefficient (σ3D) at 40 m resolution from synthetic multi-angle, mono-spectral imagery at 35 m resolution derived from stochastically generated cumuliform-type clouds in (1 km)3 domains. The retrievals are idealized in that we neglect forward-modelling and instrumental errors, with the exception of radiometric noise; thus, reported retrieval errors are the lower bounds. σ3D is retrieved with, on average, a relative root mean square error (RRMSE) < 20 % and bias < 0.1 % for clouds with maximum optical depth (MOD) < 17, and the RRMSE of the radiances is < 0.5 %, indicating very high accuracy in shallow cumulus conditions. As the MOD of the clouds increases to 80, the RRMSE and biases in σ3D worsen to 60 % and −35 %, respectively, and the RRMSE of the radiances reaches 16 %, indicating incomplete convergence. This is expected from the increasing ill-conditioning of the inverse problem with the decreasing mean free path predicted by RT theory and discussed in detail in Part 1. We tested retrievals that use a forward model that is not only less ill-conditioned (in terms of condition number) but also less accurate, due to more aggressive delta-M scaling. This reduces the radiance RRMSE to 9 % and the bias in σ3D to −8 % in clouds with MOD ∼ 80, with no improvement in the RRMSE of σ3D. This illustrates a significant sensitivity of the retrieval to the numerical configuration of the RT model which, at
least in our circumstances, improves the retrieval accuracy. All of these
ensemble-averaged results are robust in response to the inclusion of radiometric noise during the retrieval. However, individual realizations can have large deviations of up to 18 % in the mean extinction in clouds with MOD ∼ 80, which indicates large uncertainties in the retrievals in the optically thick limit. Using less ill-conditioned forward model tomography can also accurately infer optical depths (ODs) in conditions spanning the majority of oceanic cumulus fields (MOD < 80), as the retrieval provides ODs with bias and RRMSE values better than −8 % and 36 %, respectively. This is a significant improvement over retrievals using 1D RT, which have OD biases between −30 % and −23 % and RRMSE between 29 % and 80 % for the clouds used here. Prior information or other sources of information will be required to improve the RRMSE of σ3D in the optically thick limit, where the RRMSE is shown to have a strong spatial structure that varies with the solar and viewing geometry.


2022: Variable Imaging Projection Cloud Scattering Tomography.
Abstract: Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is a nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale is particularly important when the objects constitute large cloud fields, where volumetric recovery is important for climate studies. Besides speed, imaging and recovery need to be flexible, to efficiently handle variable viewing geometries and resolutions. These can be caused by perturbation in camera poses or fusion of data from different types of observational sensors. There is a need for fast variable imaging projection scattering tomography of clouds (VIP-CT). We develop a learning-based solution, using a deep-neural network (DNN) which trains on a large physics-based labeled volumetric dataset. The DNN parameters are oblivious to the domain scale, hence the DNN can work with arbitrarily large domains. VIP-CT offers much better quality than the state of the art. The inference speed and flexibility of VIP-CT make it effectively real-time in the context of spaceborne observations. The paper is the first to demonstrate CT of a real cloud using empirical data directly in a DNN. VIP-CT may offer a model for a learning-based solution to nonlinear CT problems in other scientific domains. Our code is available online.

2022: Complex-Valued Retrievals From Noisy Images Using Diffusion Models
Abstract: In diverse microscopy modalities, sensors measure only real-valued intensities. Additionally, the sensor readouts are affected by Poissonian-distributed photon noise. Traditional restoration algorithms typically aim to minimize the mean squared error (MSE) between the original and recovered images. This often leads to blurry outcomes with poor perceptual quality. Recently, deep diffusion models (DDMs) have proven to be highly capable of sampling images from the a-posteriori probability of the sought variables, resulting in visually pleasing high-quality images. These models have mostly been suggested for real-valued images suffering from Gaussian noise. In this study, we generalize annealed Langevin Dynamics, a type of DDM, to tackle the fundamental challenges in optical imaging of complex-valued objects (and real images) affected by Poisson noise. We apply our algorithm to various optical scenarios, such as Fourier Ptychography, Phase Retrieval, and Poisson denoising. Our algorithm is evaluated on simulations and biological empirical data.

2022: Settings for Spaceborne 3-D Scattering Tomography of Liquid-Phase Clouds by the CloudCT Mission
Abstract: We introduce a comprehensive method for space-borne 3-D volumetric scattering-tomography of cloud microphysics, developed for the CloudCT mission. The retrieved microphysical properties are the liquid-water-content (LWC) and effective droplet radius within a cloud. We include a model for a perspective polarization imager and an assumption of 3-D variation of the effective radius. Elements of our work include computed tomography initialization by a parametric horizontally uniform microphysical model. This results in smaller errors than the prior art. The mean absolute errors of the retrieved LWC and effective radius are reduced from 62% and 28% to 40% and 9%, respectively. The parameters of this initialization are determined by a grid search of a cost function. Furthermore, we add viewpoints in the cloudbow region, to better sample the polarized scattering phase function. The suggested advances are evaluated by retrieval of a set of clouds generated by large-eddy simulations.

2022: ALiDAn: Spatiotemporal and Multiwavelength Atmospheric Lidar Data Augmentation
Abstract: Methods based on statistical learning have become prevalent in various signal processing disciplines and have recently gained traction in atmospheric lidar studies. Nonetheless, such methods often require large quantities of annotated or resolved data. Such data are rare and require effort, especially when exploring evolving phenomena. Existing simulators and databases primarily focus on atmospheric vertical profiles. We propose the Atmospheric Lidar Data Augmentation (ALiDAn) framework to fill this gap. ALiDAn serves as an end-to-end generation and augmentation framework of spatiotemporal and multiwavelength resolved lidar simulated data. ALiDAn employs a hybrid approach of physical models, data statistics, and sampling processes. In addition, it takes into account geographical and seasonal characteristics of aerosols and meteorological conditions along with short- and long-term phenomena that affect lidar measurements. This approach can provide diversified data and robust benchmarks to assist in developing and validating new lidar processing algorithms. We demonstrate simulations compatible with a pulsed time-of-flight lidar. Our approach leverages a broader use of existing databases and can inspire similar data augmentation to other types of lidars and active sensors.

2022: C3IEL: Cluster for Cloud Evolution, ClImatE and Lightning
Abstract: Clouds play a major role in Earth’s energy budget and hydrological cycle. Clouds dynamical structure and mixing with the ambient air have a large impact on their vertical mass and energy fluxes and on precipitation. Most of the cloud evolution and mixing occurs at scales smaller than presently observable from geostationary orbit, which is less than 1 km. A satellite mission is planned for bridging this gap, named “Cluster for Cloud evolution, ClImatE and Lightning” (CIEL). The mission is a collaboration between the Israeli (ISA) and French (CNES) space agencies, which is presently at the end of its Phase A. The planned mission will be constituted of a constellation of 2 to 3 nanosatellites in a sun synchronous early afternoon polar orbit, which will take multi-stereoscopic images of the field of view during an overpass. CIEL will carry 3 instruments: (1) CLOUD visible imager at a spatial resolution of 20 m. The multi-stereoscopic reconstruction of the evolution of cloud envelops at a resolution better than 100 m and velocity of few m/s will provide an unprecedented information on the clouds dynamics and evolution. (2) WATER VAPOR imagers at 3 wavebands with different vapor absorption will provide vertically integrated water vapor around the cloud and possibly a 3-dimensional structure of the vapor around the clouds due to their mixing and evaporation with the ambient air. (3) Lightning Optical Imagers and Photometers (LOIP). The lightning sensors will provide a link between cloud dynamics and electrification at higher spatial resolution than previously available. CIEL will provide presently missing observational evidence for the role of clouds at sub-km scale in redistributing the energy and water in the atmosphere, and of the relation between storm vigor and frequency of lightning activity.

2022: Tomography of Turbulence Strength Based on Scintillation Imaging
Abstract: None

2022: Supervised Learning Calibration of an Atmospheric Lidar
Abstract: Calibration of an atmospheric lidar is often required due to variations in the electro-optical system. Rayleigh fitting commonly performed may fail under various conditions. Temporal and spatial variations both affect lidar signals. We hence opt for spatiotemporal analysis. We present a novel deep-learning (DL) lidar calibration model based on convolutional neural networks (CNN). We demonstrate our method on simulated data that mimics natural ground-based pulsed time-of-flight lidar signals. Such an approach can better address measurements with a poor signal-to-noise ratio (SNR) and provide a more frequent calibration.

2022: Towards A Most Probable Recovery in Optical Imaging
Abstract: Light is a complex-valued ﬁeld. The intensity and phase of the ﬁeld are affected by imaged objects. However, imaging sensors measure only real-valued non-negative intensities. This results in a nonlinear relation between the measurements and the unknown imaged objects. Moreover, the sensor readouts are corrupted by Poissonian-distributed photon noise. In this work, we seek the most probable object (or clear image), given noisy measurements, that is, maximizing the a-posteriori probability of the sought variables. Hence, we generalize annealed Langevin dynamics, tack-ling fundamental challenges in optical imaging, including phase recovery and Poisson (photon) denoising. We leverage deep neural networks, not for explicit recovery of the imaged object, but as an approximate gradient for a prior term. We show results on empirical data, acquired by a real experiment. We further show results of simulations. 1

2022: Vicarious spaceborne polarimetric camera calibration using solar power stations
Abstract: We propose polarimetric calibration of nano-satellites by pointing them towards solar panel farms or mirrors at solar thermal power plants. We show through simulations that both can provide significant polarization sources. Around a solar tower, this is obtained by polarized skylight reflected from mirrors. Photovoltaic solar panels, on the other hand, yield a strong polarized signal by reflecting direct sunlight around the Brewster angle. The signal is affected by aerosols. The aerosol uncertainty affects calibration tasks. Based on these findings, we simulate spaceborne polarimetric camera calibration.

2021: Plankton reconstruction through robust statistical optical tomography.
Abstract: Plankton interact with the environment according to their size and three-dimensional (3D) structure. To study them outdoors, these translucent specimens are imaged in situ. Light projects through a specimen in each image. The specimen has a random scale, drawn from the population's size distribution and random unknown pose. The specimen appears only once before drifting away. We achieve 3D tomography using such a random ensemble to statistically estimate an average volumetric distribution of the plankton type and specimen size. To counter errors due to non-rigid deformations, we weight the data, drawing from advanced models developed for cryo-electron microscopy. The weights convey the confidence in the quality of each datum. This confidence relies on a statistical error model. We demonstrate the approach on live plankton using an underwater field microscope.

