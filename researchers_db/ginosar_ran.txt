Recent papers for Ginosar Ran:

2023: GAPiM: Discovering Genetic Variations on a Real Processing-in-Memory System
Abstract: Variant calling is a fundamental stage in genome analysis that identifies mutations (variations) in a sequenced genome relative to a known reference genome. Pair-HMM is a key part of the variant calling algorithm and its most compute-intensive part. In recent years, Processing-in-Memory (PiM) solutions, which consist of placing compute capabilities near/inside memory, have been proposed to speed up the genome analysis pipeline. We implement the Pair-HMM algorithm on a commercial PiM platform developed by UPMEM. We modify the Pair-HMM algorithm to make it more suitable for PiM execution with acceptable loss of accuracy. We evaluate our implementation on single chromosomes and whole genome sequencing datasets, demonstrating up to 2x speedup compared to existing CPU accelerations and up to 3x speedup compared to FPGA accelerations.

2022: RC64: Space Manycore Enabled by SpaceWire & SpaceFibre
Abstract: RC64 rad-hard manycore DSP/ML processor employs the Space-oriented SpFi and SpW communication protocols. It is the only known Space product fully based on these two standards. RC64 employs six SpaceWire links and twelve high-speed SpaceFibre links. This connectivity facilitates modular complex systems comprising tens and more processors spanning multiple PCBs and multiple enclosures for all Space missions. Small and reliable, thermal-cycle resilient chip packages are enabled. Systems for satellite communications, Earth observation, remote sensing, storage, cloud computing, autonomous spacecraft and instruments and more are being designed and implemented. Design considerations and challenges are described, and future versions are described.

2021: The Plural Many‐core Architecture – High Performance at Low Power
Abstract: None

2021: A survey of algorithmic methods in IC reverse engineering
Abstract: None

2020: WoLFRaM: Enhancing Wear-Leveling and Fault Tolerance in Resistive Memories using Programmable Address Decoders
Abstract: Resistive memories have limited lifetime caused by limited write endurance and highly non-uniform write access patterns. Two main techniques to mitigate endurance-related memory failures are 1) wear-leveling, to evenly distribute the writes across the entire memory, and 2) fault tolerance, to correct memory cell failures. However, one of the main open challenges in extending the lifetime of existing resistive memories is to make both techniques work together seamlessly and efficiently. To address this challenge, we propose WoLFRaM, a new mechanism that combines both wear-leveling and fault tolerance techniques at low cost by using a programmable resistive address decoder (PRAD). The key idea of WoLFRaM is to use PRAD for implementing 1) a new efficient wear-leveling mechanism that remaps write accesses to random physical locations on the fly, and 2) a new effiCient fault tolerance mechanism that recovers from faults by remapping failed memory blocks to available physical locations. Our evaluations show that, for a Phase Change Memory (PCM) based system with cell endurance of 108 writes, WoLFRaM increases the memory lifetime by 68% compared to a baseline that implements the best state-of-the-art wear-leveling and fault correction mechanisms. WoLFRaM's average / worst-case performance and energy overheads are 0.51% /3.8% and 0.47% /2.1% respectively.

2019: Adaptive programming in multi-level cell ReRAM
Abstract: None

2019: POSTER: GIRAF: General Purpose In-Storage Resistive Associative Framework
Abstract: GIRAF is an in-storage architecture and algorithm framework based on Resistive Content Addressable Memory (RCAM). GIRAF functions simultaneously as a storage and a massively parallel associative processor. GIRAF alleviates the bandwidth wall by connecting every memory bit to processing transistors and keeping computing inside the storage arrays, thus implementing in-data, rather than near-data, processing. We show that GIRAF outperforms a reference computer architecture with a bandwidth-limited external storage access on a variety of data intensive workloads. The performance of GIRAF Euclidean distance, dot product and histogram implementation, exceeds the attainable performance of a reference architecture by up to four orders of magnitude, depending on the dataset size. The performance of GIRAF SpMV exceeds the attainable performance of such reference architecture by more than two orders of magnitude.

2019: SoK: An Overview of Algorithmic Methods in IC Reverse Engineering
Abstract: Reverse engineering of integrated circuits (IC) serves an evergrowing need for both defensive and offensive applications, such as competitive analysis, IP theft evidence and hardware Trojan detection. The IC reverse engineering process comprises two phases, netlist extraction and specification discovery. The latter draws a particular research interest due to fundamental questions of the process, which are how to represent specification and how to measure success of the process. In this paper, we survey the state of the art in IC reverse engineering, focusing on the specification discovery. We generate a taxonomy of the published methods and algorithms, list the challenges and open questions and discuss future directions.

2019: BioSEAL: In-Memory Biological Sequence Alignment Accelerator for Large-Scale Genomic Data
Abstract: Genome sequences contain hundreds of millions of DNA base pairs. Finding the degree of similarity between two genomes requires executing a compute-intensive dynamic programming algorithm, such as Smith-Waterman. Traditional von Neumann architectures have limited parallelism and cannot provide an efficient solution for large-scale genomic data. Approximate heuristic methods (e.g. BLAST) are commonly used. However, they are suboptimal and still compute-intensive. In this work, we present BioSEAL, a biological sequence alignment accelerator. BioSEAL is a massively parallel non-von Neumann processing-in-memory architecture for large-scale DNA and protein sequence alignment. BioSEAL is based on resistive content addressable memory, capable of energy-efficient and highperformance associative processing. We present an associative processing algorithm for entire database sequence alignment on BioSEAL and compare its performance and power consumption with state-of-art solutions. We show that BioSEAL can achieve up to 57× speedup and 156× better energy efficiency, compared with existing solutions for genome sequence alignment and protein sequence database search.

2018: PRINS: Resistive CAM Processing in Storage
Abstract: Near-data in-storage processing research has been gaining momentum in recent years. Typical processing-in-storage architecture places a single or several processing cores inside the storage and allows data processing without transferring it to the host CPU. Since this approach replicates von Neumann architecture inside storage, it is exposed to the problems faced by von Neumann architecture, especially the bandwidth wall. We present PRINS, a novel in-data processing-in-storage architecture based on Resistive Content Addressable Memory (RCAM). PRINS functions simultaneously as a storage and a massively parallel associative processor. PRINS alleviates the bandwidth wall faced by conventional processing-in-storage architectures by keeping the computing inside the storage arrays, thus implementing in-data, rather than near-data, processing. We show that PRINS may outperform a reference computer architecture with a bandwidth-limited external storage. The performance of PRINS Euclidean distance, dot product and histogram implementation exceeds the attainable performance of a reference architecture by up to four orders of magnitude, depending on the dataset size. The performance of PRINS SpMV may exceed the attainable performance of such reference architecture by more than two orders of magnitude.

2018: PhD Showcase: Accelerator Architectures for Machine Learning and Bioinformatics
Abstract: Extended Abstract Most contemporary accelerators are von Neumann machines. With the increasing sizes of gathered and then processed data, memory bandwidth is the main limiting of performance. One approach to mitigate the bandwidth constraint is to bring the processing units closer to the data. This approach is known as near-data processing (NDP) [1]. The premise of NDP is reducing memory transfer time by cutting the physical distance and increasing the bandwidth between the processing units and memory. However, NDP architectures such as 3D DRAM and CPU stacks, or SSD with embedded CPU, are still inherently limited because they are based on replicating the von Neumann architecture in memory or storage. More recent approach is to exploit processing elements closer to storage, i.e., near-storage processing. However, both NDP and near-storage processing still suffer from the von Neumann bandwidth bottleneck. NDP has a bottleneck between storage and main memory. Near-storage processing suffers from the bottleneck between the storage chips and processing units. Both approaches are inherently limited because they are largely based on the von Neumann architecture model. My research proposes two main in-storage processing architectures. The following sections shortly describe each architecture and my research contribution .

2018: RASSA: Resistive Accelerator for Approximate Long Read DNA Mapping
Abstract: Constructing human DNA sequence in real time is paramount to development of precision medicine and on-site pathogen detection of disease outbreaks. Single-molecule, real-time sequencing from Pacific Biosciences (PacBio) and Oxford Nanopore Technologies (ONT) are new technologies that can produce long reads within minutes, potentially enabling real time genomic analysis. However, long read DNA sequencing poses new challenges. First, long reads contain many thousands of base pairs (bps). Second, long reads tend to exhibit about 15-20% insertion, deletion (indel) and substitution errors.

2018: Enabling Full Associativity with Memristive Address Decoder
Abstract: Address decoders are typically built using regular logic gates. A novel Memristive Perfect Induction gate replaces standard NAND, allowing for storing the address alongside data and comparing it to the input address, thus transforming the address decoder into CAM and enabling fully associative access. Applications include fully associative TLB, cache, and virtually addressable memory.

2018: PRINS: Processing-in-Storage Acceleration of Machine Learning
Abstract: Machine learning algorithms have become a major tool in various applications. The high-performance requirements on large-scale datasets pose a challenge for traditional von Neumann architectures. We present two machine learning implementations and evaluations on PRINS, a novel processing-in-storage system based on resistive content addressable memory (ReCAM). PRINS functions simultaneously as a storage and a massively parallel associative processor. PRINS processing-in-storage resolves the bandwidth wall faced by near-data von Neumann architectures, such as three-dimensional DRAM and CPU stack or SSD with embedded CPU, by keeping the computing inside the storage arrays, thus implementing in-data, rather than near-data, processing. We show that PRINS-based processing-in-storage architecture may outperform existing in-storage designs and accelerator-based designs. Multiple performance comparisons for the ReCAM processing-in-storage implementations of $K$ -means and K-nearest neighbors are performed. Compared platforms include CPU, GPU, FPGA, and Automata Processor. We show that PRINS may achieve an order-of-magnitude speedup and improved power efficiency relative to all compared platforms.

2018: RASSA: Resistive Prealignment Accelerator for Approximate DNA Long Read Mapping
Abstract: DNA read mapping is a computationally expensive bioinformatics task, required for genome assembly and consensus polishing. It requires to find the best-fitting location for each DNA read on a long reference sequence. A novel resistive approximate similarity search accelerator (RASSA) exploits charge distribution and parallel in-memory processing to reflect a mismatch count between DNA sequences. RASSA implementation of DNA long-read prealignment outperforms the state-of-the-art solution, minimap2, by 16–77× with comparable accuracy and provides two orders of magnitude higher throughput than GateKeeper, a short-read prealignment hardware architecture implemented in FPGA.

2018: GIRAF: General Purpose In-Storage Resistive Associative Framework
Abstract: GIRAF is a General purpose In-storage Resistive Associative Framework based on resistive content addressable memory (RCAM), which functions simultaneously as a storage and a massively parallel associative processor. GIRAF alleviates the bandwidth wall by connecting every memory bit to processing transistors and keeping computing inside the storage arrays, thus implementing deep in-data, rather than near-data, processing. We show that GIRAF outperformed a reference computer architecture with a bandwidth-limited external storage access on a variety of data-intensive workloads. The performance of GIRAF Dot Product and Sparse Matrix-Vector multiplication exceeds the attainable performance of a reference architecture by 1200<inline-formula><tex-math notation="LaTeX">$ \;\times $</tex-math><alternatives><mml:math><mml:mrow><mml:mspace width="0.277778em"/><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="yavits-ieq1-3065448.gif"/></alternatives></inline-formula> and 130<inline-formula><tex-math notation="LaTeX">$ \;\times $</tex-math><alternatives><mml:math><mml:mrow><mml:mspace width="0.277778em"/><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="yavits-ieq2-3065448.gif"/></alternatives></inline-formula>, respectively.

2018: AIDA: Associative DNN Inference Accelerator
Abstract: We propose AIDA, an inference engine for accelerating fully-connected (FC) layers of Deep Neural Network (DNN). AIDA is an associative in-memory processor, where the bulk of data never leaves the confines of the memory arrays, and processing is performed in-situ. AIDA area and energy efficiency strongly benefit from sparsity and lower arithmetic precision. We show that AIDA outperforms the state of art inference accelerator, EIE, by 14.5x (peak performance) and 2.5x (throughput).

2018: Accelerator for Sparse Machine Learning
Abstract: Sparse matrix by vector multiplication (SpMV) plays a pivotal role in machine learning and data mining. We propose and investigate an SpMV accelerator, specifically designed to accelerate the sparse matrix by sparse vector multiplication (SpMSpV), and to be integrated in a CPU core. We show that our accelerator outperforms a similar solution by 70x while achieving 8x higher power efficiency, which yields an estimated 29x energy reduction for SpMSpV based applications.

2017: A Resistive CAM Processing-in-Storage Architecture for DNA Sequence Alignment
Abstract: A novel processing-in-storage (PRinS) architecture based on Resistive CAM (ReCAM) is described and proposed for Smith-Waterman (S-W) sequence alignment. The ReCAM PRinS massively parallel compare operation finds matching base pairs in a fixed number of cycles, regardless of sequence length. The ReCAM PRinS S-W algorithm is simulated and compared to FPGA, Xeon Phi, and GPU-based implementations, showing at least 4.7 times higher throughput and at least 15 times lower power dissipation.

2017: From Processing-in-Memory to Processing-in-Storage
Abstract: Near-data in-memory processing research has been gaining momentum in recent years. Typical processing-in-memory architecture places a single or several processing elements next to a volatile memory, enabling processing without transferring data to the host CPU. The increased bandwidth to and from volatile memory leads to performance gain. However processing-in-memory does not alleviate von Neumann bottleneck for big data problems, where datasets are too large to fit in main memory. We present a novel processing-in-storage system based on Resistive Content Addressable Memory ReCAM. It functions simultaneously as a mass storage and as a massively parallel associative processor. ReCAM processing-in-storage resolves the bandwidth wall by keeping computation inside the storage arrays, without transferring it up the memory hierarchy. We show that ReCAM based processing-in-storage architecture may outperform existing processing-in-memory and accelerator based designs. ReCAM processing-in-storage implementation of Smith-Waterman DNA sequence alignment reaches a speedup of almost five over a GPU cluster. An implementation of in-storage inline data deduplication is presented and shown to achieve orders of magnitude higher throughput than traditional CPU and DRAM based systems.

