2023: Informationally Robust Cheap-Talk
Abstract: We study the robustness of cheap-talk equilibria to infinitesimal private information of the receiver in a model with a binary state-space and state-independent sender-preferences.

2022: Data Curation from Privacy-Aware Agents
Abstract: A data curator would like to collect data from privacy-aware agents. The collected data will be used for the benefit of all agents. Can the curator incentivize the agents to share their data truthfully? Can he guarantee that truthful sharing will be the unique equilibrium? Can he provide some stability guarantees on such equilibrium? We study necessary and sufficient conditions for these questions to be answered positively and complement these results with corresponding data collection protocols for the curator. Our results account for a broad interpretation of the notion of privacy awareness.

2022: Herd Design
Abstract: The classic herding model examines the asymptotic behavior of agents who observe their predecessors' actions as well as a private signal from an exogenous information structure. In this paper we introduce a self-interested sender into the model, and study the sender's problem of designing this information structure. If agents cannot observe each other the model reduces to Bayesian persuasion. However, when agents observe predecessors' actions, they may learn from each other, potentially harming the sender. We identify necessary and sufficient conditions under which the sender can nevertheless obtain the same utility as when the agents are unable to observe each other.

2021: Information aggregation in large collective purchases
Abstract: Society uses the following mechanism to decide on the supply of an experience good. Each agent can choose whether or not to contribute to the good. Contributions are collected, and the good is supplied whenever total contributions exceed a threshold. We study the case where the good is excludable, agents have a common value, and each agent receives a private signal about the common value. We study how such collective decisions perform in terms of information aggregation, social efficiency, and market traction.

2020: Identifiable information structures
Abstract: None

2020: On Social Networks that Support Learning
Abstract: Bayes-rational agents reside on a social network. They take binary actions sequentially and irrevocably, and the right action depends on an unobservable state. Each agent receives a bounded private signal about the realized state and observes the actions taken by the neighbors who acted before. How does the network topology affect the ability of agents to aggregate the information dispersed over the population by means of the private signals? Most of the literature addressing such questions assumes that the network's structure is dictated by the order in which agents take their actions. By contrast, we assume that the network preexists and the order in which agents take actions is random. Hence, the network's topology is decoupled from the order of actions in a particular decision problem. The random order leads to a novel localization phenomenon: for most of the orders, agents have a bounded radius of influence, i.e., the agent's action is unlikely to affect those who are far from him in the network. This phenomenon underlies a bunch of new effects. Global information cascades become unlikely, and networks that fail to aggregate information exhibit many local cascades. The ability of an agent to learn the right action is determined by the local structure of the network around him, and there is a local topological condition guaranteeing that the agent takes the right action no matter how well others do. Roughly speaking, the condition requires that the agent bridges a multitude of mutually exclusive social circles. Networks, where this condition is satisfied for all agents, are robust to disruptions and keep aggregating information even if a substantial fraction of the population is eliminated adversarially. The full paper can be accessed at \hrefhttps://arxiv.org/pdf/2011.05255.pdf https://arxiv.org/pdf/2011.05255.pdf.

2020: Algorithms for Persuasion with Limited Communication
Abstract: The Bayesian persuasion paradigm of strategic communication models interaction between a privately informed sender and an ignorant but rational receiver. The goal is typically to design a (near-)optimal communication (or signaling) scheme for the sender. It enables the sender to disclose information to the receiver in a way as to incentivize her to take an action that is preferred by the sender. Finding the optimal signaling scheme is known to be computationally difficult in general. This hardness is further exacerbated when the message space is constrained, leading to NP-hardness of approximating the optimal sender utility within any constant factor. In this paper, we show that in several natural and prominent cases the optimization problem is tractable even when the message space is limited. In particular, we study signaling under a symmetry or an independence assumption on the distribution of utility values for the actions. For symmetric distributions, we provide a novel characterization of the optimal signaling scheme. It results in a polynomial-time algorithm to compute an optimal scheme for many compactly represented symmetric distributions. In the independent case, we design a constant-factor approximation algorithm, which stands in marked contrast to the hardness of approximation in the general case.

2020: On the behavioral implications of differential privacy
Abstract: None

2020: On the properties that characterize privacy
Abstract: None

2020: Prophet Inequalities for Bayesian Persuasion
Abstract: We study an information-structure design problem (i.e., a Bayesian persuasion problem) in an online scenario. Inspired by the classic gambler’s problem, consider a set of candidates who arrive sequentially and are evaluated by one agent (the sender). This agent learns the value from hiring the candidate to herself as well as the value to another agent, the receiver. The sender provides a signal to the receiver who, in turn, makes an irrevocable decision on whether or not to hire the candidate. A-priori, for each agent the distribution of valuation is independent across candidates but may not be identical. We design good online signaling schemes for the sender. To assess the performance, we compare the expected utility to that of an optimal offline scheme by a prophet sender who knows all candidate realizations in advance. We show an optimal prophet inequality for online Bayesian persuasion, with a 1/2-approximation when the instance satisfies a “satisfactory-statusquo” assumption. Without this assumption there are instances without any finite approximation factor. We extend the results to combinatorial domains and obtain prophet inequalities for matching with multiple hires and multiple receivers.

2020: Reaping the Informational Surplus in Bayesian Persuasion
Abstract: The Bayesian persuasion model studies communication between an informed sender and a receiver with a payoff-relevant action, emphasizing the ability of a sender to extract maximal surplus from his informational advantage. In this paper, we study a setting with multiple senders in which the receiver is restricted to choosing, at the interim stage, one sender with whom to interact. Our main result is that whenever senders are uncertain about each other’s preferences and, in particular, cannot dismiss with certainty the possibility that others are aligned with the receiver, the receiver receives all the informational surplus in all equilibria. (JEL C72, D82, D83)

2019: A Cardinal Comparison of Experts
Abstract: In various situations, decision makers face experts that may provide conflicting advice. This advice may be in the form of probabilistic forecasts over critical future events. We consider a setting where the two forecasters provide their advice repeatedly and ask whether the decision maker can learn to compare and rank the two forecasters based on past performance. We take an axiomatic approach and propose three natural axioms that a comparison test should comply with. We propose a test that complies with our axioms. Perhaps, not surprisingly, this test is closely related to the likelihood ratio of the two forecasts over the realized sequence of events. More surprisingly, this test is essentially unique. Furthermore, using results on the rate of convergence of supermartingales, we show that whenever the two experts\textquoteright{} advice are sufficiently distinct, the proposed test will detect the informed expert in any desired degree of precision in some fixed finite time.

2019: The Implications of Pricing on Social Learning
Abstract: We study the implications of endogenous pricing for learning and welfare in the classic herding model. When prices are determined exogenously, it is known that learning occurs if and only if signals are unbounded. By contrast, we show that learning can occur when signals are bounded as long as non-conformism among consumers is scarce. More formally, learning happens if and only if signals exhibit the vanishing likelihood property introduced bellow. We discuss the implications of our results for potential market failure in the context of Schumpeterian growth with uncertainty over the value of innovations.

2019: Privacy, Patience, and Protection
Abstract: None

2019: The Secretary Recommendation Problem
Abstract: In this paper we revisit the basic variant of the classical secretary problem. We propose a new approach in which we separate between an agent that evaluates the secretary performance and one that has to make the hiring decision. The evaluating agent (the sender) signals the quality of the candidate to the hiring agent (the receiver) who must make a decision. Whenever the two agents' interests are not fully aligned, this induces an information transmission (signaling) challenge for the sender. We study the sender's optimization problem subject to persuasiveness constraints of the receiver for several variants of the problem. Our results quantify the loss in performance for the sender due to online arrival. We provide optimal and near-optimal persuasive mechanisms that recover at least a constant fraction of a natural utility benchmark for the sender. The separation of evaluation and decision making can have a substantial impact on the approximation results. While in some scenarios, techniques and results closely mirror the conditions in the standard secretary problem, we also explore conditions that lead to very different characteristics.

2019: Optimal Persuasion via Bi-Pooling
Abstract: The canonical Bayesian persuasion setting studies a model where an informed agent, the Sender, can partially share his information with an uninformed agent, the Receiver. The Receiver's utility is a function of the state of nature and the Receiver's action while the Sender's is only a function of the Receiver's action. The classical results characterize the Sender's optimal information disclosure policy whenever the state space is finite. In this paper we study the same setting where the state space is an interval on the real line. We introduce the class of bi-pooling policies and the induced distribution over posteriors which we refer to as bi-pooling distributions. We show that this class of distributions characterizes the set of optimal distributions in the aforementioned setting. Every persuasion problem admits an optimal bi-pooling distribution as a solution. Conversely, for every bi-pooling distribution there exists a persuasion problem in which the given distribution is the unique optimal one. We leverage this result to study the structure of the price function (see [1]) in this setting and to identify optimal information disclosure policies. The full paper can be accessed at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3511516.

2019: Social Learning and the Innkeeper's Challenge
Abstract: Technological evolution, so central to the progress of humanity in recent decades, is the process of constantly introducing new technologies to replace old ones. A new technology does not necessarily mean a better technology and so should not always be embraced. How can society learn which novelties present actual improvements over the existing technology? Whereas the quality of status-quo technology is well known, the new one is a pig in a poke. With sufficiently many individuals willing to explore the new technology society can learn whether it is indeed an improvement. However, self motivated agents, often, do not agree to explore. This is true, in particular, if agents observed some predecessors that were disappointed from the new technology. Inspired by the classical multi-armed bandit model we study a setting where agents arrive sequentially and must pull one of two arms in order to receive a reward - a risky arm (representing the new technology) and a safe arm (representing the existing one). A central planner must induce sufficiently many agents to experiment with the risky arm. The central planner observes the actions and rewards of all agents while the agents themselves have partial observation. For the setting where each agent observes his predecessor we provide the central planner with a recommendation algorithm that is (almost) incentive compatible and facilitates social learning.

2019: M E ] 2 8 A ug 2 01 9 On comparison of expert
Abstract: A policy maker faces a sequence of unknown outcomes. At each stage two (self-proclaimed) experts provide probabilistic forecasts on the outcome in the next stage. A comparison test is a protocol for the policy maker to (eventually) decide which of the two experts is better informed. The protocol takes as input the sequence of pairs of forecasts and actual outcomes and (weakly) ranks the two experts. We focus on anonymous and non-counterfactual comparison tests and propose two natural properties to which such a comparison test must adhere. We show that these determine the test in an essentially unique way. The resulting test is a function of the derivative of the induced pair of measures at the realized outcomes.

2018: Traffic Light Scheduling, Value of Time, and Incentives
Abstract: We study the intersection signalling control problem for cars with heterogeneous valuations of time (VoT). We are interested in a control algorithm that has some desirable properties: (1) it induces cars to report their VoT truthfully, (2) it minimizes the value of time lost for cars waiting at the intersection, and (3) it is computationally efficient. We obtain three main results: (1) We describe a computationally efficient heuristic forward search approach to solve the static problem. Simulation results show that this method is significantly faster than the dynamic-programming approach to solve the static problem (which is by itself polynomial time). We therefore believe that our algorithm can be commercially implemented. (2) We extend the solution of the static problem to the dynamic case. We couple our algorithm with a carefully designed payment scheme which yields an incentive compatible mechanism. In other words, it is the best interest of each car to truthfully report its VoT. (3) We describe simulation results that compare the social welfare obtained by our scheduling algorithm, as measured by the total value of waiting time, to the social welfare obtained by other intersection signalling control methods.

2018: Recommendation Systems and Self Motivated Users
Abstract: Modern recommendation systems rely on the wisdom of the crowd to learn the optimal course of action. This induces an inherent mis-alignment of incentives between the system's objective to learn (explore) and the individual users' objective to take the contemporaneous optimal action (exploit). The design of such systems must account for this and also for additional information available to the users. A prominent, yet simple, example is when agents arrive sequentially and each agent observes the action and reward of his predecessor. We provide an incentive compatible and asymptotically optimal mechanism for that setting. The complexity of the mechanism suggests that the design of such systems for general settings is a challenging task.

