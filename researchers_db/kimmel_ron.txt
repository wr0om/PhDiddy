Recent papers for Kimmel Ron:

2023: Abstract 5354: Prediction of OncotypeDX high risk group for chemotherapy benefit in breast cancer by deep learning analysis of hematoxylin and eosin-stained whole slide images
Abstract: 
 Introduction: Breast cancer is the most common cancer in women, with most patients diagnosed with early-stage disease. While adjuvant therapy should be considered in all fit patients, in many low-risk patients drug toxicity may out-weigh the potential benefit, therefore, identifying these patients is desired. Hematoxylin and eosin (H&E) is the basic staining routinely performed for biopsies. It allows visual examination of the tissue and cells. Such manual examination, however, does not provide information about the molecular profile of the cancer, which is essential for diagnosis and guidance of treatment. The OncotypeDX assay is recommended for patients with node-negative, estrogen receptor-positive invasive breast cancer for determining chemotherapy benefit. It is based on RT-PCR gene expression profiling and provides a recurrence score (RS) that enables patient stratification to non-high risk (RS < 26) and high risk (RS ≥ 26). It was shown that high risk patients are likely to benefit from chemotherapy, while non-high risk are not. Unlike H&E staining, the OncotypeDX assay is costly, time consuming, and inaccessible in low-income countries. Here, we sought to evaluate whether analysis of scanned H&E-stained slides by convolutional neural networks (CNNs) could predict the RS risk group (high versus non-high), which determines eligibility for chemotherapy.
 Methods: 684 H&E-stained slides were collected from 430 invasive breast cancer patients who were assayed for OncotypeDX between 2014 and 2020 at Sheba medical center, Israel. The slides were scanned at 0.25 micron/pixel, and automatically segmented and split to 256 × 256 non-overlapping tiles, resulting in overall 339,986 tile images containing tissue. The patients were randomly split into training (75%) and test (25%) sets, and a CNN model was trained and validated on the training set to classify each tile to non-high risk (RS < 26) versus high risk (RS ≥ 26), in 5-fold cross-validation. The final model was then applied to the held-out test set, and tile scores were aggregated to produce per-patient prediction scores. The final CNN prediction scores on the test set were compared to the ground truth risk group and the AUC performance was calculated.
 Results: The AUC performance of the model on the held out test set for high-risk versus non-high-risk classification based on the H&E images alone was high (0.798, 95% CI: 0.689 - 0.875, P value < 0.001), showing that the H&E image analysis could predict the high risk group.
 Conclusions: These results show, for the first time, that CNN-based analysis of H&E images could predict benefit from chemotherapy, thus implying distinct tumor morphologies differing between RS groups. Utilizing such a system may enable physicians in countries that lack genetic profiling capabilities to refine chemotherapy stratification based on H&E images alone.
 Citation Format: Gil Shamai, Ran Schley, Ron Kimmel, Nora Balint-Lahat, Iris Barshack, Chen Mayer. Prediction of OncotypeDX high risk group for chemotherapy benefit in breast cancer by deep learning analysis of hematoxylin and eosin-stained whole slide images. [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2023; Part 1 (Regular and Invited Abstracts); 2023 Apr 14-19; Orlando, FL. Philadelphia (PA): AACR; Cancer Res 2023;83(7_Suppl):Abstract nr 5354.

2023: Learning Differential Invariants of Planar Curves
Abstract: We propose a learning paradigm for the numerical approximation of differential invariants of planar curves. Deep neural-networks' (DNNs) universal approximation properties are utilized to estimate geometric measures. The proposed framework is shown to be a preferable alternative to axiomatic constructions. Specifically, we show that DNNs can learn to overcome instabilities and sampling artifacts and produce consistent signatures for curves subject to a given group of transformations in the plane. We compare the proposed schemes to alternative state-of-the-art axiomatic constructions of differential invariants. We evaluate our models qualitatively and quantitatively and propose a benchmark dataset to evaluate approximation models of differential invariants of planar curves.

2023: FuseCap: Leveraging Large Language Models for Enriched Fused Image Captions
Abstract: The advent of vision-language pre-training techniques enhanced substantial progress in the development of models for image captioning. However, these models frequently produce generic captions and may omit semantically important image details. This limitation can be traced back to the image-text datasets; while their captions typically offer a general description of image content, they frequently omit salient details. Considering the magnitude of these datasets, manual reannotation is impractical, emphasizing the need for an automated approach. To address this challenge, we leverage existing captions and explore augmenting them with visual details using "frozen" vision experts including an object detector, an attribute recognizer, and an Optical Character Recognizer (OCR). Our proposed method, FuseCap, fuses the outputs of such vision experts with the original captions using a large language model (LLM), yielding comprehensive image descriptions. We automatically curate a training set of 12M image-enriched caption pairs. These pairs undergo extensive evaluation through both quantitative and qualitative analyses. Subsequently, this data is utilized to train a captioning generation BLIP-based model. This model outperforms current state-of-the-art approaches, producing more precise and detailed descriptions, demonstrating the effectiveness of the proposed data-centric approach. We release this large-scale dataset of enriched image-caption pairs for the community.

2023: Deep Accurate Solver for the Geodesic Problem
Abstract: None

2023: 3D surface topographic measurements for idiopathic scoliosis are highly correlative to patient self-image questionnaires
Abstract: None

2023: Partial Matching of Nonrigid Shapes by Learning Piecewise Smooth Functions
Abstract: Learning functions defined on non‐flat domains, such as outer surfaces of non‐rigid shapes, is a central task in computer vision and geometry processing. Recent studies have explored the use of neural fields to represent functions like light reflections in volumetric domains and textures on curved surfaces by operating in the embedding space. Here, we choose a different line of thought and introduce a novel formulation of partial shape matching by learning a piecewise smooth function on a surface. Our method begins with pairing sparse landmarks defined on a full shape and its part, using feature similarity. Next, a neural representation is optimized to fit these landmarks, efficiently interpolating between the matched features that act as anchors. This process results in a function that accurately captures the partiality. Unlike previous methods, the proposed neural model of functions is intrinsically defined on the given curved surface, rather than the classical embedding Euclidean space. This representation is shown to be particularly well‐suited for representing piecewise smooth functions. We further extend the proposed framework to the more challenging part‐to‐part setting, where both shapes exhibit missing parts. Comprehensive experiments highlight that the proposed method effectively addresses partiality in shape matching and significantly outperforms leading state‐of‐the‐art methods in challenging benchmarks. Code is available at https://github.com/davidgip74/Learning-Partiality-with-Implicit-Intrinsic-Functions

2023: Partial Shape Similarity by Multi-metric Hamiltonian Spectra Matching
Abstract: None

2022: Partial Shape Similarity via Alignment of Multi-Metric Hamiltonian Spectra
Abstract: Evaluating the similarity of non-rigid shapes with significant partiality is a fundamental task in numerous computer vision applications. Here, we propose a novel axiomatic method to match similar regions across shapes. Matching similar regions is formulated as the alignment of the spectra of operators closely related to the Laplace-Beltrami operator (LBO). The main novelty of the proposed approach is the consideration of differential operators defined on a manifold with multiple metrics. The choice of a metric relates to fundamental shape properties while considering the same manifold under different metrics can thus be viewed as analyzing the underlying manifold from different perspectives. Specifically, we examine the scale-invariant metric and the corresponding scale-invariant Laplace-Beltrami operator (SI-LBO) along with the regular metric and the regular LBO. We demonstrate that the scale-invariant metric emphasizes the locations of important semantic features in articulated shapes. A truncated spectrum of the SI-LBO consequently better captures locally curved regions and complements the global information encapsulated in the truncated spectrum of the regular LBO. We show that matching these dual spectra outperforms competing axiomatic frameworks when tested on standard benchmarks. We introduced a new dataset and compare the proposed method with the state-of-the-art learning based approach in a cross-database configuration. Specifically, we show that, when trained on one data set and tested on another, the proposed axiomatic approach which does not involve training, outperforms the deep learning alternative.

2022: Reliability of automated topographic measurements for spine deformity
Abstract: None

2022: Reliability of automated topographic measurements for spine deformity
Abstract: None

2022: Garment Avatars: Realistic Cloth Driving using Pattern Registration
Abstract: Virtual telepresence is the future of online communication. Clothing is an essential part of a person's identity and self-expression. Yet, ground truth data of registered clothes is currently unavailable in the required resolution and accuracy for training telepresence models for realistic cloth animation. Here, we propose an end-to-end pipeline for building drivable representations for clothing. The core of our approach is a multi-view patterned cloth tracking algorithm capable of capturing deformations with high accuracy. We further rely on the high-quality data produced by our tracking method to build a Garment Avatar: an expressive and fully-drivable geometry model for a piece of clothing. The resulting model can be animated using a sparse set of views and produces highly realistic reconstructions which are faithful to the driving signals. We demonstrate the efficacy of our pipeline on a realistic virtual telepresence application, where a garment is being reconstructed from two views, and a user can pick and swap garment design as they wish. In addition, we show a challenging scenario when driven exclusively with body pose, our drivable garment avatar is capable of producing realistic cloth geometry of significantly higher quality than the state-of-the-art.

2022: Prediction of Initial Risk Group, B/T Subtype, and ETV6-RUNX1 Translocation in Pediatric Acute Lymphoblastic Leukemia By Deep Convolutional Neural Network Analysis of Giemsa-Stained Whole Slide Images
Abstract: None

2022: Pattern-Based Cloth Registration and Sparse-View Animation
Abstract: We propose a novel multi-view camera pipeline for the reconstruction and registration of dynamic clothing. Our proposed method relies on a specifically designed pattern that allows for precise video tracking in each camera view. We triangulate the tracked points and register the cloth surface in a fine-grained geometric resolution and low localization error. Compared to state-of-the-art methods, our registration exhibits stable correspondence, tracking the same points on the deforming cloth surface along the temporal sequence. As an application, we demonstrate how the use of our registration pipeline greatly improves state-of-the-art pose-based drivable cloth models. Furthermore, we propose a novel model, Garment Avatar, for driving cloth from a dense tracking signal which is obtained from two opposing camera views. The method produces realistic reconstructions which are faithful to the actual geometry of the deforming cloth. In this setting, the user wears a garment with our custom pattern which enables our driving model to reconstruct the geometry. Our code and data are available at https://github.com/HalimiOshri/Pattern-Based-Cloth-Registration-and-Sparse-View-Animation. The released data includes our pattern and registered mesh sequences containing four different subjects and 15k frames in total.

2022: Deep Signatures - Learning Invariants of Planar Curves
Abstract: We propose a learning paradigm for numerical approximation of differential invariants of planar curves. Deep neural-networks' (DNNs) universal approximation properties are utilized to estimate geometric measures. The proposed framework is shown to be a preferable alternative to axiomatic constructions. Specifically, we show that DNNs can learn to overcome instabilities and sampling artifacts and produce numerically-stable signatures for curves subject to a given group of transformations in the plane. We compare the proposed schemes to alternative state-of-the-art axiomatic constructions of group invariant arc-lengths and curvatures.

2022: Deep Isometric Maps
Abstract: None

2022: Can We Quantify Aging-Associated Postural Changes Using Photogrammetry? A Systematic Review
Abstract: Background: Aging is widely known to be associated with changes in standing posture. Recent advancements in the field of computerized image processing have allowed for improved analyses of several health conditions using photographs. However, photogrammetry’s potential for assessing aging-associated postural changes is yet unclear. Thus, the aim of this review is to evaluate the potential of photogrammetry in quantifying age-related postural changes. Materials and Methods: We searched the databases PubMed Central, Scopus, Embase, and SciELO from the beginning of records to March 2021. Inclusion criteria were: (a) participants were older adults aged ≥60; (b) standing posture was assessed by photogrammetric means. PRISMA guidelines were followed. We used the Newcastle–Ottawa Scale to assess methodological quality. Results: Of 946 articles reviewed, after screening and the removal of duplicates, 11 reports were found eligible for full-text assessment, of which 5 full studies met the inclusion criteria. Significant changes occurring with aging included deepening of thoracic kyphosis, flattening of lumbar lordosis, and increased sagittal inclination. Conclusions: These changes agree with commonly described aging-related postural changes. However, detailed quantification of these changes was not found; the photogrammetrical methods used were often unvalidated and did not adhere to known protocols. These methodological difficulties call for further studies using validated photogrammetrical methods and improved research methodologies.

2022: Elastica Models for Color Image Regularization
Abstract: One classical approach to regularize color is to tream them as two dimensional surfaces embedded in a five dimensional spatial-chromatic space. In this case, a natural regularization term arises as the image surface area. Choosing the chromatic coordinates as dominating over the spatial ones, the image spatial coordinates could be thought of as a paramterization of the image surface manifold in a three dimensional color space. Minimizing the area of the image manifold leads to the Beltrami flow or mean curvature flow of the image surface in the 3D color space, while minimizing the elastica of the image surface yields an additional interesting regularization. Recently, the authors proposed a color elastica model, which minimizes both the surface area and elastica of the image manifold. In this paper, we propose to modify the color elastica and introduce two new models for color image regularization. The revised measures are motivated by the relations between the color elastica model, Euler's elastica model and the total variation model for gray level images. Compared to our previous color elastica model, the new models are direct extensions of Euler's elastica model to color images. The proposed models are nonlinear and challenging to minimize. To overcome this difficulty, two operator-splitting methods are suggested. Specifically, nonlinearities are decoupled by introducing new vector- and matrix-valued variables. Then, the minimization problems are converted to solving initial value problems which are time-discretized by operator splitting. Each subproblem, after splitting either, has a closed-form solution or can be solved efficiently. The effectiveness and advantages of the proposed models are demonstrated by comprehensive experiments. The benefits of incorporating the elastica of the image surface as regularization terms compared to common alternatives are empirically validated.

2021: Multimodal Colored Point Cloud to Image Alignment
Abstract: Reconstruction of geometric structures from images using supervised learning suffers from limited available amount of accurate data. One type of such data is accurate real-world RGB-D images. A major challenge in acquiring such ground truth data is the accurate alignment between RGB images and the point cloud measured by a depth scanner. To overcome this difficulty, we consider a differential optimization method that aligns a colored point cloud with a given color image through iterative geometric and color matching. In the proposed framework, the optimization minimizes the photometric difference between the colors of the point cloud and the corresponding colors of the image pixels. Unlike other methods that try to reduce this photometric error, we analyze the computation of the gradient on the image plane and propose a different direct scheme. We assume that the colors produced by the geometric scanner camera and the color camera sensor are different and therefore characterized by different chromatic acquisition properties. Under these multimodal conditions, we find the transformation between the camera image and the point cloud colors. We alternately optimize for aligning the position of the point cloud and matching the different color spaces. The alignments produced by the proposed method are demonstrated on both synthetic data with quantitative evaluation and real scenes with qualitative results.

2021: U-mesh: Human Correspondence Matching with Mesh Convolutional Networks
Abstract: The proliferation of 3D scanning technology has driven a need for methods to interpret geometric data, particularly for human subjects. In this paper we propose an elegant fusion of regression (bottom-up) and generative (top-down) methods to fit a parametric template model to raw scan meshes. Our first major contribution is an intrinsic convolutional mesh U-net architecture that predicts pointwise correspondence to a template surface. Soft-correspondence is formulated as coordinates in a newly-constructed Cartesian space. Modeling correspondence as Euclidean proximity enables efficient optimization, both for network training and for the next step of the algorithm. Our second contribution is a generative optimization algorithm that uses the U-net correspondence predictions to guide a parametric Iterative Closest Point registration. By employing pre-trained human surface parametric models we maximally leverage domain-specific prior knowledge. The pairing of a mesh-convolutional network with generative model fitting enables us to predict correspondence for real human surface scans including occlusions, partialities, and varying genus (e.g. from self-contact). We evaluate the proposed method on the FAUST correspondence challenge where we achieve 20% (33%) improvement over state of the art methods for inter- (intra-) subject correspondence.

2021: Depth Refinement for Improved Stereo Reconstruction
Abstract: Depth estimation is a cornerstone of a vast number of applications requiring 3D assessment of the environment, such as robotics, augmented reality, and autonomous driving to name a few. One prominent technique for depth estimation is stereo matching which has several advantages: it is considered more accessible than other depth-sensing technologies, can produce dense depth estimates in real-time, and has benefited greatly from the advances of deep learning in recent years. However, current techniques for depth estimation from stereoscopic images still suffer from a built-in drawback. To reconstruct depth, a stereo matching algorithm first estimates the disparity map between the left and right images before applying a geometric triangulation. A simple analysis reveals that the depth error is quadratically proportional to the object's distance. Therefore, constant disparity errors are translated to large depth errors for objects far from the camera. To mitigate this quadratic relation, we propose a simple but effective method that uses a refinement network for depth estimation. We show analytical and empirical results suggesting that the proposed learning procedure reduces this quadratic relation. We evaluate the proposed refinement procedure on well-known benchmarks and datasets, like Sceneflow and KITTI datasets, and demonstrate significant improvements in the depth accuracy metric.

