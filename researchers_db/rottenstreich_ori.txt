Recent papers for Rottenstreich Ori:

2025: A Heterogeneous and Adaptive Architecture for Decision-Tree-Based ACL Engine on FPGA
Abstract: Access Control Lists (ACLs) are crucial for ensuring the security and integrity of modern cloud and carrier networks by regulating access to sensitive information and resources. However, previous software and hardware implementations no longer meet the requirements of modern datacenters. The emergence of FPGA-based SmartNICs presents an opportunity to offload ACL functions from the host CPU, leading to improved network performance in datacenter applications. However, previous FPGA-based ACL designs lacked the necessary flexibility to support different rulesets without hardware reconfiguration while maintaining high performance. In this paper, we propose HACL, a heterogeneous and adaptive architecture for decision-tree-based ACL engine on FPGA. By employing techniques such as tree decomposition and recirculated pipeline scheduling, HACL can accommodate various rulesets without reconfiguring the underlying architecture. To facilitate the efficient mapping of different decision trees to memory and optimize the throughput of a ruleset, we also introduce a heterogeneous framework with a compiler in CPU platform for HACL. We implement HACL on a typical SmartNIC and evaluate its performance. The results demonstrate that HACL achieves a throughput exceeding 260 Mpps when processing 100K-scale ACL rulesets, with low hardware resource utilization. By integrating more engines, HACL can achieve even higher throughput and support larger rulesets.

2024: Survivable Payment Channel Networks
Abstract: Payment channel networks (PCNs) are a leading method to scale the transaction throughput in cryptocurrencies. Two participants can use a bidirectional payment channel for making multiple mutual payments without committing them to the blockchain. Opening a payment channel is a slow operation that involves an on-chain transaction locking a certain amount of funds. These aspects limit the number of channels that can be opened or maintained. Users may route payments through a multi-hop path and thus avoid opening and maintaining a channel for each new destination. Unlike regular networks, in PCNs capacity depends on the usage patterns and, moreover, channels may become unidirectional. Since payments often fail due to channel depletion, a protection scheme to overcome failures is of interest. We define the stopping time of a payment channel as the time at which the channel becomes depleted. We analyze the mean stopping time of a channel as well as that of a network with a set of channels. We then propose a scheme for optimizing the capacity distribution among the channels in order to increase the minimal stopping time in the network. We conduct experiments and demonstrate the accuracy of our model and the efficiency of the proposed optimization scheme.

2024: CFTO: Communication-Aware Fairness in Blockchain Transaction Ordering
Abstract: Blockchain leader-based protocols elect leaders for proposing the next block of transactions. Proposed blocks need to pass a validation routine in order to be added to the blockchain. Proposers may prioritize certain transactions based on their fees or accounts, which enables attackers to gain profits through block building, while simultaneously causing negative impacts on other users. A fair block selection follows a random selection of pending transactions among those that a proposer is aware of. We propose CFTO, a protocol that aims at encouraging fair block selection in a leader-based blockchain network while taking into account real network conditions, such as the network’s topology structure and the forwarding protocol. CFTO offers two main contributions. First, it provides incentives for acting honestly and diminishing malicious and dishonest nodes. To accomplish this, we use a reputation system, whereby each node is given a reputation score based on its actions. Second, it consists of an algorithm that evaluates the proposed blocks based on the zone structure of the network. Furthermore, we adapt the evaluation algorithm to fit the additional order constraints implied in Ethereum transaction ordering. We demonstrate the improved accuracy of CFTO in detecting fair blocks, in terms of increasing the probability of approving fair blocks and decreasing the probability of approving unfair blocks, by implementing experiments and comparing them with Helix (Yakira et al., 2021), a previously proposed consensus algorithm for fair block selection. As part of our experiments, we also compare certain features with those of previous studies.

2024: A Framework for Anomaly Detection in Blockchain Networks With Sketches
Abstract: A blockchain is a distributed ledger composed of immutable blocks of data that often refer to money transfers. As blockchain networks gain popularity, there is a rising concern for security against malicious and hacking users. Detection anomalies and unusual account activities can be based on comparing upcoming activity with recent and historical data. However, the size and rapid growth of the complete blockchain history can result in slow and expensive processing. This paper proposes a solution to this challenge by analyzing summarized block data structures, known as sketches, instead of the entire blockchain. Sketches are commonly used in computer systems and blockchain networks to provide efficient query executions while maintaining a compact data representation. This study explores the use of sketches, such as Bloom Filter and HyperLogLog, to identify suspicious accounts without requiring the examination of the entire blockchain data. We design solutions for anomaly detection of certain goals that may be indications of known attacks. We develop methods to identify accounts with high transaction volume, frequency, and node degree. Furthermore, the innovation of this paper lies in the generalization of sketch-based anomaly detection through a generic solution capable of addressing diverse queries. We conduct experiments based on real Ethereum data and compare the accuracy, time complexity, and memory usage of our algorithms with traditional detection algorithms that rely on the complete blockchain data. Our results indicate that sketch-based anomaly detection methods can provide a practical and scalable solution for detecting anomalies in transactions on blockchain networks. We managed to reduce the amount of memory used by the detection process by 90%-96% and reduce the time complexity by 86% while maintaining high accuracy.

2024: Estimating Daily Start Times of Periodic Traffic Light Plans from Traffic Trajectories
Abstract: In recent years, the wealth of available vehicle location data from connected vehicles, cell phones, and navigation systems has been introduced. This data can be used to improve the existing transportation network in various ways. Among the most promising approaches is traffic light optimization. Traffic light optimization has the potential to reduce traffic congestion, air pollution and GHG emissions. The first step in such optimization is the understanding of the existing traffic light plans. Such plans are periodic but, in practice, often start every day at arbitrary times, making it hard to align traffic trajectories from various days toward the analysis of the plan. We provide an estimation model for estimating the daily start time of periodic plans of traffic lights. The study is inspired by real-world data provided, for instance, by navigation applications. We analyze the accuracy of such computations as a function of the characteristics of the sampled traffic and the length of the evaluated time period.

2024: Quantitative Approach for Coordination, at Scale, of Signalized Intersection Pairs
Abstract: The coordination of signalized intersections in urban cities improves both traffic operations and environmental aspects. Traffic signal coordination has a long history, where the impact of offset on delays and emissions at signalized intersections has been investigated through simulations and a limited number of experimental findings. Coordinating intersections is often warranted by specific engineering requirements and judgment. However, as a consequence, many intersections in cities remain without coordination. In this paper, we examine the potential benefits of coordinating signalized intersections at scale. Unlike previous studies, our analysis is based on aggregated anonymized probe data analysis and does not need to explicitly model traffic-oriented issues such as queue spillback and platoon dispersion. We follow a quantitative approach by considering an intersection pair, i.e. a system of two signalized intersections which can be spatially coupled. We introduce a new method for coordinating those signalized intersections. The method first evaluates the effect of different offsets on vehicle travel times and fuel consumption (or emissions). Then, it coordinates the two intersections by setting a common cycle and finding the optimal offset that minimizes fuel consumption and/or travel times. We present the analysis for several case studies from real intersections at Jakarta, Rio de Janeiro, Kolkata, and Haifa. Finally, we evaluated our method by implementing it in a real experimental study at Jakarta. We collaborated with the city to implement the optimal offset determined by the proposed method, and we compared the results before and after coordination.

2024: Privacy Comparison for Bitcoin Light Client Implementations
Abstract: Light clients implement a simple solution for Bitcoin’s scalability problem, as they do not store the entire blockchain but only the state of particular addresses of interest. To be able to keep track of the updated state of their addresses, light clients rely on full nodes to provide them with the required information. To do so, they must reveal information about the addresses they are interested in. This paper studies the two most common light client implementations, SPV and Neutrino with regards to their privacy. We define privacy metrics for comparing the privacy of the different implementations. We evaluate and compare the privacy of the implementations over time on real Bitcoin data and discuss the inherent privacy-communication tradeoff. In addition, we propose general techniques to enhance light client privacy in the existing implementations. Finally, we propose a new SPV-based light client model, the aggregation model, evaluate it, and show it can achieve enhanced privacy than in the existing light client implementations.

2024: Traffic-Aware Merkle Trees for Shortening Blockchain Transaction Proofs
Abstract: Merkle trees play a crucial role in blockchain networks in organizing network state. They allow proving a particular value of an entry in the state to a node that maintains only the root of the Merkle trees, a hash-based signature computed over the data in a hierarchical manner. Verification of particular state entries is crucial in reaching a consensus on the execution of a block where state information is required in the processing of its transactions. For instance, a payment transaction should be based on the balance of the two involved accounts. The proof length affects the network communication and is typically logarithmic in the state size. In this paper, we take advantage of typical transaction characteristics for better organizing Merkle trees to improve blockchain network performance. We focus on the common transaction processing where Merkle proofs are jointly provided for multiple accounts. We first provide lower bounds for the communication cost that are based on the distribution of accounts involved in the transactions. We then describe algorithms that consider traffic patterns for significantly reducing it. The algorithms are inspired by various coding methods such as Huffman coding, partition and weight balancing. We also generalize our approach towards the encoding of smart contract transactions that involve an arbitrary number of accounts. Likewise, we rely on real blockchain data to show the savings allowed by our approach. The experimental evaluation is based on transactions from the Ethereum network and demonstrates cost reduction for both payment transactions and smart contract transactions.

2024: SoK: Applications of Sketches and Rollups in Blockchain Networks
Abstract: Blockchain networks suffer from a critical scalability problem that is often expressed in two dimensions: the size of the network state and the computational overhead in processing transactions as part of the network update. This paper surveys two major families of solutions known as sketches and rollups that both rely on aggregation methods. Sketches are popular hash-based data structures used to represent a large amount of data while supporting particular queries such as on set membership, cardinality estimation and identification of large elements. Rollups play in a different form and refer to aggregation of the execution of multiple transactions to allow high transaction rates and low fees. The design of popular blockchain networks such as Bitcoin and Ethereum makes use of sketches for various tasks such as summarization of transaction blocks or declaring the interests of light nodes. In addition, rollups are implemented in several forms to allow high transaction rates through offloading parts of the execution out of the blockchain while keeping its security. This paper overviews the basics of sketches and rollups and provides a comprehensive survey on the wide range of existing applications of the two families in blockchains.

2024: Edge-Disjoint Tree Allocation for Multi-Tenant Cloud Security in Datacenter Topologies
Abstract: Resource sharing with its implied mutual interference has been considered a major concern for running applications of multiple tenants in shared cloud datacenters. Besides its security benefits, the isolation of traffic might ensure a quality of service (QoS) performance guarantee avoiding interference among tenants. Traffic isolation can be achieved by dedicating the usage of link resources in the network to a single tenant preventing its sharing among others. Accordingly, tenants should be connected through an edge-disjoint tree to enable isolated communication among its hosts. In this paper, we study the problem of establishing edge-disjoint trees in common datacenter topologies. We show that the availability of such trees is highly affected by the mapping of the tenants to hosts of the topology. Specifically, with the flexibility to map tenants in the datacenter topology, we describe a mapping algorithm and an optimal tree establishment for the optimization problem. Given the mapping of the tenants, we prove the problem turns out to be NP-Hard and provide comprehensive heuristics for the problem. Finally, we conduct experiments using real workloads to examine tree availability under various scenarios.

2024: Invertible Bloom Lookup Tables with Listing Guarantees
Abstract: The Invertible Bloom Lookup Table (IBLT) is a probabilistic concise data structure for set representation that supports a listing operation as the recovery of the elements in the represented set. Its applications can be found in network synchronization and traffic monitoring as well as in error-correction codes. IBLT can list its elements with probability affected by the size of the allocated memory and the size of the represented set, such that it can fail with small probability even for relatively small sets. While previous works only studied the failure probability of IBLT, this work initiates the worst case analysis of IBLT that guarantees successful listing for all sets of a certain size. The worst case study is important since the failure of IBLT imposes high overhead. We describe a novel approach that guarantees successful listing when the set satisfies a tunable upper bound on its size. To allow that, we develop multiple constructions that are based on various coding techniques such as stopping sets and the stopping redundancy of error-correcting codes, and Steiner systems as well as new methodologies we develop. We analyze the sizes of IBLTs with listing guarantees obtained by the various methods as well as their mapping memory and runtime overheads. Lastly, we study lower bounds on the achievable sizes of IBLT with listing guarantees and verify the results in the paper by simulations.

2024: Detection of NFT Duplications with Image Hash Functions
Abstract: Non-fungible tokens (NFTs) are digital assets representing ownership or proof of authenticity of a unique item. NFTs are blockchain-based and rely on smart contracts. The increase in duplicate NFTs in recent years brings the need for discovery tools for forged NFTs, some of which include using image hash functions. Though the problem of image duplication is widely discussed, detecting NFT duplications requires using fast detection methods as a new NFT image needs to be compared with the entire NFT history on the blockchain. In this paper, we analyze the performance of several image-hash functions, examine the cases where each function performs well, and evaluate multiple image-hash-functions-based NFT duplication detectors. Our approach achieves high accuracy in detecting NFT duplications and demonstrates that using several hash functions rather than one increases the ability to detect duplications.

2024: Probe-Based Study of Traffic Variability for the Design of Traffic Light Plans
Abstract: Computing efficient traffic signal plans is often based on the amount of traffic in an intersection, its distribution over the various intersection movements and hours as well as on performance metrics such as traffic delay. In their simple and typical form, plans are fixed in the same hour over weekdays. This allows low operation costs without the necessity for traffic detection and monitoring tools. A critical factor in the potential efficiency of such plans is the similarity of traffic patterns over the days along each of the intersection movements. In this paper, we study traffic variability and propose simple metrics to measure it based on traffic volume and traffic delay. We propose an automatic probe data-based method, for city-wide estimation of traffic variability. We discuss how such measures can be used for signal planning such as an indication of which intersections can benefit from dynamic but expensive traffic detection tools or in selecting plan resolution. Likewise, we discuss various methods to mitigate the impact of such variability. We demonstrate the framework based on real traffic statistics to study the traffic variability in the city of Haifa along its 162 intersections.

2024: An Empirical Study of Cross-Chain Arbitrage in Decentralized Exchanges
Abstract: Blockchain interoperability refers to the ability of blockchains to share information with each other. Decentralized Exchanges (DEXs) are peer-to-peer marketplaces where traders can exchange cryptocurrencies. Several studies have focused on arbitrage analysis within a single blockchain, typically in Ethereum. Recently, we have seen a growing interest in cross-chain technologies to create a more interconnected blockchain network. We present a framework to study cross-chain arbitrage in DEXs. We use this framework to analyze cross-chain arbitrages between two popular DEXs, PancakeSwap and QuickSwap, within a time frame of a month. While PancakeSwap is implemented on a blockchain named BNB Chain, QuickSwap is implemented on a different blockchain named Polygon. The approach of this work is to study the cross-chain arbitrage through an empirical study. We refer to the number of arbitrages, their revenue as well as to their duration. This work lays the basis for understanding cross-chain arbitrage and its potential impact on the blockchain technology.

2024: Understanding the Blockchain Interoperability Graph Based on Cryptocurrency Price Correlation
Abstract: Cryptocurrencies have gained high popularity in recent years, with over 9000 of them, including major ones such as Bitcoin and Ether. Each cryptocurrency is implemented on one block chain or over several such networks. Recently, various technologies known as blockchain interoperability have been developed to connect these different blockchains and create an interconnected blockchain ecosystem. This paper aims to provide insights on the blockchain ecosystem and the connection between blockchains that we refer to as the interoperability graph. Our approach is based on the analysis of the correlation between cryptocurrencies implemented over the different blockchains. We examine over 4800 cryptocurrencies implemented on 76 blockchains and their daily prices over a year. This experimental study has potential implications for decentralized finance (DeFi), including portfolio investment strategies and risk management.

2024: Topologies for Blockchain Payment Channel Networks: Models and Constructions
Abstract: Payment channel networks (PCNs), also known as off-chain networks, implement a common approach to deal with the scalability problem of blockchain networks. They enable users to execute payments without committing them to the blockchain by relying on predefined payment channels. A pair of users can employ a payment even without a direct channel between them, by routing the payment via payment channels involving other intermediate users. Users, together with the channels, form a graph known as the off-chain network topology. The off-chain topology and the payment characteristics affect network performance such as the average number of intermediate users a payment is routed through or the values of transaction fees. In this paper, we study two basic problems in payment channel network design. First, efficiently mapping users to an off-chain topology with a known structure. Second, constructing a topology with a bounded number of channels that can serve users well with associated payments. We design algorithms for both problems while considering several fundamental topologies. We study topology-related real data statistics of Raiden, the off-chain extension for Ethereum as well as of Lightning, the equivalent off-chain layer of Bitcoin. We conduct experiments to demonstrate the effectiveness of the algorithms for these networks.

2023: Scaling by Learning: Accelerating Open vSwitch Data Path With Neural Networks
Abstract: Open vSwitch (OVS) is a widely used open-source virtual switch implementation. In this work, we seek to scale up OVS to support hundreds of thousands of OpenFlow rules by accelerating the core component of its data-path - the packet classification mechanism. To do so we use NuevoMatch, a recent algorithm that uses neural network inference to match packets, and promises significant scalability and performance benefits. We overcome the primary algorithmic challenge of the slow training rate in the vanilla NuevoMatch, speeding it up by over three orders of magnitude. This improvement enables two design options to integrate NuevoMatch with OVS: (1) as an extra caching layer in front of OVS’s megaflow cache, and (2) using it to completely replace OVS’s data-path while performing classification directly on OpenFlow rules, and obviating control-path upcalls. Comprehensive evaluation on real-world packet traces and ClassBench rules demonstrates geometric mean speedups of <inline-formula> <tex-math notation="LaTeX">$1.9\times $ </tex-math></inline-formula> and <inline-formula> <tex-math notation="LaTeX">$12.3\times $ </tex-math></inline-formula> for the first and second designs, respectively, for 500K rules, with the latter also supporting up to 60K OpenFlow rule updates/second, by far exceeding the original OVS.

2023: Attacking the Privacy of Approximate Membership Check Filters by Positive Concentration
Abstract: Approximate membership check filters are increasingly used to speed up data processing in many applications. Also, privacy is becoming a key design objective for many systems and thus, the privacy of filters needs to be carefully considered. Previous works have shown that an attacker that knows the implementation details of the filter and has access to its content, may be able to extract some information about the elements stored in the filter. This attack is, however, specific to Bloom filters and requires that the universe of elements must be small. In this article, we show that in many practical settings, an attacker that has only a black-box access to the filter, can extract information about the elements stored in the filter regardless of the specific filter type and the universe size. This is possible based on the key observation that in many applications, the elements stored in the filter are not randomly chosen, but they are concentrated in one or more parts of the universe of elements. To identify these parts, the positive probability can be measured on different parts of the universe; the parts having significantly larger values than the average positive probability for the filter are the ones on which the filter elements are concentrated. This approach is formalized and applied to several case studies showing the process by which the attacker can get additional information about the elements stored for the filters in a wide range of scenarios.

2023: Braess Paradox in Layer-2 Blockchain Payment Networks
Abstract: Layer-2 is a popular approach to deal with the scalability limitation of blockchain networks. It allows users to execute transactions without committing them to the blockchain by relying on predefined payment channels. Users together with the payment channels form a graph, known as the offchain network topology. Transactions between pairs of users without a connecting channel are also supported through a path of multiple channels. Serving such transactions involves fees paid to intermediate users. In this paper we uncover the potential existence of the Braess paradox in payment networks: Sometimes establishing a new payment channel can increase the fees paid for serving some fixed transactions. We study conditions for the paradox to appear and provide indications for the appearance of the paradox based on real data of Bitcoin's Lightning, a popular layer-2 network. Last, we discuss methods to mitigate the paradox upon establishing a new payment channel.

2023: Compressing Distributed Network Sketches With Traffic-Aware Summaries
Abstract: Network measurements are important for identifying congestion, DDoS attacks, and more. To support real-time analytics, stream ingestion is performed jointly by multiple nodes, each observing part of the traffic, periodically reporting its measurements to a single centralized server that aggregates them. To avoid communication congestion, each node reports a compressed version of its collected measurements. Traditionally, nodes symmetrically report summaries of the same size computed on their data. We explain that to maximize the accuracy of the joint measurement, nodes should imply various compression ratios on their measurements based on the amount of traffic observed by each node. We illustrate the approach for three common sketches: The Count-Min sketch (CM), which estimates flow sizes as well as for the K-minimum-values (KMV) sketch and the HyperLogLog (HLL), which both estimate the number of distinct flows. For each sketch, we compute node compression ratios based on the traffic distribution. In general, this is done with a single round of communication with the central server, after which the compression ratio for each node can be computed. We perform extensive simulations for the sketches and analytically show that, under real-world scenarios, our sketches send smaller summaries than traditional ones while retaining similar error bounds.

