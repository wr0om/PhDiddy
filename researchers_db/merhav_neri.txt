Recent papers for Merhav Neri:

2025: A Toolbox for Refined Information-Theoretic Analyses
Abstract: None

2024: Refinements and Extensions of Ziv’s Model of Perfect Secrecy for Individual Sequences
Abstract: We refine and extend Ziv’s model and results regarding perfectly secure encryption of individual sequences. According to this model, the encrypter and the legitimate decrypter share a common secret key that is not shared with the unauthorized eavesdropper. The eavesdropper is aware of the encryption scheme and has some prior knowledge concerning the individual plaintext source sequence. This prior knowledge, combined with the cryptogram, is harnessed by the eavesdropper, who implements a finite-state machine as a mechanism for accepting or rejecting attempted guesses of the plaintext source. The encryption is considered perfectly secure if the cryptogram does not provide any new information to the eavesdropper that may enhance their knowledge concerning the plaintext beyond their prior knowledge. Ziv has shown that the key rate needed for perfect secrecy is essentially lower bounded by the finite-state compressibility of the plaintext sequence, a bound that is clearly asymptotically attained through Lempel–Ziv compression followed by one-time pad encryption. In this work, we consider some more general classes of finite-state eavesdroppers and derive the respective lower bounds on the key rates needed for perfect secrecy. These bounds are tighter and more refined than Ziv’s bound, and they are attained using encryption schemes that are based on different universal lossless compression schemes. We also extend our findings to the case where side information is available to the eavesdropper and the legitimate decrypter but may or may not be available to the encrypter.

2024: Parameter Estimation Based on Noisy Chaotic Signals in the Weak-Noise Regime
Abstract: We consider the problem of parameter estimation, based on noisy chaotic signals, from the viewpoint of twisted modulation for waveform communication. In particular, we study communication systems where the parameter to be estimated is conveyed as the initial condition of a chaotic dynamical system of a certain class and we examine its estimation performance in terms of the expectation of a given convex function of the estimation error at high SNR, under the demand that the probability of anomaly is kept small. We derive a lower bound on the weak-noise estimation error for this class of chaotic modulators, and argue that it can be outperformed by using the itinerary signal associated with the chaotic system instead of the main chaotic output signal.

2024: A Toolbox for Refined Information-Theoretic Analyses with Applications
Abstract: This monograph offers a toolbox of mathematical techniques, which have been effective and widely applicable in information-theoretic analysis. The first tool is a generalization of the method of types to Gaussian settings, and then to general exponential families. The second tool is Laplace and saddle-point integration, which allow to refine the results of the method of types, and are capable of obtaining more precise results. The third is the type class enumeration method, a principled method to evaluate the exact random-coding exponent of coded systems, which results in the best known exponent in various problem settings. The fourth subset of tools aimed at evaluating the expectation of non-linear functions of random variables, either via integral representations, or by a refinement of Jensen's inequality via change-of-measure, by complementing Jensen's inequality with a reversed inequality, or by a class of generalized Jensen's inequalities that are applicable for functions beyond convex/concave. Various application examples of all these tools are provided along this monograph.

2024: The Secrecy Capacity of the Wiretap Channel With Additive Noise and Rate-Limited Help
Abstract: The wiretap channel with additive (possibly non-Gaussian) noise and rate-limited help, available at the legitimate receiver (Rx) or/and transmitter (Tx), is studied under various channel configurations (degraded, reversely degraded and non-degraded) and power/amplitude constraints. For all channel configurations, the rate-limited Rx help results in a (weak or strong) secrecy capacity boost equal to the help rate. This holds irrespective of whether the help is secure or not, or whether the helper is aware of the message being transmitted or not; the secrecy of help or helper’s knowledge of the message does not provide any extra capacity boost. The secrecy capacity is positive for the reversely-degraded channel (where the no-help secrecy capacity is zero) and no wiretap coding is needed to achieve it under weak secrecy. The same capacity boost also holds if non-secure help is available to the transmitter (encoder), in addition to or instead of the same Rx help, so that, in the case of the joint Tx/Rx help, one help link can be omitted without affecting the capacity. If Rx/Tx help links are independent of each other, the capacity boost is the sum of help rates and no link can be omitted without loss in the capacity. Non-singular correlation of the receiver and eavesdropper noises does not affect the secrecy capacity and non-causal help does not bring in any capacity increase over the causal one. The choice of the secrecy criterion (weak/strong) affects the complexity of implementation but not the secrecy capacity. Stronger noise at the legitimate receiver can sometimes result in higher secrecy capacity.

2024: Lossy Compression of Individual Sequences Revisited: Fundamental Limits of Finite-State Encoders
Abstract: We extend Ziv and Lempel’s model of finite-state encoders to the realm of lossy compression of individual sequences. In particular, the model of the encoder includes a finite-state reconstruction codebook followed by an information lossless finite-state encoder that compresses the reconstruction codeword with no additional distortion. We first derive two different lower bounds to the compression ratio, which depend on the number of states of the lossless encoder. Both bounds are asymptotically achievable by conceptually simple coding schemes. We then show that when the number of states of the lossless encoder is large enough in terms of the reconstruction block length, the performance can be improved, sometimes significantly so. In particular, the improved performance is achievable using a random-coding ensemble that is universal, not only in terms of the source sequence but also in terms of the distortion measure.

2024: Universal Slepian-Wolf Coding for Individual Sequences
Abstract: We establish a coding theorem and a matching converse theorem for separate encodings and joint decoding of individual sequences using finite-state machines. The achievable rate region is characterized in terms of the Lempel-Ziv (LZ) complexities, the conditional LZ complexities and the joint LZ complexity of the two source sequences. An important feature that is needed to this end, which may be interesting on its own right, is a certain asymptotic form of a chain rule for LZ complexities, which we establish in this work. The main emphasis in the achievability scheme is on the universal decoder and its properties. We then show that the achievable rate region is universally attainable by a modified version of Draper’s universal incremental Slepian-Wolf (SW) coding scheme, provided that there exists a low-rate reliable feedback link.

2024: Optimal Signals and Detectors Based on Correlation and Energy
Abstract: In continuation of an earlier study, we explore a Neymann-Pearson hypothesis testing scenario where, under the null hypothesis (<inline-formula> <tex-math notation="LaTeX">${\mathcal { H}}_{0}$ </tex-math></inline-formula>), the received signal is a white noise process <inline-formula> <tex-math notation="LaTeX">$N_{t}$ </tex-math></inline-formula>, which is not Gaussian in general, and under the alternative hypothesis (<inline-formula> <tex-math notation="LaTeX">${\mathcal { H}}_{1}$ </tex-math></inline-formula>), the received signal comprises a deterministic transmitted signal <inline-formula> <tex-math notation="LaTeX">$s_{t}$ </tex-math></inline-formula> corrupted by additive white noise, the sum of <inline-formula> <tex-math notation="LaTeX">$N_{t}$ </tex-math></inline-formula> and another noise process originating from the transmitter, denoted as <inline-formula> <tex-math notation="LaTeX">$Z_{t}$ </tex-math></inline-formula>, which is not necessarily Gaussian either. Our approach focuses on detectors that are based on the correlation and energy of the received signal, which are motivated by implementation simplicity. We optimize the detector parameters to achieve the best trade-off between missed-detection and false-alarm error exponents. First, we optimize the detectors for a given signal, resulting in a non-linear relation between the signal and correlator weights to be optimized. Subsequently, we optimize the transmitted signal and the detector parameters jointly, revealing that the optimal signal is a balanced ternary signal and the correlator has at most three different coefficients, thus facilitating a computationally feasible solution.

2024: Two New Families of Local Asymptotically Minimax Lower Bounds in Parameter Estimation
Abstract: We propose two families of asymptotically local minimax lower bounds on parameter estimation performance. The first family of bounds applies to any convex, symmetric loss function that depends solely on the difference between the estimate and the true underlying parameter value (i.e., the estimation error), whereas the second is more specifically oriented to the moments of the estimation error. The proposed bounds are relatively easy to calculate numerically (in the sense that their optimization is over relatively few auxiliary parameters), yet they turn out to be tighter (sometimes significantly so) than previously reported bounds that are associated with similar calculation efforts, across many application examples. In addition to their relative simplicity, they also have the following advantages: (i) Essentially no regularity conditions are required regarding the parametric family of distributions. (ii) The bounds are local (in a sense to be specified). (iii) The bounds provide the correct order of decay as functions of the number of observations, at least in all the examples examined. (iv) At least the first family of bounds extends straightforwardly to vector parameters.

2024: Power-limited Modulation-Estimation with a Helper
Abstract: The problem of transmitting a parameter value over an additive white Gaussian noise (AWGN) channel is considered, where, in addition to the transmitter and the receiver, there is a helper that observes the noise non-causally and provides a description of limited rate $R_{\mathrm{h}}$ to the transmitter and/or the receiver. We derive upper and lower bounds on the optimal achievable $\alpha-\mathbf{th}$ moment of the estimation error and show that they coincide for small values of $\alpha$ and for high values of $R_{\mathrm{h}}$. The upper bound relies on a recently proposed channel-coding scheme that effectively conveys $R_{\mathrm{h}}$ bits essentially error-free and the rest of the rate—over the same AWGN channel without help, with the error-free bits being allocated to the most significant bits of the quantized parameter.

2024: On Jacob Ziv's Individual-Sequence Approach to Information Theory
Abstract: This article stands as a tribute to the enduring legacy of Jacob Ziv and his landmark contributions to information theory. Specifically, it delves into the groundbreaking individual-sequence approach -- a cornerstone of Ziv's academic pursuits. Together with Abraham Lempel, Ziv pioneered the renowned Lempel-Ziv (LZ) algorithm, a beacon of innovation in various versions. Beyond its original domain of universal data compression, this article underscores the broad utility of the individual-sequence approach and the LZ algorithm across a wide spectrum of problem areas. As we traverse through the forthcoming pages, it will also become evident how Ziv's visionary approach has left an indelible mark on my own research journey, as well as on those of numerous colleagues and former students. We shall explore, not only the technical power of the LZ algorithm, but also its profound impact on shaping the landscape of information theory and its applications.

2023: The Secrecy Capacity of Gaussian Wiretap Channels with Rate-Limited Help at the Encoder
Abstract: The Gaussian wiretap channel (WTC) with rate-limited help, available at the transmitter/encoder (Tx), in addition to or instead of the same help at the legitimate receiver, is studied under various channel configurations. For the degraded or reversely-degraded WTC, rate-limited non-secure Tx help results in a secrecy capacity boost equal to the help rate irrespective of whether the help is causal or not. For the non-degraded WTC, the secrecy capacity boost is lower bounded by the help rate. A capacity-achieving signaling is two-phase time sharing, where wiretap coding without help is used in Phase 1 and help without wiretap coding is used in Phase 2. The secrecy capacity with Tx help is positive for the reversely-degraded channel (where the no-help secrecy capacity is zero) and no Phase 1 is needed to achieve it. Unlike the no-help case, more noise at the legitimate receiver can sometimes result in higher secrecy capacity with Tx help. In the case of the joint Tx/Rx non-secure help, one help link can be omitted without affecting the capacity.

2023: Some Families of Jensen-like Inequalities with Application to Information Theory
Abstract: It is well known that the traditional Jensen inequality is proved by lower bounding the given convex function, f(x), by the tangential affine function that passes through the point (E{X},f(E{X})), where E{X} is the expectation of the random variable X. While this tangential affine function yields the tightest lower bound among all lower bounds induced by affine functions that are tangential to f, it turns out that when the function f is just part of a more complicated expression whose expectation is to be bounded, the tightest lower bound might belong to a tangential affine function that passes through a point different than (E{X},f(E{X})). In this paper, we take advantage of this observation by optimizing the point of tangency with regard to the specific given expression in a variety of cases and thereby derive several families of inequalities, henceforth referred to as “Jensen-like” inequalities, which are new to the best knowledge of the author. The degree of tightness and the potential usefulness of these inequalities is demonstrated in several application examples related to information theory.

2023: Error Exponents of the Dirty-Paper and Gel’fand-Pinsker Channels
Abstract: We derive various error exponents for communication channels with random states, which are available non-causally at the encoder only. For both the finite-alphabet Gel’fand-Pinsker channel and its Gaussian counterpart, the dirty-paper channel, we derive random coding exponents, error exponents of the typical random codes (TRCs), and error exponents of expurgated codes. For the two channel models, we analyze some sub-optimal bin-index decoders, which turn out to be asymptotically optimal, at least for the random coding error exponent. For the dirty-paper channel, we show explicitly via a numerical example, that at rates below capacity, the optimal values of the dirty-paper design parameter α in the random coding sense and in the TRC exponent sense are different from one another, and they are both different from the optimal α that is required for attaining the channel capacity. For the Gel’fand-Pinsker channel, we allow for a variable-rate random binning code construction, and prove that the previously proposed maximum penalized mutual information decoder is asymptotically optimal within a given class of decoders, at least for the random coding error exponent.

2023: In Memory of Jacob Ziv
Abstract: None

2023: Trade-offs Between Weak-Noise Performance and Probability of Anomaly in Parameter Estimation from Noisy Chaotic Signals
Abstract: We consider the problem of parameter estimation, based on noisy chaotic signals, from the viewpoint of twisted modulation for waveform communication. In particular, we study communication systems where the parameter to be estimated is conveyed as the initial condition of a chaotic dynamical system of a certain class and we examine its estimation performance in terms of the expectation of a given convex function of the estimation error at high SNR, under the demand that the probability of anomaly is kept small. We derive a lower bound on the weak-noise estimation error for this class of chaotic modulators, and argue that it can be outperformed by using the itinerary signal associated with the chaotic system instead of the main chaotic output signal.

2023: Modulation and Estimation With a Helper
Abstract: The problem of transmitting a parameter value over an additive white Gaussian noise (AWGN) channel is considered, where, in addition to the transmitter and the receiver, there is a helper that observes the noise non-causally and provides a description of limited rate <inline-formula> <tex-math notation="LaTeX">$R_{\mathrm {h}}$ </tex-math></inline-formula> to the transmitter and/or the receiver. We derive upper and lower bounds on the optimal achievable <inline-formula> <tex-math notation="LaTeX">$\alpha $ </tex-math></inline-formula>-th moment of the estimation error and show that they coincide for small values of <inline-formula> <tex-math notation="LaTeX">$\alpha $ </tex-math></inline-formula> and for high values of <inline-formula> <tex-math notation="LaTeX">$R_{\mathrm {h}}$ </tex-math></inline-formula>. The upper bound relies on a recently proposed channel-coding scheme that effectively conveys <inline-formula> <tex-math notation="LaTeX">$R_{\mathrm {h}}$ </tex-math></inline-formula> bits essentially error-free and the rest of the rate—over the same AWGN channel without help, with the error-free bits being allocated to the most significant bits of the quantized parameter. We then concentrate on the setting with a total transmit energy constraint, for which we derive achievability results for both channel coding and parameter modulation for several scenarios: when the helper assists only the transmitter or only the receiver and knows the noise, and when the helper assists the transmitter and/or the receiver and knows both the noise and the message. In particular, for the message-informed helper that assists both the receiver and the transmitter, it is shown that the error probability in the channel-coding task decays doubly exponentially. Finally, we translate these results to those for continuous-time power-limited AWGN channels with unconstrained bandwidth. As a byproduct, we show that the capacity with a message-informed helper that is available only at the transmitter can exceed the sum of the capacity without help and the help rate <inline-formula> <tex-math notation="LaTeX">$R_{\mathrm {h}}$ </tex-math></inline-formula>.

2022: D-Semifaithful Codes That are Universal Over Both Memoryless Sources and Distortion Measures
Abstract: We prove the existence of codebooks for <inline-formula> <tex-math notation="LaTeX">$d$ </tex-math></inline-formula>-semifaithful lossy compression that are simultaneously universal with respect to both the class of finite-alphabet memoryless sources and the class of all bounded additive rational distortion measures. By applying independent random selection of the codewords according to a mixture of all memoryless sources, we achieve redundancy rates that are within <inline-formula> <tex-math notation="LaTeX">$O(\log n/n)$ </tex-math></inline-formula> close to the empirical rate-distortion function of every given source vector with respect to every bounded, rational distortion measure.

2022: Universal Decoding for the Typical Random Code and for the Expurgated Code
Abstract: We provide two results concerning the optimality of the stochastic-mutual information (SMI) decoder, which chooses the estimated message according to a posterior probability mass function, which is proportional to the exponentiated empirical mutual information induced by the channel output sequence and the different codewords. First, we prove that the error exponents of the typical random codes under the optimal maximum likelihood (ML) decoder and the SMI decoder are equal. As a corollary to this result, we also show that the error exponents of the expurgated codes under the ML and the SMI decoders are equal. These results strengthen the well-known result due to Csiszár and Körner, according to which, the ML and the maximum-mutual information (MMI) decoders achieve equal random-coding error exponents, since the error exponents of the typical random code and the expurgated code are strictly higher than the random-coding error exponents, at least at low coding rates. The universal optimality of the SMI decoder, in the random-coding error exponent sense, is easily proven by commuting the expectation over the channel noise and the expectation over the ensemble. This commutation can no longer be carried out, when it comes to typical and expurgated exponents. Therefore, the proof of the universal optimality of the SMI decoder must be completely different and it turns out to be highly non-trivial.

2022: The DNA Storage Channel: Capacity and Error Probability Bounds
Abstract: The DNA storage channel is considered, in which the <inline-formula> <tex-math notation="LaTeX">$M$ </tex-math></inline-formula> Deoxyribonucleic acid (DNA) molecules comprising each codeword are stored without order, sampled <inline-formula> <tex-math notation="LaTeX">$N$ </tex-math></inline-formula> times with replacement, and then sequenced over a discrete memoryless channel. For a constant coverage depth <inline-formula> <tex-math notation="LaTeX">$M/N$ </tex-math></inline-formula> and molecule length scaling <inline-formula> <tex-math notation="LaTeX">$\Theta (\log M)$ </tex-math></inline-formula>, lower (achievability) and upper (converse) bounds on the capacity of the channel, as well as a lower (achievability) bound on the reliability function of the channel are provided. Both the lower and upper bounds on the capacity generalize a bound which was previously known to hold only for the binary symmetric sequencing channel, and only under certain restrictions on the molecule length scaling and the crossover probability parameters. When specified to binary symmetric sequencing channel, these restrictions are completely removed for the lower bound and are significantly relaxed for the upper bound in the high-noise regime. The lower bound on the reliability function is achieved under a universal decoder, and reveals that the dominant error event is that of <italic>outage</italic> – the event in which the capacity of the channel induced by the DNA molecule sampling operation does not support the target rate.

